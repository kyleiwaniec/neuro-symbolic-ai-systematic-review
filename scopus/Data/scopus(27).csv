Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Abstract,Author Keywords,Index Keywords,References,Sponsors,Conference name,Conference date,Conference location,Conference code,Document Type,Publication Stage,Open Access,Source,EID
"Demeter D., Downey D.","57205541880;35956201800;","Just Add Functions: A Neural-Symbolic Language Model",2020,"AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",,,,"7634","7642",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106687657&partnerID=40&md5=99a9831b6a0bb62d7b930f25aeee9a0a","Neural network language models (NNLMs) have achieved ever-improving accuracy due to more sophisticated architectures and increasing amounts of training data. However, the inductive bias of these models (formed by the distributional hypothesis of language), while ideally suited to modeling most running text, results in key limitations for today's models. In particular, the models often struggle to learn certain spatial, temporal, or quantitative relationships, which are commonplace in text and are second-nature for human readers. Yet, in many cases, these relationships can be encoded with simple mathematical or logical expressions. How can we augment today's neural models with such encodings In this paper, we propose a general methodology to enhance the inductive bias of NNLMs by incorporating simple functions into a neural architecture to form a hierarchical neural-symbolic language model (NSLM). These functions explicitly encode symbolic deterministic relationships to form probability distributions over words. We explore the effectiveness of this approach on numbers and geographic locations, and show that NSLMs significantly reduce perplexity in small-corpus language modeling, and that the performance improvement persists for rare tokens even on much larger corpora. The approach is simple and general, and we discuss how it can be applied to other word classes beyond numbers and geography. © 2020 The Twenty-Fifth AAAI/SIGAI Doctoral Consortium (AAAI-20). All Rights Reserved.",,"Artificial intelligence; Computational linguistics; Encoding (symbols); Network architecture; Probability distributions; General methodologies; Geographic location; Inductive bias; Language model; Logical expressions; Network language; Neural architectures; Symbolic languages; Modeling languages","Ahn, S., Choi, H., Pärnamaa, T., Bengio, Y., (2017) A neural knowledge language model, , CoRR abs/1608.00318; Bengio, Y., Schwenk, H., Senecal, J.-S., Morin, F., Gauvain, J.-L., (2006) Neural probabilistic language models; Besold, T. R., d'Avila Garcez, A. S., Bader, S., Bowman, H., Domingos, P. M., Hitzler, P., Kühnberger, K.-U., Zaverucha, G., (2017) Neural-symbolic learning and reasoning: A survey and interpretation, , ArXiv abs/1711.03902; Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., Koehn, P., One billion word benchmark for measuring progress in statistical language modeling (2013) INTERSPEECH; Firth, J. R., (1957) A synopsis of linguistic theory 1930-55, pp. 1-32. , 1952 59; (2019) GeoNames, , http://geonames.org; Grave, E., Joulin, A., Usunier, N., (2017) Improving neural language models with a continuous cache, , CoRR abs/1612.04426; Hupkes, D., Zuidema, W. H., Visualisation and 'diagnostic classifiers' reveal how recurrent and recursive neural networks process hierarchical structure (extended abstract) (2018) IJCAI; Jean, S., Cho, K., Memisevic, R., Bengio, Y., On using very large target vocabulary for neural machine translation (2015) ACL; Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N., Wu, Y., (2016) Exploring the limits of language modeling, , CoRR abs/1602.02410; Kordopatis-Zilos, G., Papadopoulos, S., Kompatsiaris, Y., Geotagging text content with language models and feature mining (2017) Proceedings of the IEEE, 105, pp. 1971-1986; Krause, B., Kahembwe, E., Murray, I., Renals, S., (2019) Dynamic evaluation of transformer language models, , CoRR abs/1904.08378; Kushman, N., Zettlemoyer, L. S., Barzilay, R., Artzi, Y., Learning to automatically solve algebra word problems (2014) ACL; Marcus, G., (2018) Deep learning: A critical appraisal, , CoRR abs/1801.00631; Merity, S., Keskar, N. S., Socher, R., (2017) Regularizing and optimizing lstm language models, , ArXiv abs/1708.02182; Morin, F., Bengio, Y., Hierarchical probabilistic neural network language model (2005) AISTATS; O'Hare, N., Murdock, V., Modeling locations with social media (2012) Information Retrieval, 16, pp. 30-62; Pennington, J., Socher, R., Manning, C. D., Glove: Global vectors for word representation (2014) EMNLP; Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., (2019) Language models are unsupervised multitask learners; Roy, S., Roth, D., Solving general arithmetic word problems (2015) EMNLP; Smart, P. D., Jones, C. B., Twaroch, F. A., Multisource toponym data integration and mediation for a metagazetteer service (2010) GIScience; Spithourakis, G. P., Riedel, S., (2018) Numeracy for language models: Evaluating and improving their ability to predict numbers, , CoRR abs/1805.08154; Spithourakis, G. P., Augenstein, I., Riedel, S., Numerically grounded language models for semantic error correction (2016) EMNLP; Tobler, W. R., (1970) A computer movie simulating urban growth in the detroit region; Yang, Z., Dai, Z., Salakhutdinov, R. R., Cohen, W. W., (2018) Breaking the softmax bottleneck: A high-rank rnn language model, , CoRR abs/1711.03953; Zaremba, W., Sutskever, I., Vinyals, O., (2014) Recurrent neural network regularization, , CoRR abs/1409.2329","Association for the Advancement of Artificial Intelligence","34th AAAI Conference on Artificial Intelligence, AAAI 2020","7 February 2020 through 12 February 2020",,166426,Conference Paper,"Final","",Scopus,2-s2.0-85106687657
"Chen K., Huang Q., Palangi H., Smolensky P., Forbus K.D., Gao J.","57205545957;55233543400;26647742200;6602511111;7003585370;55702627000;","Mapping natural-language problems to formal-language solutions using structured neural representations",2020,"37th International Conference on Machine Learning, ICML 2020","PartF168147-2",,,"1544","1553",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105153943&partnerID=40&md5=021a240dc88634099a98164553961ddf","Generating formal-language programs represented by relational tuples, such as Lisp programs or mathematical operations, to solve problems stated in natural language is a challenging task because it requires explicitly capturing discrete symbolic structural information implicit in the input. However, most general neural sequence models do not explicitly capture such structural information, limiting their performance on these tasks. In this paper, we propose a new encoder-decoder model based on a structured neural representation, Tensor Product Representations (TPRs), for mapping Natural-language problems to Formal-language solutions, called TPN2F. The encoder of TP-N2F employs TPR 'binding' to encode natural-language symbolic structure in vector space and the decoder uses TPR 'unbinding' to generate, in symbolic space, a sequential program represented by relational tuples, each consisting of a relation (or operation) and a number of arguments. TP-N2F considerably outperforms LSTM-based seq2seq models on two benchmarks and creates new state-of-the-art results. Ablation studies show that improvements can be attributed to the use of structured TPRs explicitly in both the encoder and decoder. Analysis of the learned structures shows how TPRs enhance the interpretability of TP-N2F. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"Decoding; Formal languages; LISP (programming language); Machine learning; Mapping; Signal encoding; Vector spaces; Encoder-decoder; Interpretability; Mathematical operations; Natural languages; Neural representations; Sequential programs; State of the art; Structural information; Long short-term memory","Amini, A., Gabriel, S., Lin, P., Kedziorski, R. K., Choi, Y., Hajishirzi, H., Mathqa: Towards interpretable math word problem solving with operation-based formalisms (2019) NACCL; Bednarek, J., Piaskowski, K., Krawiec, K., (2019) Ain't nobody got time for coding: Structure-aware program synthesis from natural language, , arXiv.org; Cai, D., Lam, W., (2019) Core semantic frst: A top-down approach for amr parsing, , arXiv:1909.04303; Chen, K., Forbus, K. D., Action recognition from skeleton data via analogical generalization over qualitative representations (2018) Thirty-Second AAAI Conference; Chen, K., Rabkina, I., McLure, M. D., Forbus, K. D., Human-like sketch object recognition via analogical learning (2019) Thirty-Third AAAI Conference, 33, pp. 1336-1343; Crouse, M., McFate, C., Forbus, K. D., Learning from unannotated qa pairs to analogically disanbiguate and answer questions (2018) Thirty-Second AAAI Conference; Forbus, K., Liang, C., Rabkina, I., Representation and computation in cognitive models (2017) Top Cognitive System; Gao, J., Galley, M., Li, L., Neural approaches to conversational ai (2019) Foundations and Trends R in Information Retrieval, 13 (2-3), pp. 127-298; Goldin-Meadow, S., Gentner, D., (2003) Language in mind: Advances in the study of language and thought, , MIT Press; Huang, Q., Smolensky, P., He, X., Wu, O., Deng, L., Tensor product generation networks for deep nlp modeling (2018) NAACL; Huang, Q., Deng, L., Wu, D., Liu, c., He, X., Attentive tensor product learning (2019) Thirty-Third AAAI Conference, 33; Kamath, A., Das, R., A survey on semantic parsing (2019) AKBC; Kingma, D. P., Ba, J., (2017) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Langley, P., Crafting papers on machine learning (2000) Proceedings of the 17th International Conference on Machine Learning (ICML 2000), pp. 1207-1216. , Langley, P. (ed), Stanford, CA, Morgan Kaufmann; Lee, K., Palangi, H., Chen, X., Hu, H., Gao, J., (2019) Learning visual relation priors for image-text matching and image captioning with neural scene graph generators, , http://arxiv.org/abs/1909.09953, abs/1909.09953; Lee, M., He, X., Yih, W.-t., Gao, J., Deng, L., Smolensky, P., Reasoning in vector space: An exploratory study of question answering (2016) ICLR; Liao, Y., Bing, L., Li, P., Shi, S., Lam, W., Zhang, T., Core semantic frst: A top-down approach for amr parsing (2018) EMNLP, pp. 3855-3864; Luong, M.-T., Pham, H., Manning, C. D., Effective approaches to attention-based neural machine translation (2015) EMNLP, pp. 533-536; Martin, A. E., A compositional neural architecture for language (2020) Journal of Cognitive Neuroscience; Palangi, H., Smolensky, P., He, X., Deng, L., Questionanswering with grammatically-interpretable representations (2018) AAAI; Polosukhin, I., Skidanov, A., Neural program search: Solving programming tasks from description and examples (2018) ICLR workshop; Roads, B., Love, B., (2019) Learning as the unsupervised alignment of conceptual systems, , arXiv preprint arXiv:1906.09012; Rumelhart, D. E., Hinton, G. E., Williams, R. J., Learning internal representations by error propagation (1986) Parallel distributed processing: Explorations in the microstructure of cognition, 1, pp. 318-362. , Rumelhart, D. E., McClelland, J. L., and the PDP Group (eds), MIT press, Cambridge, MA; Schlag, I., Schmidhuber, J., Learning to reason with third order tensor products (2018) Neural Information Processing Systems; Smolensky, P., Tensor product variable binding and the representation of symbolic structures in connectionist networks (1990) Artifcial Intelligence, 46, pp. 159-216; Smolensky, P., Lee, M., He, X., Yih, W.-t., Gao, J., Deng, L., (2016) Basic reasoning with tensor product representations, , arXiv preprint arXiv:1601.02745",,"37th International Conference on Machine Learning, ICML 2020","13 July 2020 through 18 July 2020",,168147,Conference Paper,"Final","",Scopus,2-s2.0-85105153943
"Liu W., Tang J., Liang X., Cai Q.","57221156044;57216618053;55926362100;25639729200;","Heterogeneous graph reasoning for knowledge-grounded medical dialogue system",2021,"Neurocomputing","442",,,"260","268",,,"10.1016/j.neucom.2021.02.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102968935&doi=10.1016%2fj.neucom.2021.02.021&partnerID=40&md5=6add2adafb53cee8074009061704a920","Beyond the common difficulties faced in task-oriented dialogue system, medical dialogue has recently attracted increasing attention due to its huge application potential while posing more challenges in reasoning over medical domain knowledge and logic. Existing works resort to neural language models for dialogue embedding and neglect the explicit logical reasoning, leading to poor explainable and generalization ability. In this work, we propose an explainable Heterogeneous Graph Reasoning (HGR) model to unify the relational dialogue context understanding and entity-correlation reasoning into a heterogeneous graph structure. HGR encodes entity context according to the corresponding utterance and deduces next response after fusing the underlying medical knowledge with entity context by attentional graph propagation. To push forward the future research on expert-sensitive task-oriented dialogue system, we first release a large-scale Medical Dialogue Consultant benchmark (MDG-C) with 16 Gastrointestinal diseases for evaluating consultant capability and a Medical Dialogue Diagnosis benchmark (MDG-D) with 6 diseases for measuring diagnosis capability of models, respectively. Extensive experiments on both MDG-C and MDG-D benchmarks demonstrate the superiority of our HGR over state-of-the-art knowledge grounded approaches in general fields of medical dialogue system. © 2021 Elsevier B.V.","Deep learning; Dialogue system; Graph reasoning","Deep learning; Diagnosis; Deep learning; Dialogue systems; Domain knowledge; Embeddings; Entity contexts; Graph reasoning; Heterogeneous graph; Language modeling; Medical domains; Task-oriented; Speech processing; Article; automated reasoning; benchmarking; deep learning; heterogeneous graph reasoning; human; information processing; medical dialogue system; model; priority journal","Dodge, J., Gane, A., Zhang, X., Bordes, A., Chopra, S., Miller, A.H., Szlam, A., Weston, J., Evaluating prerequisite qualities for learning end-to-end dialog systems (2016) 4th International Conference on Learning Representations, ICLR 2016; Bordes, A., Boureau, Y., Weston, J., Learning end-to-end goal-oriented dialog (2017) 5th International Conference on Learning Representations, ICLR; Yan, Z., Duan, N., Chen, P., Zhou, M., Zhou, J., Li, Z., Building task-oriented dialogue systems for online shopping (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence; Tang, K.-F., Kao, H.-C., Chou, C.-N., Chang, E.Y., Inquire and diagnose: Neural symptom checking ensemble using deep reinforcement learning (2016), Proceedings of NIPS Workshop on Deep Reinforcement Learning; Wei, Z., Liu, Q., Peng, B., Tou, H., Chen, T., Huang, X., Wong, K.-F., Dai, X., Task-oriented dialogue system for automatic diagnosis (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 201-207; Liao, K., Liu, Q., Wei, Z., Peng, B., Chen, Q., Sun, W., Huang, X., (2004), Task-oriented dialogue system for automatic disease diagnosis via hierarchical reinforcement learning, CoRR abs/2004.14254. arXiv14254; Du, N., Wang, M., Tran, L., Lee, G., Shafran, I., Learning to infer entities, properties and their relations from clinical conversations (2019) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 4979-4990; Lin, X., He, X., Chen, Q., Tou, H., Wei, Z., Chen, T., Enhancing dialogue symptom diagnosis with global attention and symptom graph (2019) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 5033-5042; Xu, L., Zhou, Q., Gong, K., Liang, X., Tang, J., Lin, L., End-to-end knowledge-routed relational dialogue system for automatic diagnosis (2019) Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence; Zhang, S., Dinan, E., Urbanek, J., Szlam, A., Kiela, D., Weston, J., Personalizing dialogue agents: I have a dog, do you have pets too? (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 2204-2213; Moghe, N., Arora, S., Banerjee, S., Khapra, M.M., Towards exploiting background knowledge for building conversation systems (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2322-2332. , Association for Computational Linguistics; Dinan, E., Roller, S., Shuster, K., Fan, A., Auli, M., Weston, J., Wizard of wikipedia: knowledge-powered conversational agents (2019) 7th International Conference on Learning Representations, ICLR; Wu, W., Guo, Z., Zhou, X., Wu, H., Zhang, X., Lian, R., Wang, H., Proactive human-machine conversation with explicit conversation goal (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 3794-3804; Liu, S., Chen, H., Ren, Z., Feng, Y., Liu, Q., Yin, D., Knowledge diffusion for neural dialogue generation (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 1489-1498; Zhou, H., Young, T., Huang, M., Zhao, H., Xu, J., Zhu, X., Commonsense knowledge aware conversation generation with graph attention (2018) Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI, pp. 4623-4629; Tuan, Y.-L., Chen, Y.-N., Lee, H.-Y., DyKgChat: benchmarking dialogue generation grounding on dynamic knowledge graphs (2019) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 1855-1865; Zhang, H., Liu, Z., Xiong, C., Liu, Z., Grounded conversation generation as guided traverses in commonsense knowledge graphs (2020) Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 2031-2043; Zhou, H., Zheng, C., Huang, K., Huang, M., Zhu, X., KdConv, A Chinese multi-domain dialogue dataset towards multi-turn knowledge-driven conversation (2020) Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics; Ghazvininejad, M., Brockett, C., Chang, M., Dolan, B., Gao, J., Yih, W., Galley, M., A knowledge-grounded neural conversation model (2018) Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, pp. 5110-5117; Lian, R., Xie, M., Wang, F., Peng, J., Wu, H., Learning to select knowledge for response generation in dialog systems (2019) Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI, pp. 5081-5087; Kim, B., Ahn, J., Kim, G., Sequential latent knowledge selection for knowledge-grounded dialogue (2020) 8th International Conference on Learning Representations, ICLR; Du, N., Chen, K., Kannan, A., Tran, L., Chen, Y., Shafran, I., Extracting symptoms and their status from clinical conversations (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 915-925; Shi, X., Hu, H., Che, W., Sun, Z., Liu, T., Huang, J., Understanding medical conversations with scattered keyword attention and weak supervision from responses (2020), pp. 8838-8845. , The Thirty-Fourth AAAI Conference on Artificial Intelligence; Dhingra, B., Li, L., Li, X., Gao, J., Chen, Y.-N., Ahmed, F., Deng, L., Towards end-to-end reinforcement learning of dialogue agents for information access (2017) Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 484-495; Li, X., Chen, Y.-N., Li, L., Gao, J., Celikyilmaz, A., End-to-end task-completion neural dialogue systems (2017) Proceedings of the Eighth International Joint Conference on Natural Language Processing, pp. 733-743; Peng, B., Li, X., Gao, J., Liu, J., Wong, K.-F., Deep Dyna-Q: integrating planning for task-completion dialogue policy learning (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 2182-2192; Serban, I.V., Sordoni, A., Bengio, Y., Courville, A.C., Pineau, J., Building end-to-end dialogue systems using generative hierarchical neural network models (2016) Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 3776-3784; Linmei, H., Yang, T., Shi, C., Ji, H., Li, X., Heterogeneous graph attention networks for semi-supervised short text classification (2019) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 4821-4830; Yu, W., Zhou, J., Yu, W., Liang, X., Xiao, N., Heterogeneous graph learning for visual commonsense reasoning (2019), pp. 2765-2775. , Advances in Neural Information Processing Systems; Odmaa, B., Yunfei, Y., Zhifang, S., Damai, D., Baobao, C., Sujian, L., Hongying, Z., Preliminary study on the construction of chinese medical knowledge graph (2019) J. Chin. Inf. Process., 33 (10), pp. 1-7; Velickovic, P., Cucurull, G., Casanova, A., Romero, A., Liò, P., Bengio, Y., Graph attention networks (2018) 6th International Conference on Learning Representations, ICLR; See, A., Liu, P.J., Manning, C.D., Get to the point: summarization with pointer-generator networks (2017) Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1073-1083; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) 3rd International Conference on Learning Representations, ICLR; Chen, B., Cherry, C., A systematic comparison of smoothing techniques for sentence-level BLEU (2014), pp. 362-367. , Proceedings of the Ninth Workshop on Statistical Machine Translation; Luo, R., Xu, J., Zhang, Y., Ren, X., Sun, X., Pkuseg: A toolkit for multi-domain chinese word segmentation, Arxiv abs/1906.11455; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Gardner, M., Grus, J., Neumann, M., Tafjord, O., Dasigi, P., Liu, N.F., Peters, M., Zettlemoyer, L., AllenNLP A deep semantic natural language processing platform (2018) Proceedings of Workshop for NLP Open Source Software (NLP-OSS) Melbourne, Australia, pp. 1-6",,,,,,Article,"Final","",Scopus,2-s2.0-85102968935
"Chen Q., Lamoreaux A., Wang X., Durrett G., Bastani O., Dillig I.","57217225561;57223910991;57026634100;6504004627;56786340300;22936636100;","Web question answering with neurosymbolic program synthesis",2021,"Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)",,,,"328","343",,,"10.1145/3453483.3454047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108908770&doi=10.1145%2f3453483.3454047&partnerID=40&md5=6bc6beaf397478142d133bc74fc766ff","In this paper, we propose a new technique based on program synthesis for extracting information from webpages. Given a natural language query and a few labeled webpages, our method synthesizes a program that can be used to extract similar types of information from other unlabeled webpages. To handle websites with diverse structure, our approach employs a neurosymbolic DSL that incorporates both neural NLP models as well as standard language constructs for tree navigation and string manipulation. We also propose an optimal synthesis algorithm that generates all DSL programs that achieve optimal F1 score on the training examples. Our synthesis technique is compositional, prunes the search space by exploiting a monotonicity property of the DSL, and uses transductive learning to select programs with good generalization power. We have implemented these ideas in a new tool called WebQA and evaluate it on 25 different tasks across multiple domains. Our experiments show that WebQA significantly outperforms existing tools such as state-of-the-art question answering models and wrapper induction systems. © 2021 ACM.","Program Synthesis; Programming by Example; Web Information Extraction","Air navigation; Computer programming languages; Digital subscriber lines; Natural language processing systems; Extracting information; Language constructs; Monotonicity property; Natural language queries; Optimal synthesis; Question Answering; Synthesis techniques; Transductive learning; Websites","Agarwal, R., Srikant, R., Fast algorithms for mining association rules (1994) Proc. Of the 20th Vldb Conference., pp. 487-499. , htps://doi.org/10.5555/645920.672836; Anderson, G., Verma, A., Dillig, I., Chaudhuri, S., Neurosymbolic reinforcement learning with formally verifed exploration (2020) NeurIPS; Andreas, J., Rohrbach, M., Darrell, T., Klein, D., Learning to compose neural networks for question answering (2016) Naacl, , htps://doi.org/10.18653/v1/N16-1181; Andreas, J., Rohrbach, M., Darrell, T., Klein, D., Neural module networks (2016) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 39-48. , htps://doi.org/10.1109/CVPR.2016.12; Anton, T., Xpath-wrapper induction by generalizing tree traversal patterns (2005) Lernen, Wissensentdeckung und Adaptivitt (LWA) 2005, Gi Workshops, Saarbrcken., pp. 126-133; Baik, C., Jin, Z., Cafarella, M., Jagadish, H.V., Duoquest: A dual-specifcation system for expressive sql queries (2020) Proceedings of the 2020 Acm Sigmod International Conference on Management of Data (SIGMOD '20), pp. 2319-2329. , htps://doi.org/10.1145/3318464.3389776, Association for Computing Machinery, New York, NY, USA; Baldini Soares, L., FitzGerald, N., Ling, J., Kwiatkowski, T., (2019) Matching the Blanks: Distributional Similarity for Relation Learning., , htps://doi.org/10.18653/v1/P19-1279; Barman, S., Chasins, S., Bodik, R., Gulwani, S., Ringer: Web automation by demonstration (2016) Proceedings of the 2016 Acm Sigplan International Conference on Object-Oriented Programming, Systems, Languages, and Applications., pp. 748-764. , htps://doi.org/10.1145/3022671.2984020; Bornholt, J., Torlak, E., Grossman, D., Ceze, L., (2016) Optimizing Synthesis with Metasketches (POPL), pp. 775-788. , htps://doi.org/10.1145/2914770.2837666; Chang, C.-H., Lui, S.-C., Iepad: Information extraction based on pattern discovery (2001) Proceedings of the 10th International Conference on World Wide Web., pp. 681-688. , htps://doi.org/10.1145/371920.372182; Chasins, S., Barman, S., Bodik, R., Gulwani, S., Browser record and replay as a building block for end-user web automation tools (2015) Proceedings of the 24th International Conference on World Wide Web., pp. 179-182. , htps://doi.org/10.1145/2740908.2742849; Chasins, S., Bodik, R., Skip blocks: Reusing execution history to accelerate web scripts (2017) Proceedings of the Acm on Programming Languages 1, Oopsla, pp. 1-28. , htps://doi.org/10.1145/3133875, 2017; Chasins, S.E., Mueller, M., Bodik, R., Rousillon: Scraping distributed hierarchical web data (2018) Proceedings of the 31st Annual Acm Symposium on User Interface Software and Technology., pp. 963-975; Chen, Q., Wang, X., Ye, X., Durrett, G., Dillig, I., Multi-modal synthesis of regular expressions (2020) Proceedings of the 41st Acm Sigplan Conference on Programming Language Design and Implementation (PLDI 2020), pp. 487-502. , htps://doi.org/10.1145/3385412.3385988, Association for Computing Machinery, New York, NY, USA; Chen, W., Wang, H., Chen, J., Zhang, Y., Wang, H., Li, S., Zhou, X., Yang Wang, W., Tabfact: A large-scale dataset for table-based fact verifcation (2020) International Conference on Learning Representations (ICLR), , Addis Ababa, Ethiopia; Chen, Y., Martins, R., Feng, Y., Maximal multi-layer specifcation synthesis (2019) Proceedings of the 2019 27th Acm Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2019), pp. 602-612. , htps://doi.org/10.1145/3338906.3338951, Association for Computing Machinery, New York, NY, USA; Choi, E., Kwiatkowski, T., Zettlemoyer, L., Scalable semantic parsing with partial ontologies (2015) Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 1311-1320. , htps://doi.org/10.3115/v1/P15-1127, Association for Computational Linguistics, Beijing, China; Crescenzi, V., Mecca, G., Merialdo, P., Roadrunner: Towards automatic data extraction from large web sites (2001) Vldb, 1, pp. 109-118. , htps://doi.org/10.5555/645927.672370; Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., Bert: Pre-training of deep bidirectional transformers for language understanding (2019) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186. , htps://doi.org/10.18653/v1/N19-1423, Association for Computational Linguistics, Minneapolis, Minnesota; Dietterich, T.G., Ensemble methods in machine learning (2000) International Workshop on Multiple Classifer Systems, pp. 1-15. , htps://doi.org/10.5555/648054.743935, Springer; Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., Gardner, M., Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs (2019) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 2368-2378. , htps://doi.org/10.18653/v1/N19-1246, Association for Computational Linguistics, Minneapolis, Minnesota; Ellis, K., Ritchie, D., Solar-Lezama, A., Tenen-Baum, J., Learning to infer graphics programs from hand-drawn images (2018) Advances in Neural Information Processing Systems., pp. 6059-6068; Etzioni, O., Banko, M., Soderland, S., Weld, D.S., Open information extraction from the web (2008) Commun. Acm, 51 (12), pp. 68-74. , htps://doi.org/10.1145/1409360.1409378, Dec. 2008); Freitag, D., Machine learning for information extraction in informal domains (2000) Mach. Learn., 39 (2-3), pp. 169-202. , May 2000); Gaunt, A.L., Brockschmidt, M., Kushman, N., Tarlow, D., Diferentiable programs with neural libraries (2017) International Conference on Machine Learning., pp. 1213-1222; Gavran, I., Darulova, E., Majumdar, R., Interactive synthesis of temporal specifcations from examples and natural language Proc. Acm Program. Lang. 4, Oopsla, 2020. , htps://doi.org/10.1145/3428269, Nov. 2020; Gulhane, P., Madaan, A., Mehta, R., Ra-Mamirtham, J., Rastogi, R., Satpal, S., Sengamedu, S.H., Tiwari, C., Web-scale information extraction with vertex (2011) 2011 Ieee 27th International Conference on Data Engineering, pp. 1209-1220. , htps://doi.org/10.1109/ICDE.2011.5767842; Gulwani, S., Automating string processing in spreadsheets using input-output examples (2011) Proceedings of the 38th Annual Acm SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL), pp. 317-330. , htps://doi.org/10.1145/1926385.1926423; Gupta, N., Lin, K., Roth, D., Singh, S., Gardner, M., Neural module networks for reasoning over text (2020) Iclr; Han, X., Zhu, H., Yu, P., Wang, Z., Yao, Y., Liu, Z., Sun, M., Fewrel: A large-scale supervised few-shot relation classifcation dataset with state-of-the-Art evaluation (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 4803-4809. , htps://doi.org/10.18653/v1/D18-1514, Association for Computational Linguistics, Brussels, Belgium; Honnibal, M., Montani, I., Van Landeghem, S., Boyd, A., (2020) SpaCy: Industrial-strength Natural Language Processing in Python., , htps://doi.org/10.5281/zenodo.1212303; Hsu, C.-N., Dung, M.-T., Generating fnite-state transducers for semi-structured data extraction from the web (1998) Information Systems, 23 (8), pp. 521-538. , htps://doi.org/10.5555/306766.306775, 1998; Hu, Q., D'Antoni, L., Syntax-guided synthesis with quantitative syntactic objectives (2018) International Conference on Computer Aided Verifcation, pp. 386-403. , htps://doi.org/10.1007/978-3-319-96145-3-21, Springer; Inala, J.P., Yang, Y., Paulos, J., Pu, Y., Bastani, O., Kumar, V., Rinard, M., Solar-Lezama, A., Neurosymbolic transformers for multi-Agent communication (2020) NeurIPS; Iyer, A., Jonnalagedda, M., Parthasarathy, S., Rad-Hakrishna, A., Rajamani, S.K, Synthesis and machine learning for heterogeneous extraction (2019) Proceedings of the 40th Acm Sigplan Conference on Programming Language Design and Implementation., pp. 301-315. , htps://doi.org/10.1145/3314221.3322485; Kushmerick, N., Weld, D.S., Doorenbos, R., Wrapper induction for information extraction (1997) University of Washington Washington; Le, V., Gulwani, S., (2014) FlashExtract: A Framework for Data Extraction by Examples (PLDI), pp. 542-553. , htps://doi.org/10.1145/2666356.2594333; Yuchen Lin, B., Sheng, Y., Vo, N., Tata, S., Freedom: A transferable neural architecture for structured information extraction on web documents (2020) Proceedings of the 26th Acm Sigkdd International Conference on Knowledge Discovery Data Mining, , htps://doi.org/10.1145/3394486.3403153, Aug 2020; Lockard, C., Shiralkar, P., Luna Dong, X., Hajishirzi, H., Zeroshotceres: Zero-shot relation extraction from semi-structured webpages (2020) Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 8105-8117. , htps://doi.org/10.18653/v1/2020.acl-main.721, Association for Computational Linguistics, Online; Mao, J., Gan, C., Kohli, P., Tenenbaum, J.B., Wu, J., The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision (2019) Iclr; Mintz, M., Bills, S., Snow, R., Jurafsky, D., Distant supervision for relation extraction without labeled data (2009) Proceedings of the Joint Conference of the 47th Annual Meeting of the Acl and the 4th International Joint Conference on Natural Language Processing of the Afnlp, pp. 1003-1011. , htps://www.aclweb.org/anthology/P09-1113, Association for Computational Linguistics, Suntec, Singapore; Muslea, I., Minton, S., Knoblock, C., A hierarchical approach to wrapper induction (1999) Proceedings of the Third Annual Conference on Autonomous Agents., pp. 190-197. , htps://doi.org/10.1145/301136.301191; Opitz, D., MacLin, R., Popular ensemble methods: An empirical study (1999) Journal of Artifcial Intelligence Research, 11, pp. 169-198. , htps://doi.org/10.1613/jair.614, 1999; Pasupat, P., Liang, P., Zero-shot entity extraction from web pages (2014) Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 391-401. , htps://doi.org/10.3115/v1/P14-1037, Association for Computational Linguistics, Baltimore, Maryland; Pasupat, P., Liang, P., Compositional semantic parsing on semi-structured tables (2015) Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 1470-1480. , htps://doi.org/10.3115/v1/P15-1142, Association for Computational Linguistics, Beijing, China; Patwardhan, S., Rilof, E., Efective information extraction with semantic afnity patterns and relevant regions (2007) Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pp. 717-727. , htps://www.aclweb.org/anthology/D07-1075, Association for Computational Linguistics, Prague, Czech Republic; Pennington, J., Socher, R., Manning, C., Glove: Global vectors for word representation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543. , htps://doi.org/10.3115/v1/D14-1162, Association for Computational Linguistics, Doha, Qatar; Qian, Y., Santus, E., Jin, Z., Guo, J., Barzilay, R., Graphie: A graph-based framework for information extraction (2019) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,Volume 1 (Long and Short Papers), pp. 751-761. , htps://doi.org/10.18653/v1/N19-1082, Association for Computational Linguistics, Minneapolis, Minnesota; Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P., Squad: 100,000+ questions for machine comprehension of text (2016) Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 2383-2392. , htps://doi.org/10.18653/v1/D16-1264, Association for Computational Linguistics, Austin, Texas; Raza, M., Gulwani, S., Web data extraction using hybrid program synthesis: A combination of top-down and bottom-up inference (2020) Proceedings of the 2020 Acm Sigmod International Conference on Management of Data., pp. 1967-1978. , htps://doi.org/10.1145/3318464.3380608; Raza, M., Gulwani, S., Milic-Frayling, N., Compositional program synthesis from natural language and examples (2015) Proceedings of the 24th International Conference on Artifcial Intelligence (IJCAI'15), pp. 792-800. , htps://doi.org/10.5555/2832249.2832359, AAAI Press; Reimers, N., Gurevych, I., Sentence-bert: Sentence embeddings using siamese bert-networks (2019) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, , htps://arxiv.org/abs/1908.10084, Association for Computational Linguistics; Shah, A., Zhan, E., Sun, J.J., Verma, A., Yue, Y., Chaudhuri, S., Learning diferentiable programs with admissible neural heuristics (2020) NeurIPS; Valkov, L., Chaudhari, D., Srivastava, A., Sutton, C., Chaudhuri, S., Houdini: Lifelong learning as program synthesis (2018) Advances in Neural Information Processing Systems., pp. 8687-8698; Wang, X., Dillig, I., Singh, R., Program synthesis using abstraction refnement (2017) Proceedings of the Acm on Programming Languages 2, Popl, pp. 1-30. , 2017; Wang, X., Dillig, I., Singh, R., Synthesis of data completion scripts using fnite tree automata (2017) Proceedings of the Acm on Programming Languages 1, Oopsla, pp. 1-26. , htps://doi.org/10.1145/3133886, 2017; Wang, X., Gulwani, S., Singh, R., Fidex: Filtering spreadsheet data using examples (2016) Proceedings of the 2016 Acm Sigplan International Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA), pp. 195-213; Wu, S., Hsiao, L., Cheng, X., Hancock, B., Rekatsi-Nas, T., Levis, P., Ré, C., Fonduer: Knowledge base construction from richly formatted data (2018) Proceedings of the 2018 International Conference on Management of Data (SIGMOD '18), pp. 1301-1316. , Association for Computing Machinery, New York, NY, USA; Young, H., Bastani, O., Naik, M., (2019) Learning Neu-rosymbolic Generative Models Via Program Synthesis; Zanda, M., Brown, G., A study of semi-supervised generative ensembles (2009) Multiple Classifer Systems, pp. 242-251. , htps://doi.org/10.1007/978-3-642-02326-2-25, Jón Atli Benedik-tsson, Josef Kittler, and Fabio Roli (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg; Zhu, X., (2005) Semi-Supervised Learning Literature Survey, , Technical Report 1530. Computer Sciences, University of Wisconsin-Madison","ACM SIGPLAN","42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, PLDI 2021","20 June 2021 through 25 June 2021",,169620,Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85108908770
"Škrlj B., Martinc M., Lavrač N., Pollak S.","57191625180;57193521100;7004388979;55543643800;","autoBOT: evolving neuro-symbolic representations for explainable low resource text classification",2021,"Machine Learning","110","5",,"989","1028",,,"10.1007/s10994-021-05968-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104608374&doi=10.1007%2fs10994-021-05968-x&partnerID=40&md5=59b5fd0f7b23614c0337e650f6050d25","Learning from texts has been widely adopted throughout industry and science. While state-of-the-art neural language models have shown very promising results for text classification, they are expensive to (pre-)train, require large amounts of data and tuning of hundreds of millions or more parameters. This paper explores how automatically evolved text representations can serve as a basis for explainable, low-resource branch of models with competitive performance that are subject to automated hyperparameter tuning. We present autoBOT (automatic Bags-Of-Tokens), an autoML approach suitable for low resource learning scenarios, where both the hardware and the amount of data required for training are limited. The proposed approach consists of an evolutionary algorithm that jointly optimizes various sparse representations of a given text (including word, subword, POS tag, keyword-based, knowledge graph-based and relational features) and two types of document embeddings (non-sparse representations). The key idea of autoBOT is that, instead of evolving at the learner level, evolution is conducted at the representation level. The proposed method offers competitive classification performance on fourteen real-world classification tasks when compared against a competitive autoML approach that evolves ensemble models, as well as state-of-the-art neural language models such as BERT and RoBERTa. Moreover, the approach is explainable, as the importance of the parts of the input space is part of the final solution yielded by the proposed optimization procedure, offering potential for meta-transfer learning. © 2021, The Author(s).","AutoML; Natural language processing; Neuro-symbolic computing; Representation learning","Classification (of information); Computational linguistics; Evolutionary algorithms; Graph algorithms; Graphic methods; Knowledge representation; Transfer learning; Classification performance; Classification tasks; Competitive performance; Large amounts of data; Optimization procedures; Relational features; Sparse representation; Symbolic representation; Text processing","Agarwal, B., Mittal, N., Text classification using machine learning methods - A survey (2014) Roceedings of the Second International Conference on Soft Computing for Problem Solving (Socpros 2012), 2012, pp. 701-709. , December 28-30, pringer; Belinkov, Y., Glass, J., Analysis methods in neural language processing: A survey (2019) Transactions of the Association for Computational Linguistics, 7, pp. 49-72; Beyer, H.G., Schwefel, H.P., Wegener, I., How to analyse evolutionary algorithms (2002) Theoretical Computer Science, 287 (1), pp. 101-130; Bird, S., Klein, E., Loper, E., (2009) Natural language processing with Python: Analyzing text with the natural language toolkit, , O’Reilly Media Inc, California; Bougouin, A., Boudin, F., Daille, B., TopicRank: Graph-based topic ranking for keyphrase extraction (2013) Proceedings of the Sixth International Joint Conference on Natural Language Processing, pp. 543-551. , Asian Federation of Natural Language Processing, Nagoya, Japan; Campos, R., Mangaravite, V., Pasquali, A., Jorge, A.M., Nunes, C., Jatowt, A., A text feature based automatic keyword extraction method for single documents (2018) Advances in Information Retrieval, pp. 684-691. , Pasi G, Piwowarski B, Azzopardi L, Hanbury A, (eds), Springer, Germany; Chambers, L.D., (2000) The Practical Handbook of Genetic Algorithms: Applications, , CRC Press, Florida; Chang, C.C., Lin, C.J., LIBSVM: A library for support vector machines (2011) ACM Transactions on Intelligent Systems and Technology, 2 (3), pp. 1-27; Davis, L., (1991) Handbook of Genetic Algorithms, , (ed), Chapman & Hall, London; de Rainville, F.M., Fortin, F.A., Gardner, M.A., Parizeau, M., Gagné, C., Deap: A python framework for evolutionary algorithms (2012) Proceedings of the 14Th Annual Conference Companion on Genetic and Evolutionary Computation, pp. 85-92; Deb, K., Jain, H., An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part I: Solving problems with box constraints (2013) IEEE transactions on evolutionary computation, 18 (4), pp. 577-601; Demšar, J., Statistical comparisons of classifiers over multiple data sets (2006) Journal of Machine Learning Research., 7, pp. 1-30; Denysiuk, R., Gaspar-Cunha, A., Delbem, A.C., Neuroevolution for solving multiobjective knapsack problems (2019) Expert Systems with Applications, 116, pp. 65-77; Devlin, J., Chang, M.W., Lee, K., Toutanova, K., BERT: Pre-training of deep bidirectional transformers for language understanding (2019) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186. , Minneapolis, Minnesota, Association for Computational Linguistics; Dorronsoro, B., Pinel, F., Combining machine learning and genetic algorithms to solve the independent tasks scheduling problem (2017) 2017 3Rd IEEE International Conference on Cybernetics (CYBCONF), pp. 1-8. , IEEE; (2017) D., , http://archive.ics.uci.edu/ml, Graff, C, UCI Machine Learning Repository; Eiben, A.E., Aarts, E.H., van Hee, K.M., Global convergence of genetic algorithms: A Markov chain analysis (1990) Proceedings of the International Conference on Parallel Problem Solving from Nature, pp. 3-12. , Springer; El-Beltagy, S.R., Rafea, A., KP-Miner: A keyphrase extraction system for English and Arabic documents (2009) Information Systems, 34 (1), pp. 132-144; English, T.M., Evaluation of evolutionary and genetic optimizers: No free lunch (1996) Evolutionary Programming, pp. 163-169; Fellbaum, C., WordNet (2012) The Encyclopedia of Applied Linguistics; Feurer, M., Klein, A., Eggensperger, K., Springenberg, J.T., Blum, M., Hutter, F., Auto-sklearn: Efficient and robust automated machine learning (2019) Textitautomated Machine Learning, pp. 113-134. , Springer; Friedman, J., Hastie, T., Tibshirani, R., (2001) The Elements of Statistical Learning, 1. , Springer Series, New York, USA: Statistics; Gijsbers, P., Vanschoren, J., Gama: Genetic automated machine learning assistant (2019) Journal of Open Source Software, 4 (33), p. 1132; Greene, D., Cunningham, P., Practical solutions to the problem of diagonal dominance in kernel document clustering (2006) Proceedings of the Twenty-Third International Conference (ICML 2006), pp. 377-384. , . In: W.W. Cohen, A.W. Moore (eds.) Machine Learning, Pittsburgh, Pennsylvania, USA, June 25-29, 2006, ACM International Conference Proceeding Series (pp,). ACM; Hajj, N., Rizk, Y., Awad, M., A subjectivity classification framework for sports articles using improved cortical algorithms (2019) Neural Computing and Applications, 31 (11), pp. 8069-8085; He, Y., Lin, J., Liu, Z., Wang, H., Li, L.J., Han, S., Amc: Automl for model compression and acceleration on mobile devices (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 784-800; Ishibuchi, H., Tsukamoto, N., Nojima, Y., Evolutionary many-objective optimization: A short review (2008) Proceedings of the 2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence), pp. 2419-2426. , . In:, (pp,). IEEE; Jennings, P.C., Lysgaard, S., Hummelshøj, J.S., Vegge, T., Bligaard, T., Genetic algorithms for computational materials discovery accelerated by machine learning (2019) NPJ Computational Materials, 5 (1), pp. 1-6; Jing, K., Xu, J., (2019) A Survey on Neural Network Language Models; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Borchers, A., In-datacenter performance analysis of a tensor processing unit (2017) Proceedings of the 44Th Annual International Symposium on Computer Architecture, pp. 1-12; Khosrovian, K., Pfahl, D., Garousi, V., Gensim 2.0: A customizable process simulation model for software process evaluation (2008) Proceedings of the International Conference on Software Process, pp. 294-306. , Springer; Kipf, T.N., Welling, M., Semi-supervised classification with graph convolutional networks. In: Proceedings of the 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings (2017) Openreview.Net; Komer, B., Bergstra, J., Eliasmith, C., Hyperopt-sklearn: Automatic hyperparameter configuration for scikit-learn (2014) ICML Workshop on Automl, p. 50. , Citeseer; Kotthoff, L., Thornton, C., Hoos, H.H., Hutter, F., Leyton-Brown, K., Auto-WEKA 2.0?: Automatic model selection and hyperparameter optimization in WEKA (2017) Journal of Machine Learning Research, 18 (25), pp. 1-5; Kowsari, K., Jafari Meimandi, K., Heidarysafa, M., Mendu, S., Barnes, L., Brown, D., Text classification algorithms: A survey (2019) Information, 10 (4), p. 150; Lavrač, N., Škrlj, B., Robnik-Šikonja, M., Propositionalization and embeddings: two sides of the same coin (2020) Machine Learning, 109 (7), pp. 1465-1507; Le, Q.V., Mikolov, T., (2014) Distributed representations of sentences and documents. In: Proceedings of the 31th International Conference on Machine Learning, pp. 1188-1196. , ICML 2014, Beijing, China, 21-26 June 2014, JMLR Workshop and Conference Proceedings vol. 32 (pp,). JMLR.org; Li, X., Roth, D., Learning question classifiers (2002) Proceedings of the 19Th International Conference on Computational Linguistics (COLING 2002), 1, pp. 1-7; Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Stoyanov, V., (2019) A Robustly Optimized BERT Pretraining Approach, , RoBERTa; Madrid, J., (2019) Autotext: Automl for Text Classification, , https://inaoe.repositorioinstitucional.mx/jspui/bitstream/1009/1950/1/MadridPJG.pdf; Manning, C.D., Raghavan, P., Schütze, H., Scoring, term weighting and the vector space model (2008) Introduction to information retrieval, 100, pp. 2-4; Martinc, M., Škrjanec, I., Zupan, K., Pollak, S., (2017) Pan, p. 2017. , Author profiling - gender and language variety prediction. In, Working Notes Papers of the CLEF; Mihalcea, R., Tarau, P., TextRank: Bringing order into text (2004) Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pp. 404-411. , Barcelona, Spain, Association for Computational Linguistics; Mirończuk, M.M., Protasiewicz, J., A recent overview of the state-of-the-art elements of text classification (2018) Expert Systems with Applications, 106, pp. 36-54; Misra, R., Arora, P., (2019) Sarcasm Detection Using Hybrid Neural Network; Mitchell, M., (1998) An Introduction to Genetic Algorithms, , MIT Press, Cambridge, MA, USA; Mohr, F., Wever, M., Hüllermeier, E., Ml-plan: Automated machine learning via hierarchical planning (2018) Machine Learning, 107 (8), pp. 1495-1515; Moradi, M., Dorffner, G., Samwald, M., Deep contextualized embeddings for quantifying the informative content in biomedical text summarization (2020) Computer Methods and Programs in Biomedicine, 184, p. 105117; Myers, I.B., (1962) The Myers-Briggs Type Indicator: Manual, , Consulting Psychologists Press, Germany; (2013) Second Joint Conference on Lexical and Computational Semantics (*SEM), pp. 312-320. , Association for Computational Linguistics, Atlanta, Georgia, USA; Olson, R.S., Moore, J.H., Tpot: A tree-based pipeline optimization tool for automating machine learning (2019) Automated Machine Learning, pp. 151-160. , Springer; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Scikit-learn: Machine learning in Python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Pilat, M., Křen, T., Neruda, R., Asynchronous evolution of data mining workflow schemes by strongly typed genetic programming (2016) 2016 IEEE 28Th International Conference on Tools with Artificial Intelligence (ICTAI), pp. 577-584. , IEEE; Pollak, S., Coesemans, R., Daelemans, W., Lavrač, N., Detecting contrast patterns in newspaper articles by combining discourse analysis and text mining (2011) Pragmatics, Quarterly Publication of the International Pragmatics Association (IPrA)., 21 (4), pp. 647-683; Qian, M., Zhai, C., (2014), Unsupervised feature selection for multi-view clustering on text-image web news data. In: J. Li, X.S. Wang, M.N. Garofalakis, I. Soboroff, T. Suel, M. Wang (eds.) Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management CIKM (pp. 1963–1966). Shanghai, China:ACM; Rappl, G., On linear convergence of a class of random search algorithms (1989) ZAMM-Journal of Applied Mathematics and Mechanics/Zeitschrift für Angewandte Mathematik und Mechanik, 69 (1), pp. 37-45; Reif, M., Shafait, F., Dengel, A., Meta-learning for evolutionary parameter optimization of classifiers (2012) Machine Learning, 87 (3), pp. 357-380; Rose, S., Engel, D., Cramer, N., Cowley, W., (2010) Automatic keyword extraction from individual documents, pp. 1-20. , Wiley Online Library, New Jersey; Rudin, C., Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead (2019) Nature Machine Intelligence, 1 (5), pp. 206-215; Sennrich, R., Haddow, B., Birch, A., Neural machine translation of rare words with subword units (2016) Proceedings of the 54Th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1715-1725. , Berlin, Germany, Association for Computational Linguistics; Škrlj, B., Repar, A., Pollak, S., RaKUn: Rank-based keyword extraction via unsupervised learning and meta vertex aggregation (2019) International Conference on Statistical Language and Speech Processing, pp. 311-323. , Springer; Snoek, J., Larochelle, H., Adams, R.P., (2012), Practical bayesian optimization of machine learning algorithms. In: P.L. Bartlett, F.C.N. Pereira, C.J.C. Burges, L. Bottou, K.Q. Weinberger (eds.) Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012 (pp. 2960–2968), Lake Tahoe, Nevada, United States; Speer, R., Chin, J., Havasi, C., Conceptnet 5.5: An open multilingual graph of general knowledge (2017) Proceeding of the Thirty-First AAAI Conference on Artificial Intelligence, pp. 4441-4451. , Singh SP, Markovitch S, (eds), AAAI Press, San Fransisco, California, USA; Stanley, K.O., Clune, J., Lehman, J., Miikkulainen, R., Designing neural networks through neuroevolution (2019) Nature Machine Intelligence, 1 (1), pp. 24-35; Sterckx, L., Demeester, T., Deleu, J., Develder, C., Topical word importance for fast keyphrase extraction (2015) Proceedings of the 24Th International Conference on World Wide Web, pp. 121-122. , New York, ACM; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proc of the Thirty-First AAAI Conference on Artificial Intelligence, pp. 4278-4284. , Singh SP, Markovitch S, (eds), AAAI Press, San Francisco, California, USA; Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K., Auto-weka: combined selection and hyperparameter optimization of classification algorithms (2013) The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD 2013, pp. 847-855. , Dhillon IS, Koren Y, Ghani R, Senator TE, Bradley P, Parekh R, He J, Grossman RL, Uthurusamy R, (eds), ACM, Chicago, IL, USA; Vafaie, H., De Jong, K., Feature space transformation using genetic algorithms (1998) IEEE Intelligent Systems and their Applications, 13 (2), pp. 57-65; Virtanen, P., Gommers, R., Oliphant, T.E., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Bright, J., Scipy 10 Fundamental algorithms for scientific computing in Python (2020) Nature Methods, 17 (3), pp. 261-272; Wan, X., Xiao, J., Single document keyphrase extraction using neighborhood knowledge (2008) Proceedings of the AAAI Conference, 8, pp. 855-860; Transformers: State-of-the-art natural language processing. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 38–45). Association for Computational Linguistics, Online (2020) Https://Doi.Org/10.18653/V1/2020.Emnlp-Demos.6, , https://www.aclweb.org/anthology/2020.emnlp-demos.6, Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Le Scao, T., Gugger, S., Drame, M., Lhoest, Q., Rush, A; Wolpert, D.H., Macready, W.G., No free lunch theorems for optimization (1997) IEEE Transactions on Evolutionary Computation, 1 (1), pp. 67-82; Yang, C., Akimoto, Y., Kim, D.W., Udell, M., Oboe (2019) Proceedings of the 25Th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining; Yang, Z., Dai, Z., Yang, Y., Carbonell, J.G., Salakhutdinov, R., Le, Q.V., (2019), Xlnet: Generalized autoregressive pretraining for language understanding. In: H.M. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E.B. Fox, R. Garnett (eds.) Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019(pp. 5754–5764) Vancouver, BC, Canada: NeurIPS 2019; Zimmer, M., Doncieux, S., Bootstrapping q -learning for robotics from neuro-evolution results (2017) IEEE Transactions on Cognitive and Developmental Systems, 10 (1), pp. 102-119; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2018) 2018 IEEE Conference on Computer Vision and Pattern Recognition CVPR 2018, pp. 8697-8710. , Salt Lake City, UT, USA, IEEE Computer Society",,,,,,Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85104608374
"Wang Q., Hao Y., Chen F.","57216212246;55197931300;57221281500;","Deepening the IDA* algorithm for knowledge graph reasoning through neural network architecture",2021,"Neurocomputing","429",,,"101","109",,,"10.1016/j.neucom.2020.12.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098717859&doi=10.1016%2fj.neucom.2020.12.040&partnerID=40&md5=1664fc555b7f44fd3fadab33ad9243f8","Inferring missing links in Knowledge Graphs (KGs) is a key evaluation task for KG reasoning, which aims to find relations for a given entity pair. Existing research often employs the IDA* (Iterative Deepening A*) algorithm for the path discovery task owing to its efficiency and accuracy. However, it relies on heuristics to set cost functions and is also difficult to utilize useful context information in the search process. In this paper, we propose the Deep-IDA* framework which applies neural networks and reinforcement learning (RL) to empower the IDA* algorithm to tackle the path discovery problem in KG reasoning. We model KG reasoning as a Markov Decision Process (MDP) and divide our Deep-IDA* framework and the resulting path into two parts: path-finding and path-reasoning. For path-finding, we propose a policy network to model the cost from the source to a candidate location. In this process, we employ the GCN (Graph Convolutional Network) to embed the observable sub-track, then employ the LSTM (Long Short-Term Memory) to record the historical trajectory, and introduce the attention to utilize the context information, and finally form policy. For path-reasoning with the searched candidate paths passed from the former process, we employ a value network to estimate the cost from the candidate to the destination entity, using the GNN (Graph Neural Networks) to learn a message-passing algorithm that solves the path inference problem, and using the GRU (Gated Recurrent Unit) to update the historical information. Finally, the actor-learner algorithm is utilized to minimize the sum of the losses of the two parts. Experiment results on three datasets demonstrate the effectiveness and efficiency of our framework. © 2020 Elsevier B.V.","IDA* algorithm; Knowledge graph; Markov decision process; Neural network; Reinforcement learning","Convolutional neural networks; Cost benefit analysis; Cost functions; Efficiency; Graph algorithms; Inference engines; Iterative methods; Knowledge representation; Markov processes; Message passing; Network architecture; Reinforcement learning; Candidate locations; Context information; Convolutional networks; Effectiveness and efficiencies; Graph neural networks; Historical information; Markov Decision Processes; Message passing algorithm; Long short-term memory; article; attention; gated recurrent unit network; human; Markov decision process; reasoning; reinforcement learning (machine learning); short term memory","Hart, P.E., Nilsson, N.J., Raphael, B., A formal basis for the heuristic determination of minimum cost paths (1968) IEEE Trans. Syst. Sci. Cybernet., 4 (2), pp. 100-107; (2017), Xiong, Wenhan, Thien Hoang, and William Yang Wang. “Deeppath: A RL method for knowledge graph reasoning.” arXiv preprint arXiv:1707.06690; (2018), Chen, Wenhu, et al. “Variational knowledge graph reasoning.” arXiv preprint arXiv:1803.06581; (2019), Wang, Jingyuan, et al. “Empowering A* Search Algorithms with Neural Networks for Personalized Route Recommendation.” Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM; Wang, Q.I., Hao, Y., ALSTM: An attention-based long short-term memory framework for knowledge base reasoning (2020) Neurocomputing; (2017), Das, Rajarshi, et al. “Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning.” arXiv preprint arXiv:1711.05851; (2015), Vinyals, Oriol, Samy Bengio, and Manjunath Kudlur. “Order matters: Sequence to sequence for sets.” arXiv preprint arXiv:1511.06391; (1810), Jacob Devlin, Ming-Wei Chang, Kenton Lee, and KristinaToutanova.2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv04805; (2016), Seo, Minjoon, et al. “Bidirectional attention flow for machine comprehension.” arXiv preprint arXiv:1611.01603; Scarselli, F., The graph neural network model (2008) IEEE Trans. Neural Networks, 20 (1), pp. 61-80; (2015), Li, Yujia, et al. “Gated graph sequence neural networks.” arXiv preprint arXiv:1511.05493; (2014), Cho, Kyunghyun, et al. “Learning phrase representations using RNN encoder-decoder for statistical machine translation.” arXiv preprint arXiv:1406.1078; (2018), Espeholt, Lasse, et al. “Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures.” arXiv preprint arXiv:1802.01561; Sutton, R.S., Barto, A.G., Reinforcement, learning: An introduction (2018), MIT press; Wang, Q., Hao, Y., Cao, J., ADRL: An attention based deep reinforcement learning framework for knowledge graph reasoning (2020) Knowledge-Based Syst., 197. , 105910; (2019), Wu, Zonghan, et al. “A comprehensive survey on graph neural networks.” arXiv preprint arXiv:1901.00596; Bordes, A., “Translating embeddings for modeling multi-relational data.” (2013) Adv. Neural Inform. Process. Syst.; Nickel, M., Tresp, V., Kriegel, H.-P., “A Three-Way Model for Collective Learning on Multi-Relational Data.” (2011) ICML, 11; (2014), Yang, Bishan, et al. “Embedding entities and relations for learning and inference in knowledge bases.” arXiv preprint arXiv:1412.6575; Wang, Q., “Knowledge graph embedding: A survey of approaches and applications.” (2017) IEEE Trans. Knowledge Data Eng., 29 (12), pp. 2724-2743; (2014), Wang, Zhen, et al. “Knowledge graph embedding by translating on hyperplanes.” Twenty-Eighth AAAI conference on artificial intelligence; (2015), Lin, Yankai, et al. “Learning entity and relation embeddings for knowledge graph completion.” Twenty-ninth AAAI conference on artificial intelligence; (2015), Toutanova, Kristina, et al. “Representing text for joint embedding of text and knowledge bases.” Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing; (2011), Lao, Ni, Tom Mitchell, and William W. Cohen. “Random walk inference and learning in a large scale knowledge base.” Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics; (2018), Shen, Yelong, et al. “M-walk: Learning to walk over graphs using monte carlo tree search.” Advances in Neural Information Processing Systems; (2015), Neelakantan, Arvind, Benjamin Roth, and Andrew McCallum. “Compositional vector space models for knowledge base inference.”2015 AAAI spring symposium series; (2016), Das, Rajarshi, et al. “Chains of reasoning over entities, relations, and text using recurrent neural networks.” arXiv preprint arXiv:1607.01426; Williams, R.J., Simple statistical gradient-following algorithms for connectionist reinforcement learning (1992) Mach. Learn., 8 (3-4), pp. 229-256; (2018), Dettmers, Tim, et al. “Convolutional 2d knowledge graph embeddings.” Thirty-Second AAAI Conference on Artificial Intelligence; (2017), Veličković, Petar, et al. “Graph attention networks.” arXiv preprint arXiv: 1710.10903; (2010), Glorot, Xavier, and Yoshua Bengio. “Understanding the difficulty of training deep feedforward neural networks.” Proceedings of the thirteenth international conference on artificial intelligence and statistics; (2015), Lillicrap, Timothy P., et al. “Continuous control with deep reinforcement learning.” arXiv preprint arXiv:1509.02971; (2015), Mnih, Volodymyr, et al. “Human-level control through deep reinforcement learning.” Nature 518.7540: 529; (2017), Silver, David, et al. “Mastering the game of go without human knowledge.” Nature 550.7676: 354; Ji, G., He, S., Liheng, X.U., Liu, K., Zhao, J., Knowledge graph embedding via dynamic mapping matrix (2015) ACL, 1, pp. 687-696; Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2014. Embedding entities and relations for learning and inference in knowledge bases. CoRR, abs/1412.6575; LeCun, Y., Bengio, Y., Hinton, G., “Deep learning.” (2015) Nature, 521 (7553), pp. 436-444; Džeroski, S., De Raedt, L., Driessens, K., “Relational reinforcement learning.” (2001) Mach. Learn., 43 (1-2), pp. 7-52; Yang, F., Yang, Z., Cohen, W.W., “Differentiable learning of logical rules for knowledge base reasoning.” (2017) Adv. Neural Inform. Process. Syst.; Wang, Q., Ji, Y., Hao, Y., Cao, J., GRL: Knowledge graph completion with GAN-based reinforcement learning (2020) Knowledge-Based Syst., 209; Lan, Z., Sharma, P., (2020) Albert: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS, 1-17",,,,,,Article,"Final","",Scopus,2-s2.0-85098717859
"Cui Q., Zhou Y., Zheng M.","57237325000;12761881300;57235645300;","Sememes-Based Framework for Knowledge Graph Embedding with Comprehensive-Information",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12816 LNAI",,,"419","426",,,"10.1007/978-3-030-82147-0_34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113718164&doi=10.1007%2f978-3-030-82147-0_34&partnerID=40&md5=f3f9a13cbdf51e50799b75c9bdbb3992","The goal of knowledge graph embedding is to represent both entities and relationships as low-dimensional, dense vectors that can be used to empower other machine learning models. While most approaches concentrate on modeling the structural information of the graph, part of the work also focuses on fusing entity descriptions, allowing entities to be fused with richer semantics. However, the complex entity text descriptions contain a lot of noise, which reduces the semantic purity. Therefore, in this paper, we propose a novel sememes-based framework for knowledge graph to streamline the semantic space of entities. More specifically, We replace entity descriptions with a finite set of semantics and encode the sememe labels of entities using a pre-trained Bert model, and finally jointly learning the symbolic triples and sememe labels. The experimental results show that our method outperforms other baselines on the task of link prediction and entity classification. © 2021, Springer Nature Switzerland AG.","Knowledge graph embedding; Link prediction; Sememes-based description","Embeddings; Knowledge representation; Semantics; Complex entities; Comprehensive information; Knowledge graphs; Link prediction; Low dimensional; Machine learning models; Semantic Space; Structural information; Learning systems","Bloomfield, L., A set of postulates for the science of language (1926) Language, 2 (3), pp. 153-164; Bollacker, K., Evans, C., Paritosh, P., Sturge, T., Taylor, J., Freebase: A collaboratively created graph database for structuring human knowledge (2008) Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, pp. 1247-1250. , pp; Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., Yakhnenko, O., Translating embeddings for modeling multi-relational data (2013) Advances in Neural Information Processing Systems, pp. 2787-2795. , pp; Devlin, J., Chang, M.W., Lee, K., Toutanova, K., (2018) Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding. Arxiv Preprint Arxiv, 1810, p. 04805; Dong, Z., Dong, Q., HowNet-a hybrid language and knowledge resource (2003) International Conference on Natural Language Processing and Knowledge Engineering, 2003. Proceedings. 2003, Pp. 820–824. IEEE; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 249-256. , pp; Han, X., Openke: An open toolkit for knowledge embedding (2018) Proceedings of EMNLP; Ji, G., He, S., Xu, L., Liu, K., Zhao, J., Knowledge graph embedding via dynamic mapping matrix (2015) Proceedings of the 53Rd Annual Meeting of the Association for Computational Linguistics and the 7Th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 687-696. , pp; Jin, H., (2018) Incorporating Chinese Characters of Words for Lexical Sememe Prediction. Arxiv Preprint Arxiv, 1806, p. 06349; Lin, Y., Liu, Z., Sun, M., Liu, Y., Zhu, X., Learning entity and relation embeddings for knowledge graph completion (2015) Proceedings of AAAI, pp. 2181-2187. , pp; Miller, G.A., Wordnet: A lexical database for English (1995) Commun. ACM, 38 (11), pp. 39-41; Qin, Y., Improving sequence modeling ability of recurrent neural networks via sememes (2020) IEEE/ACM Trans. Audio Speech Lang. Process., 28, pp. 2364-2373; Wang, Z., Zhang, J., Feng, J., Chen, Z., Knowledge graph embedding by translating on hyperplanes (2014) AAAI, Vol. 14, Pp. 1112–1119. Citeseer; Xiao, H., (2018) Bert-As-Service, , https://github.com/hanxiao/bert-as-service; Xiao, H., Huang, M., Meng, L., Zhu, X., SSP: Semantic space projection for knowledge graph embedding with text descriptions (2017) Thirty-First AAAI Conference on Artificial Intelligence; Xie, R., Liu, Z., Jia, J., Luan, H., Sun, M., Representation learning of knowledge graphs with entity descriptions (2016) Thirtieth AAAI Conference on Artificial Intelligence; Yi-Xin, Z., A study on information-knowledge-intelligence transformation (2004) Acta Electronica Sinica, 32 (4), p. 16; Zhong, Y., Mechanism-based artificial intelligence theory: A universal theory of artificial intelligence (2018) CAAI Trans. Intell. Syst., 13 (1), pp. 2-18",,"14th International Conference on Knowledge Science, Engineering and Management, KSEM 2021","14 August 2021 through 16 August 2021",,263589,Conference Paper,"Final","",Scopus,2-s2.0-85113718164
"Zhou M., Ji D., Li F.","57224192500;8698003700;57215065441;","Relation Extraction in Dialogues: A Deep Learning Model Based on the Generality and Specialty of Dialogue Text",2021,"IEEE/ACM Transactions on Audio Speech and Language Processing","29",,"9439807","2015","2026",,,"10.1109/TASLP.2021.3082295","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107200162&doi=10.1109%2fTASLP.2021.3082295&partnerID=40&md5=95e3b167fd71613270903576b8ac1557","Relation extraction from dialogue text is an innovative task in natural language processing. In addition to the general characteristics of general relation extraction from news or scientific publication text, the task is of certain special features. For example, the context in dialogues frequently switches between speakers, and there exist rich pronoun anaphora in the dialogue text. Thus, it is important for the model to be aware of such features to improve the performance. Taking these factors together, we propose an end to-end neural model for dialogue-based relation extraction, which includes four modules to handle the problems existing in the task from different aspects: (1) the word-relation attention to model a natural intuition that different words contribute differently for the identification of different relations; (2) the graph reasoning to consider the global context information in the dialogue that contains many inter-sentence relations; (3) the speaker embeddings to incorporate speaker information into our model; (4) the speaker coreference to associate pronouns with speakers and enrich the information of graph reasoning. Our model was evaluated on a recently-proposed dataset for dialogue-based relation extraction, and achieved the state of the-art performance. We show that our proposed modules are effective through ablation studies. Our work can be a competitive benchmark for the study of dialogue based relation extraction. © 2014 IEEE.","deep learning; dialogue; natural language processing; Relation extraction","Extraction; Natural language processing systems; General relations; Global context; Learning models; NAtural language processing; Neural modeling; Relation extraction; Scientific publications; State-of-the-art performance; Deep learning","Calí, A., Gottlob, G., Pieris, A., Query answering under expressive entity-relationship schemata (2010) Proc. Int. Conf. Conceptual Model., pp. 347-361. , Springer; Shin, J., Wu, S., Wang, F., De Sa, C., Zhang, C., Ré, C., Incremental knowledge base construction using deepdive (2015) Proc. VLDB Endowment Int. Conf. Very Large Data Bases, 8 (11), pp. 1310-1321; Zhang, C., (2015) Deepdive: A Data Management System for Automatic Knowledge Base Construction, pp. 1-205. , PhD Thesis, University of Wisconsin-Madison, Madison, Wisconsin; Graja, M., Jaoua, M., Belguith, L.H., Statistical framework with knowledge base integration for robust speech understanding of the tunisian dialect (2015) IEEE/ACM Trans. Audio, Speech Lang. Proc., 23 (12), pp. 2311-2321. , https://doi.org/10.1109/TASLP.2015.2464687, Dec. [Online]; Lan, Y., Wang, S., Jiang, J., Knowledge base question answering with a matching-aggregation model and question-specific contextual relations (2019) IEEE/ACM Trans. Audio, Speech Lang. Proc., 27 (10), pp. 1629-1638. , https://doi.org/10.1109/TASLP.2019.2926125, Oct. [Online]; Hendrickx, I., Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals (2010) Proc. 5th Int. Workshop Semantic Eval., pp. 33-38; Riedel, S., Yao, L., McCallum, A., Modeling relations and their mentions without labeled text (2010) Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discov. Databases, pp. 148-163. , Springer; Socher, R., Huval, B., Manning, C.D., Ng, A.Y., Semantic compositionality through recursive matrix-vector spaces (2012) Proc. 2012 Joint Conf. Empirical Methods Natural Lang. Process. Comput. Natural Lang. Learn., pp. 1201-1211; Liu, Y., Li, S., Wei, F., Ji, H., Relation classification via modeling augmented dependency paths (2016) IEEE/ACM Trans. Audio, Speech Lang. Proc., 24 (9), pp. 1585-1594. , https://doi.org/10.1109/TASLP.2016.2573050, Sep. [Online]; Li, L., Wang, J., Li, J., Ma, Q., Wei, J., Relation classification via keyword-attentive sentence mechanism and synthetic stimulation loss (2019) IEEE/ACM Trans. Audio, Speech, Lang. Proc., 27 (9), pp. 1392-1404. , https://doi.org/10.1109/TASLP.2019.2921726, Sep. [Online]; Yao, Y., Docred: A large-scale document-level relation extraction dataset (2019) Proc. 57th Annual Meeting Asso. Comput. Linguist., pp. 764-777; Christopoulou, F., Miwa, M., Ananiadou, S., Connecting the dots: Document-level neural relation extraction with edge-oriented graphs (2019) Proc. Conf. Emp. Methods Natu. Lang. Process. 9th Inter. Joint (EMNLPIJCNLP), pp. 4927-4938; Nan, G., Guo, Z., Sekulić, I., Lu, W., Reasoning with latent structure refinement for document-level relation extraction (2020) Proc. 58th Ann. Meeting Asso. Comput. Linguist., pp. 1546-1557; Quirk, C., Poon, H., Distant supervision for relation extraction beyond the sentence boundary (2016) Proc. 15th Conf. Eur. Ch. Asso. Comput. Linguist.: Volume 1, Long Papers, pp. 1171-1182. , 2017; Song, L., Zhang, Y., Wang, Z., Gildea, D., N-ary relation extraction using graph-state LSTM (2018) Proc. 2018 Conf. Empirical Methods Natural Lang. Process, pp. 2226-2235. , https://www.aclweb.org/anthology/D18-1246, Brussels, Belgium: Association for Computational Linguistics, Oct.-Nov. [Online]; Gupta, P., Rajaram, S., Schütze, H., Runkler, T., Neural relation extraction within and across sentence boundaries (2019) Proc. AAAI Conf. Artif. Intell., 33, pp. 6513-6520; Doddington, G., Mitchell, A., Przybocki, M., Ramshaw, L., Strassel, S., Weischedel, R., The automatic content extraction (ACE) program tasks, data, and evaluation (2004) Proc. LREC'04, pp. 837-840; Mintz, M., Bills, S., Snow, R., Jurafsky, D., Distant supervision for relation extraction without labeled data (2009) Proc. Joint Conf. 47th Annu. Meeting ACL 4th Int. Joint Conf. Natural Lang. Process. AFNLP. Suntec, pp. 1003-1011. , https://www.aclweb.org/anthology/P09-1113, Singapore: Association for Computational Linguistics, Aug. [Online]; Yu, D., Sun, K., Cardie, C., Yu, D., Dialogue-based relation extraction (2020) Proc. 58th Annu. Meeting Assoc. Comput. Linguistics, pp. 4927-4940; Zeng, D., Liu, K., Lai, S., Zhou, G., Zhao, J., Relation classification via convolutional deep neural network (2014) Proc. 25th Int. Conf. Comput. Linguistics: Tech. Papers, pp. 2335-2344; Xu, Y., Mou, L., Li, G., Chen, Y., Peng, H., Jin, Z., Classifying relations via long short term memory networks along shortest dependency paths (2015) Proc. EMNLP, pp. 1785-1794; Guo, Z., Zhang, Y., Lu, W., Attention guided graph convolutional networks for relation extraction (2019) Proc. 57th Annu. Meeting Assoc. Comput. Linguistics, pp. 241-251; Lee, K., He, L., Lewis, M., Zettlemoyer, L., End-to-end neural coreference resolution (2017) Proc. 2017 Conf. Empirical Methods Natural Lang. Process, pp. 188-197. , https://www.aclweb.org/anthology/D17-1018, Copenhagen, Denmark: Association for Computational Linguistics, Sep. [Online]; Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., BERT: Pre-training of deep bidirectional transformers for language understanding (2019) Proc. Conf. North Amer. Ch. Asso. Comput. Linguist.: Human Lang. Technol., Volume 1 (Long and Short Papers), pp. 4171-4186; Vaswani, A., Attention is all you need (2017) Proc. NIPS, pp. 5998-6008; Doddington, G.R., Mitchell, A., Przybocki, M.A., Ramshaw, L.A., Strassel, S.M., Weischedel, R.M., The automatic content extraction (Ace) program-tasks, data, and evaluation (2004) Proc. Lrec, 2 (1), pp. 837-840. , Lisbon; Walker, C., Strassel, S., Medero, J., Maeda, K., Ace 2005 multilingual training corpus (2006) Linguistic Data Consortium, 57, p. 45. , https://catalog.ldc.upenn.edu/LDC2006T06, Philadelphia; Nguyen, T.H., Grishman, R., Relation extraction: Perspective from convolutional neural networks (2015) Proc. 1st Workshop Vector Space Model. Natural Lang. Process, pp. 39-48; Miwa, M., Bansal, M., End-to-end relation extraction using lstms on sequences and tree structures (2016) Proc. ACL, pp. 1105-1116. , Berlin, Germany:Association for Computational Linguistics; Riedel, S., Yao, L., McCallum, A., Modeling relations and their mentions without labeled text (2010) Proc. Mach. Learn. Knowl. Discovery Databases, pp. 148-163. , J. L. Balcázar, F. Bonchi, A. Gionis, and M. Sebag, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg; Zeng, D., Liu, K., Chen, Y., Zhao, J., Distant supervision for relation extraction via piecewise convolutional neural networks (2015) Proc. Conf. Empirical Methods Natural Lang. Process, pp. 1753-1762; Lin, Y., Shen, S., Liu, Z., Luan, H., Sun, M., Neural relation extraction with selective attention over instances (2016) Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, 1, pp. 2124-2133; Li, J., Biocreative v CDR task corpus: A resource for chemical disease relation extraction (2016) Database, 1, p. 10; Wu, Y., Luo, R., Leung, H.C., Ting, H.-F., Lam, T.-W., Renet: A deep learning approach for extracting gene-disease associations from literature (2019) Proc. Int. Conf. Res. Comput. Mol. Biol., pp. 272-284. , Springer; Peng, N., Poon, H., Quirk, C., Toutanova, K., Yih, W.-T., Cross-sentence n-ary relation extractionwith graph lstms (2017) Trans. Assoc. Comput. Linguistics, 5, pp. 101-115. , https://www.aclweb.org/anthology/Q17-1008, [Online]; Sahu, S.K., Christopoulou, F., Miwa, M., Ananiadou, S., Inter-sentence relation extraction with document-level graph convolutional neural network (2019) Proc. 57th Annual Meeting Assoc. Comput. Linguist., pp. 4309-4316; Manning, C.D., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S.J., McClosky, D., The stanford corenlp natural language processing toolkit (2014) Proc. 52nd ACL, pp. 55-60. , Sep; Kipf, T.N., Welling, M., Semi-supervised classification with graph convolutional networks (2017) Proc. ICLR, pp. 1-14. , Toulon, France; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Wang, H., Focke, C., Sylvester, R., Mishra, N., Wang, W., (2019) Fine-tune Bert for Docred with Two-step Process; Sukhbaatar, S., Szlam, A., Weston, J., Fergus, R., End-to-end memory networks (2015) Proc. Adv. Neural Inf. Process. Syst., 28, pp. 2440-2448. , C. N. Cortes, D. Lawrence, M. Lee Sugiyama, and R. Garnett, Eds., Curran Associates, Inc",,,,,,Article,"Final","",Scopus,2-s2.0-85107200162
"Bounabi M., Elmoutaouakil K., Satori K.","57195492422;35329465400;35976902500;","A new neutrosophic TF-IDF term weighting for text mining tasks: text classification use case",2021,"International Journal of Web Information Systems","17","3",,"229","249",,,"10.1108/IJWIS-11-2020-0067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103899477&doi=10.1108%2fIJWIS-11-2020-0067&partnerID=40&md5=707e28923b31ac89b6593e7020b37ae9","Purpose: This paper aims to present a new term weighting approach for text classification as a text mining task. The original method, neutrosophic term frequency – inverse term frequency (NTF-IDF), is an extended version of the popular fuzzy TF-IDF (FTF-IDF) and uses the neutrosophic reasoning to analyze and generate weights for terms in natural languages. The paper also propose a comparative study between the popular FTF-IDF and NTF-IDF and their impacts on different machine learning (ML) classifiers for document categorization goals. Design/methodology/approach: After preprocessing textual data, the original Neutrosophic TF-IDF applies the neutrosophic inference system (NIS) to produce weights for terms representing a document. Using the local frequency TF, global frequency IDF and text N's length as NIS inputs, this study generate two neutrosophic weights for a given term. The first measure provides information on the relevance degree for a word, and the second one represents their ambiguity degree. Next, the Zhang combination function is applied to combine neutrosophic weights outputs and present the final term weight, inserted in the document's representative vector. To analyze the NTF-IDF impact on the classification phase, this study uses a set of ML algorithms. Findings: Practicing the neutrosophic logic (NL) characteristics, the authors have been able to study the ambiguity of the terms and their degree of relevance to represent a document. NL's choice has proven its effectiveness in defining significant text vectorization weights, especially for text classification tasks. The experimentation part demonstrates that the new method positively impacts the categorization. Moreover, the adopted system's recognition rate is higher than 91%, an accuracy score not attained using the FTF-IDF. Also, using benchmarked data sets, in different text mining fields, and many ML classifiers, i.e. SVM and Feed-Forward Network, and applying the proposed term scores NTF-IDF improves the accuracy by 10%. Originality/value: The novelty of this paper lies in two aspects. First, a new term weighting method, which uses the term frequencies as components to define the relevance and the ambiguity of term; second, the application of NL to infer weights is considered as an original model in this paper, which also aims to correct the shortcomings of the FTF-IDF which uses fuzzy logic and its drawbacks. The introduced technique was combined with different ML models to improve the accuracy and relevance of the obtained feature vectors to fed the classification mechanism. © 2021, Emerald Publishing Limited.","artificial intelligence; Fuzzy logic; Fuzzy TF-IDF; Machine learning; Neutrosophic logic; Neutrosophic TF-IDF; Text classification; Web mining","Classification (of information); Computer circuits; Feedforward neural networks; Fuzzy logic; Inverse problems; Support vector machines; Classification mechanism; Comparative studies; Degree of relevance; Design/methodology/approach; Document categorization; Feed-forward network; Neutrosophic logic; Text classification; Text mining","Aharrane, N., El Moutaouakil, K., Satori, K., (2015) A comparison of supervised classification methods for a statistical set of features: application: amazigh OCR, pp. 1-8. , 2015 Intelligent Systems and Computer Vision (ISCV), IEEE; Aizawa, A., An information-theoretic perspective of tf–idf measures (2003) Information Processing and Management, 39 (1), pp. 45-65; Akhtar, N., Qureshi, M.N., Ahamad, M.V., An improved clustering method for text documents using neutrosophic logic (2017) Applications of Soft Computing for the Web, pp. 167-179. , Springer, Singapore; Ansari, A.Q., Biswas, R., Aggarwal, S., Neutrosophic classifier: an extension of fuzzy classifer (2013) Applied Soft Computing, 13 (1), pp. 563-573; Bounabi, M., El Moutaouakil, K., Satori, K., A comparison of text classification methods method of weighted terms selected by different stemming techniques (2017) in Proceedings of the 2nd international Conference on Big Data, Cloud and Applications, p. 43. , p., ACM; Bounabi, M., El Moutaouakil, K., Satori, K., A probabilistic vector representation and neural network for text classification (2018) International Conference on Big Data, Cloud and Applications, pp. 343-355. , Springer, Cham; Bounabi, M., El Moutaouakil, K., Satori, K., Association models to select the best rules for fuzzy inference system (2020) Embedded Systems and Artificial Intelligence, pp. 349-357. , Springer, Singapore; Bounabi, M., Moutaouakil, K.E., Satori, K., A comparison of text classification methods using different stemming techniques (2019) International Journal of Computer Applications in Technology, 60 (4), pp. 298-306; Broumi, S., Bakali, A., Talea, M., Smarandache, F., Dey, A., Spanning tree problem with neutrosophic edge weights (2018) Procedia Computer Science, 127, pp. 190-199; Chen, K., Zhang, Z., Long, J., Zhang, H., Turning from TF-IDF to TF-IGM for term weighting in text classification (2016) Expert Systems with Applications, 66, pp. 245-260; Dang, S., Ahmad, P.H., Text mining: Techniques and its application (2014) International Journal of Engineering and Technology Innovations, 1 (4), pp. 866-2348; Dunne, R.A., Campbell, N.A., On the pairing of the softmax activation and cross-entropy penalty functions and the derivation of the softmax activation function (1997) in Proc. 8th Aust. Conf. on the Neural Networks, 181, p. 185. , p., Melbourne; Feng, X., Liang, Y., Shi, X., Xu, D., Wang, X., Guan, R., Overfitting reduction of text classification based on AdaBELM (2017) Entropy, 19 (7), p. 330; Ge, L., Moh, T.S., Improving text classification with word embedding (2017) in 2017 IEEE International Conference on Big Data (Big Data), pp. 1796-1805. , IEEE; Greene, D., Cunningham, P., Practical solutions to the problem of diagonal dominance in kernel document clustering (2006) in Proceedings of the 23rd international conference on Machine learning, pp. 377-384; Gupta, Y., Saini, A., Saxena, A.K., A new fuzzy logic based ranking function for efficient information retrieval system (2015) Expert Systems with Applications, 42 (3), pp. 1223-1234; Hamon, D., (2016) System and method providing a binary representation of a web page, , (accessed U.S. Patent, 29 March 2016; Jang, J.S., ANFIS: adaptive-network-based fuzzy inference system (1993) IEEE Transactions on Systems, Man, and Cybernetics, 23 (3), pp. 665-685; Jones, K.S., A statistical interpretation of term specificity and its application in retrieval (1972) Journal of Documentation; Kandasamy, I., Vasantha, W.B., Obbineni, J.M., Smarandache, F., Sentiment analysis of tweets using refined neutrosophic sets (2020) Computers in Industry, 115, p. 103180; Ko, Y., A new term‐weighting scheme for text classification using the odds of positive and negative class probabilities (2015) Journal of the Association for Information Science and Technology, 66 (12), pp. 2553-2565; Kou, G., Yang, P., Peng, Y., Xiao, F., Chen, Y., Alsaadi, F.E., Evaluation of feature selection methods for text classification with small datasets using multiple criteria decision-making methods (2020) Applied Soft Computing, 86, p. 105836; Krstajic, D., Buturovic, L.J., Leahy, D.E., Thomas, S., Cross-validation pitfalls when selecting and assessing regression and classification models (2014) Journal of Cheminformatics, 6 (1), pp. 1-15; Liang, W.E.I., Exploration on translation of the literary term ambiguity (2017) China Terminology, (4), p. 9; Liu, C.Z., Sheng, Y.X., Wei, Z.Q., Yang, Y.Q., Research of text classification based on improved TF-IDF algorithm (2018) in 2018 IEEE International Conference of Intelligent Robotic and Control Engineering (IRCE), pp. 218-222. , August)., IEEE; Luhn, H.P., The automatic creation of literature abstracts (1958) IBM Journal of Research and Development, 2 (2), pp. 159-165; Mullai, M., Broumi, S., Stephen, A., Shortest path problem by minimal spanning tree algorithm using bipolar neutrosophic numbers (2017) International Journal of Mathematic Trends and Technology, 46 (2), pp. 80-87; Nancy Garg, H., An improved score function for ranking neutrosophic sets and its application to decision making process (2016) International Journal for Uncertainty Quantification, 6 (5), pp. 377-385; Rajman, M., Besançon, R., Text mining: natural language techniques and text mining applications (1998) Data Mining and Reverse Engineering, pp. 50-64. , Springer, Boston, MA; Rao, D.H., Saraf, S.S., Study of defuzzification methods of fuzzy logic controller for speed control of a DC motor (1996) in Proceedings of International Conference on Power Electronics, Drives and Energy Systems for Industrial Growth, 2, pp. 782-787. , IEEE; Ropero, J., Gómez, A., León, C., Carrasco, A., Term weighting: novel fuzzy logic based method vs classical TF-IDF method for web information extraction (2009) ICEIS, 2, pp. 130-137; Smarandache, F., (2002) Neutrosophy, a new branch of philosophy, , Infinite Study; Smarandache, F., Definiton of neutrosophic logic – a generalization of the intuitionistic fuzzy logic (2003) In EUSFLAT Conf, pp. 141-146; Smarandache, F., Neutrosophic set–a generalization of the intuitionistic fuzzy set (2010) Journal of Defense Resources Management (JoDRM), 1 (1), pp. 107-116; (2003), Smarandache, F. (Ed.) (, Infinite Study; Svozil, D., Kvasnicka, V., Pospichal, J., Introduction to multi-layer feed-forward neural networks (1997) Chemometrics and Intelligent Laboratory Systems, 39 (1), pp. 43-62; Tharwat, A., Parameter investigation of support vector machine classifier with kernel functions (2019) Knowledge and Information Systems, 61 (3), pp. 1269-1302; WangSmarandacheZhang, H., Sunderraman, R., (2010) Single valued neutrosophic sets. Infinite study; Wu, H.C., Luk, R.W.P., Wong, K.F., Kwok, K.L., Interpreting tf-idf term weights as making relevance decisions (2008) ACM Transactions on Information Systems (TOIS), 26 (3), pp. 1-37; Zadeh, L.A., Fuzzy sets (1965) Information and Control, 8 (3), pp. 338-353; ZhangWang, H.Y., Chen, X.H., (2014) Interval neutrosophic sets and their application in multicriteria decision making problems, p. 645953. , p., Sci. World J. 2014",,,,,,Article,"Final","",Scopus,2-s2.0-85103899477
"Ezzat M.","57210670847;","A comprehensive conceptualization of urban constructs as a basis for design creativity: An ontological conception of urbanism for human-computer aided spatial experiential simulation and design creativity",2021,"Smart Innovation, Systems and Technologies","178 SIST",,,"580","591",,,"10.1007/978-3-030-48279-4_55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091292384&doi=10.1007%2f978-3-030-48279-4_55&partnerID=40&md5=a48aae9258822f66f672b75c13057346","“The phenomenon of place is not comprehensible without computation, and any effort for simulating spatial experience or for the creative manifestation of such phenomena is not attainable without the computation that possesses a comprehensive conceptualization of spatial signs” is a conclusion of the article. Place is a fairly complex phenomenon that encompasses several interrelated knowledge domains. For example, from the users’ point of view, the phenomenon of place manifests over the interrelation between spatial cognition, psychology, and behavioral utilization. In contrast, from the designers’ point of view, these interrelated dimensions should be innovatively crafted. Any creative crafting of the virtual phenomenon of place needs to be aware of the spatial subjective conceptions of the intended users. To resolve such complexity, the article recognizes the phenomenon of place as a mere relationship between the two realms of spatial representations and spatial conceptions. The realm of representation is objectively analyzed over the two layers of spatial signs and spatial features, while the realm of conception is subjectively obtainable using knowledge graphs. The article’s recognition of place as the virtualization of space implies that the multi-knowledge domains’ complexity of place will be reduced to merely the conceptualization of any spatial representations. The article’s findings of conceptualization of space adhere to findings from the fields of analogy, cognition, psycholinguistics, and creativity. These findings are central for simulating the subjective spatial experiences, subjective potential spatial utilization, and finally, for design creativity. Structuring such conceptualization is founded on an ontology of urban constructs and on language. This explains the need for the computation-human integrative role in learning the spatial concepts and then on linking the comprehensively learned conception with the spatial representations. The article is a philosophical explanation of a parallel computational model for conceptualizing urban constructs. The proposed conceptualization is theoretical, and it will be supplemented in the future with empirical analysis. © Springer Nature Switzerland AG 2021.","A knowledge graph for conceptualizing urban constructs; Analogical urban design; Computational-aided design creativity; Design creativity; Phenomenology; Urban design ontology; Urban identity","Knowledge representation; Ontology; Philosophical aspects; Regional planning; Conceptualization of spaces; Design creativities; Empirical analysis; Knowledge domains; Parallel computational models; Philosophical explanations; Spatial cognition; Spatial representations; Behavioral research","Ezzat, M., A comprehensive proposition of urbanism (2019) New Metropolitan Perspectives, ISHT 2018, Regio Calabria, Italy. Smart Innovation, Systems and Technologies, 100, pp. 433-443. , Springer, Cham; Ezzat, M., A framework for a comprehensive conceptualization of urban constructs: SpatialNet and SpatialFeaturesNet for computer-aided creative urban design (2020) RE: Anthropocene, Proceedings of the 25th International Conference of the Association for Computer-Aided Architectural Design Research in Asia (CAADRIA); Fishe, S., Philosophy of architecture (2016) The Stanford Encyclopedia of Philosophy, Metaphysics Research Lab, Stanford University; Ventura, D., The computational creativity complex (2015) Computational Creativity Research: Towards Creative Machines, , Besold, T., Schorlemmer, M., Smaill, A. (eds) Atlantis Press, Paris; Ezzat, M., A computational tool for mapping the users’ urban cognition-a framework and a representation for the evolutionary optimization of the fuzzy binary relation between the urban conceptions of “us” and “others (2018) The 36th eCAADe Conference; Tamari, T., The phenomenology of architecture: a short introduction to Juhani Pallasmaa (2017) Body Soc, 23 (1), pp. 91-95; Lefebvre, H., (1974) The Production of Space, , Blackwell, Oxford; Derrida, J., (1967) Of Grammatology. Les Éditions de Minuit, , Paris; Derrida, J., (1967) Speech and Phenomena, , Presses Universitaires de France, Paris; Funke, J., On the psychology of creativity (2009) Milieus of Creativity: An Interdisciplinary Approach to Spatiality of Creativity, , Meusburger, P., Funke, J., Wunder, E. (eds) Springer, Dordrecht; Brinck, I., The gist of creativity (1997) The Complexity of Creativity, , Andersson, Å.E., Sahlin, N.E. (eds) Springer, Dordrecht; Evans, V., What’s in a concept? Analog versus parametric concepts in LCCM theory (2015) The Conceptual Mind: New Directions in the Study of Concepts, , Margolis, E., Laurence, S. (eds) The MIT Press, Cambridge; Heath, D., Norton, D., Ventura, D., A conveying semantics through visual metaphor (2014) ACM Trans. Intell. Syst. Technol, 5 (2). , 31:1–31:17; Heath, D., Norton, D., Ventura, D., Autonomously communicating conceptual knowledge through visual art (2013) ICCC; Prinz, J.J., (2002) Furnishing the Mind: Concepts and Their Perceptual Basis, , The MIT Press, Cambridge; Koolhaas, R., (2018) Harvard Graduate School of Design, Trüby, S., Westcott, J., Petermann, S.: Rem Koolhaas. Elements of Architecture, , Taschen, Cologne; Goel, A.K., Craw, S., Design, innovation and case-based reasoning (2006) Knowl. Eng. Rev, 20, pp. 271-276; Richter, K., Donath, D., (2006) eCAADe, , Towards a better understanding of the case-based reasoning paradigm in architectural education and design; Peckham, A., Schmiedeknecht, T., (2014) The Rationalist Reader, , Routledge, Abingdon; Stojanovski, T., (2013) City Information Modeling (CIM) and urbanism: blocks, connections, territories, people and situations, , SimAUD; Norton, D., Heath, D., Ventura, D., Finding creativity in an artificial artist (2013) J. Creat. Behav, 47 (2), pp. 106-124; Malt, B.C., Gennari, S.P., Imai, M., Ameel, E., Saji, N., Majid, A., Where are the concepts? What words can and can’t reveal (2015) The Conceptual Mind: New Directions in the Study of Concepts, , Margolis, E., Laurence, S. (eds) The MIT Press, Cambridge",,"4th International Symposium on New Metropolitan Perspectives, NMP 2020","26 May 2020 through 28 May 2020",,244699,Conference Paper,"Final","",Scopus,2-s2.0-85091292384
"Zarisfi Kermani F., Sadeghi F., Eslami E.","57201254803;23489903000;16233285000;","Solving the twitter sentiment analysis problem based on a machine learning-based approach",2020,"Evolutionary Intelligence","13","3",,"381","398",,4,"10.1007/s12065-019-00301-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074497303&doi=10.1007%2fs12065-019-00301-x&partnerID=40&md5=064426e2a466ab68466559bf866ee630","Twitter Sentiment Analysis (TSA) as part of a text classification task has been widely attended by researchers in recent years. This paper presents a machine learning approach to solving the TSA problem in three phases. In the second phase, a suitable value for representing each feature in the Vector Space Model is determined through the weighted combination of the values obtained from four methods (i.e., Term Frequency and Inverse Document Frequency, semantic similarity, sentiment scoring using SentiWordNet, and sentiment scoring based on the class of tweets). In this manner, finding the percentage of contributions or weights of each method is defined as an optimization problem and solved using a genetic algorithm. Also, the weighted values obtained from four methods are combined based on the Einstein sum as an important T-conorm method. Finally, the performance of the proposed method is tested based on the accuracy of support vector machine and multinomial naïve Bayes classification algorithms on four famous Twitter datasets, namely the Stanford testing dataset, STS-Gold dataset, Obama-McCain Debate dataset, and Strict Obama-McCain Debate dataset. The obtained results show the high superiority of the proposed method in comparison with the other methods. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Einstein T-conorm; Genetic algorithm; Multinomial Naïve Bayes; Support vector machine; Twitter sentiment analysis","Classification (of information); Fuzzy logic; Genetic algorithms; Learning algorithms; Machine learning; Phase space methods; Semantics; Sentiment analysis; Social networking (online); Statistical tests; Support vector machines; Vector spaces; Bayes classification; Inverse Document Frequency; Machine learning approaches; Multinomials; Optimization problems; Semantic similarity; T-conorms; Text classification; Inverse problems","Supriya, B.N., Kallimani, V., Prakash, S., Akki, C.B., Twitter sentiment analysis using binary classification technique (2016) International Conference on Nature of Computation and Communication ICTCC 2016: Nature of Computation and Communication, pp. 91-396; Haque, M.A., Rahman, T., Sentiment analysis by using fuzzy logic (2014) Int J Comput Sci Eng Inf Technol (IJCSEIT), 4, pp. 33-48; Shirdastian, H., Laroche, M., Richard, M.-O., Using big data analytics to study brand authenticity sentiments: the case of starbucks on twitter (2019) Int J Inf Manage, 48, pp. 291-307; Mansour, R., Hady, M.F.A., Hosam, E., Amr, H., Ashour, A., Feature selection for twitter sentiment analysis: An experimental study (2015) International Conference on Intelligent Text Processing and Computational Linguistics Cicling Computational Linguistics and Intelligent Text Processing, pp. 92-103; Bao, Y., Quan, C., Wang, L., Ren, F., The role of pre-processing in twitter sentiment analysis (2014) International Conference on Intelligent Computing ICIC: Intelligent Computing Methodologies, pp. 615-624; Keshavarz, H., Abadeh, M.-S., ALGA: adaptive lexicon learning using genetic algorithm for sentiment analysis of microblogs (2017) Knowl-Based Syst, 122, pp. 1-16; Ismail, H.-M., Belkhouche, B., Zaki, N., Semantic twitter sentiment analysis based on a fuzzy thesaurus (2018) Soft Comput, 22, pp. 6011-6024; Medhat, W., Hassan, A., Korashy, H., Sentiment analysis algorithms and applications: a survey (2014) Ain Shams Eng J, 5, pp. 1093-1113; Asghar, M.-Z., Khan, A., Khan, F., Kundi, F.-M., RIFT: a rule induction framework for twitter sentiment analysis (2018) Arabian J Sci Eng, 43, pp. 857-877; Le, B., Nguyen, H., Twitter sentiment analysis using machine learning techniques (2015) Advanced Computational Methods for Knowledge Engineering AISC: Advances in Intelligent Systems and Computing, pp. 279-289; Pandey, A.-C., Rajpoot, D.-S., Saraswat, M., Twitter sentiment analysis using hybrid cuckoo search method (2017) Inf Process Manage, 53, pp. 764-779; Speriosu, M., Sudan, N., Upadhyay, S., Baldridge, J., Twitter polarity classification with label propagation over lexical links and the follower graph (2011) Conference on Empirical Methods in Natural Language Processing, pp. 53-63. , UK; Masud, F., Khan, A., Ahmad, S., Asghar, M.-Z., Lexicon-based sentiment analysis in the social web (2014) J Basic Appl Sci Res, 4 (6), pp. 238-248; Asghar, M.-Z., Kundi, F.-M., Ahmad, S., Khan, A., Khan, F., T-SAF: twitter sentiment analysis framework using a hybrid classification scheme (2018) Exp Syst, 35, pp. 1-19; Saif, H., He, Y., Fernandez, M., Alani, H., Contextual semantics for sentiment analysis of Twitter (2016) Inf Process Manage, 52, pp. 5-19; Khan, F.-H., Qamar, U., Bashir, S., SentiMI: introducing point-wise mutual information with SentiWordNet to improve sentiment polarity detection (2016) Appl Soft Comput, 39, pp. 140-153; Esuli, A., Sebastiani, F., Sentiwordnet: A publicly available lexical resource for opinion mining (2006) Proceedings of the Fifth International Conference on Language Resources and Evaluation, pp. 417-422; Nielsen, F.-A., A new ANEW: Evaluation of a word list for sentiment analysis for microblogs (2011) Proceedings of the ESWC2011 Workshop on ‘Making Sense of Microposts’: Big Things Come in Small Packages, pp. 93-98; Taboada, M., Brooke, J., Tofiloski, M., Voll, K., Stede, M., Lexicon-based methods for sentiment analysis (2011) Comput Lingust, 37, pp. 267-307; Paltoglou, G., Thelwall, M., A study of information retrieval weighting schemes for sentiment analysis (2010) Proceedings of the 48Th Annual Meeting of the Association for Computational Linguistics: Association for Computational Linguistics, pp. 1386-1395; Yager, R.R., Kelman, A., Fusion of fuzzy information with considerations for compatibility, partial aggregation, and reinforcement (1996) Int J Appr Reason, 15, pp. 93-122; Appel, O., Chiclana, F., Carter, J., Fujita, H., a hybrid approach to the sentiment analysis problem at the sentence level (2016) Knowl-Based Syst, 108, pp. 110-124; Gassert, H., (2018) Operators on Fuzzy Sets: Zadeh and Einsteinations on Fuzzy Sets Properties of T-Norms and T-Conorms, , https://pdfs.semanticscholar.org/a045/52b74047208d23d77b8aa9f5f334b59e65ea.pdf, Accessed 8 Dec 2018; Goldberg, D.-E., (1989) Genetic algorithms in search optimization and machine learning, , Addition Wesley, Massachusetts; Effrosynidis, D., Symeonidis, S., Arampatzis, A., A comparison of pre-processing techniques (2017) International Conference on Theory and Practice of Digital Libraries TPDL: Research and Advanced Technology for Digital Libraries, pp. 394-406; Salton, G., Wong, A., Yang, C.-S., A vector space model for automatic indexing (1975) Commun ACM, 18, pp. 613-620; Han, J., Kamber, M., (2006) Data Mining: Concepts and Techniques, 2Nd Edn. University of Illinois at Urbana-Champaign, Printed on Elsevier Inc; Vierira, S.-M., Mendonca, L.-F., Farinha, G.-J., Sousa, J.-M.-C., Modified binary PSO for feature selection using SVM applied to mortality prediction of septic patients (2013) Appl Soft Comput, 13, pp. 3494-3504; Gen, M., Cheng, R., (1997) Genetic Algorithms and Engineering Design, , printed on Wiley; Vapnik, V.-N., (1995) The nature of statistical learning theory, , Springer, New York; Saif, H., Fernande, M., Alani, Y.H.H., Evaluation datasets for twitter sentiment analysis: A survey and a new dataset, the STS-Gold (2013) 1St Interantional Workshop on Emotion and Sentiment in Social and Expressive Media: Approaches and Perspectives from AI (ESSEM 2013), pp. 9-21. , Turin, Italy; Go, A., Bhayani, R., Huang, L., (2010) Twitter Sentiment Classification Using Distant Supervision, , Technical report Stanford University; Shapiro, S.S., Wilk, M.B., Chen, H.J., A comparative study of various tests for normality (1968) J Am Stat Assoc, 63 (324), pp. 1343-1372",,,,,,Article,"Final","",Scopus,2-s2.0-85074497303
"Jiang J., Wang H., Xie J., Guo X., Guan Y., Yu Q.","56376858400;57209074133;57200535026;24777794600;7202924009;56359402300;","Medical knowledge embedding based on recursive neural network for multi-disease diagnosis",2020,"Artificial Intelligence in Medicine","103",,"101772","","",,3,"10.1016/j.artmed.2019.101772","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078077985&doi=10.1016%2fj.artmed.2019.101772&partnerID=40&md5=3483a63fb7430aa96a98811d66247886","The representation of knowledge based on first-order logic captures the richness of natural language and supports multiple probabilistic inference models. Although symbolic representation enables quantitative reasoning with statistical probability, it is difficult to utilize with machine learning models as they perform numerical operations. In contrast, knowledge embedding (i.e., high-dimensional and continuous vectors) is a feasible approach to complex reasoning that can not only retain the semantic information of knowledge, but also establish the quantifiable relationship among embeddings. In this paper, we propose a recursive neural knowledge network (RNKN), which combines medical knowledge based on first-order logic with a recursive neural network for multi-disease diagnosis. After the RNKN is efficiently trained using manually annotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented knowledge embeddings and weight matrixes are learned. The experimental results confirm that the diagnostic accuracy of the RNKN is superior to those of four machine learning models, four classical neural networks and Markov logic network. The results also demonstrate that the more explicit the evidence extracted from CEMRs, the better the performance. The RNKN gradually reveals the interpretation of knowledge embeddings as the number of training epochs increases. © 2019 Elsevier B.V.","Electronic medical records; First-order logic; Knowledge embedding; Recursive neural network","Computer circuits; Embeddings; Formal logic; Knowledge based systems; Machine learning; Medical computing; Neural networks; Semantics; Classical neural networks; Electronic medical record; First order logic; Knowledge embedding; Machine learning models; Probabilistic inference models; Recursive neural networks; Statistical probability; Diagnosis; algorithm; Article; Chinese; computer assisted diagnosis; diagnostic accuracy; electronic medical record; embedding; machine learning; priority journal; recursive neural network; computer assisted diagnosis; electronic health record; human; organization and management; procedures; Algorithms; Diagnosis, Computer-Assisted; Electronic Health Records; Humans; Machine Learning; Neural Networks, Computer","Bollacker, K., Evans, C., Paritosh, P., Freebase: a collaboratively created graph database for structuring human knowledge (2008) Proc. SIGMOD Conference, pp. 1247-1250; Bordes, A., Glorot, X., Weston, J., A semantic matching energy function for learning with multi-relational data (2014) Mach Learn, 94 (2), pp. 233-259; Bordes, A., Weston, J., Collobert, R., Learning structured embeddings of knowledge bases (2012) AAAI Conference on Artificial Intelligence, AAAI 2011, San Francisco, California, USA, August. DBLP; https://www.nlm.nih.gov/research/umls/, U.S. National Library of Medicine, “Unified Medical Language System.” [Online] Available:; Palmerini, T., Benedetto, U., Bacchi-Reggiani, L., Mortality in patients treated with extended duration dual antiplatelet therapy after drug-eluting stent implantation: a pairwise and Bayesian network meta-analysis of randomised trials (2015) Lancet, 385 (9985), pp. 2371-2382; Snidaro, L., Visentini, I., Bryan, K., Fusing uncertain knowledge and evidence for maritime situational awareness via Markov Logic Networks (2015) Inf Fusion, 21, pp. 159-172; Marini, S., Trifoglio, E., Barbarini, N., A dynamic Bayesian network model for long-term simulation of clinical complications in type 1 diabetes (2015) J Biomed Inform, 57 (100), pp. 369-376; Fuster-Parra, P., Tauler, P., Bennasar-Veny, M., Bayesian network modeling: a case study of an epidemiologic system analysis of cardiovascular risk (2016) Comput Methods Programs Biomed, 126, pp. 128-142; Yu, T., Li, J., Yu, Q., Knowledge graph for TCM health preservation (2017) Artif Intell Med, 77, pp. 48-52; Rao, D., Mcnamee, P., Dredze, M., Entity linking: finding extracted entities in a knowledge base. (2013) Multi-source, multilingual information extraction and summarization, pp. 93-115. , Springer Berlin Heidelberg; Shen, W., Wang, J., Han, J., Entity linking with a knowledge base: issues, techniques, and solutions (2015) Knowl Data Eng IEEE Trans, 27 (2), pp. 443-460; Dredze, M., Mcnamee, P., Rao, D., Entity disambiguation for knowledge base population (2010) International Conference on Computational Linguistics. Association for Computational Linguistics, pp. 277-285; Duque, A., Stevenson, M., Martinez-Romo, J., Co-occurrence graphs for word sense disambiguation in the biomedical domain (2018) Artif Intell Med, 87, pp. 9-19; Yang, B., Yih, W.T., He, X., Embedding entities and relations for learning and inference in knowledge bases (2014) Eprint Arxiv; Rocktäschel, T., Singh, S., Riedel, S., Injecting logical background knowledge into embeddings for relation extraction (2014) North Am Chap Assoc Comput Linguis, pp. 648-664; Rocktäschel, T., Bošnjak, M., Singh, S., Low-dimensional embeddings of logic (2014) ACL 2014 Workshop on Semantic Parsing, pp. 45-49; Xiao, H., Huang, M., Meng, L., SSP: semantic space projection for knowledge graph embedding with text descriptions (2017) AAAI, 17, pp. 3104-3110; Guo, S., Wang, Q., Wang, B., SSE: semantically smooth embedding for knowledge graphs (2017) IEEE Trans Knowl Data Eng, 29 (4), pp. 884-897; Zhao, C., Jiang, J., Guan, Y., EMR-based medical knowledge representation and inference via Markov random fields and distributed representation learning (2018) Artif Intell Med, 87, pp. 49-59; Mikolov, T., Chen, K., Corrado, G., Efficient estimation of word representations in vector space (2013) Comput Sci; Mikolov, T., Sutskever, I., Chen, K., Distributed representations of words and phrases and their compositionality (2013) Adv Neural Inf Process Syst, 26, pp. 3111-3119; Goller, C., Kuchler, A., Learning task-dependent distributed representations by backpropagation through structure (2002) IEEE International Conference on Neural Networks. IEEE, 1, pp. 347-352; Bordes, A., Usunier, N., Garcia-Duran, A., Translating embeddings for modeling multi-relational data (2013) International Conference on Neural Information Processing Systems. Curran Associates Inc., pp. 2787-2795; Williams, D., Hinton, G., Learning representations by back-propagating errors (1986) Nature, 323 (6088), pp. 533-538; Mikolov, T., Le, Q.V., Sutskever, I., Exploiting similarities among languages for machine translation (2013) Comput Sci; Socher, R., Chen, D., Manning, C.D., Reasoning with neural tensor networks for knowledge base completion (2013) International Conference on Neural Information Processing Systems. Curran Associates Inc., pp. 926-934; Chen, D., Socher, R., Manning, C.D., Learning new facts from knowledge bases with neural tensor networks and semantic word vectors (2013) Comput Sci; Lakkaraju, H., Socher, R., Manning, C., Aspect specific sentiment analysis using hierarchical deep learning (2014) NIPS Workshop on Deep Learning and Representation Learning; Zou, W.Y., Socher, R., Cer, D., Bilingual word embeddings for phrase-based machine translation (2013) Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 1393-1398; Pei, W., Ge, T., Chang, B., Max-margin tensor neural network for Chinese word segmentation (2014) Meeting of the Association for Computational Linguistics, pp. 293-303; Socher, R., Huval, B., Manning, C.D., Semantic compositionality through recursive matrix-vector spaces (2012) Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 1201-1211; Choi, E., Bahadori, M.T., Song, L., GRAM: graph-based attention model for healthcare representation learning (2016) 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 787-795; Lewis, M., Steedman, M., Combined distributional and logical semantics (2013) Trans Assoc Comput Linguist, 1, pp. 179-192; Jiang, J., Zhao, C., Guan, Y., Learning and inference in knowledge-based probabilistic model for medical diagnosis (2017) Knowledge Based Syst; https://github.com/WILAB-HIT/Resources/, WILAB-HIT, “Resources.” [Online] Available:; Jiang, J., Xie, J., Zhao, C., Max-margin weight learning for medical knowledge network (2018) Comput Methods Prog Biomed; Socher, R., Manning, C.D., Ng, A.Y., Learning continuous phrase representations and syntactic parsing with recursive neural networks (2010) NIPS-2010 Deep Learning and Unsupervised Feature Learning Workshop; Socher, R., Lin, C.Y., Ng, A.Y., Parsing natural scenes and natural language with recursive neural networks (2012) International Conference on International Conference on Machine Learning. Omnipress, pp. 129-136; Socher, R., Perelygin, A., Wu, J., Recursive deep models for semantic compositionality over a sentiment treebank (2013) Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 1631-1642; https://www.i2b2.org/, I2B2, “Informatics for integrating biology & the bedside.” [Online] Available:; Yilmaz, E., Kanoulas, E., Aslam, J.A., A simple and efficient sampling method for estimating AP and NDCG (2008) International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, pp. 603-610; Krizhevsky, A., Sutskever, I., Hinton, G., ImageNet classification with deep convolutional neural networks (2012) NIPS; Mikolov, T., Karafiát, M., Burget, L., Recurrent neural network based language model (2010) 11st Annual Conference of the International Speech Communication Association; Yang, Z., Yang, D., Dyer, C., Hierarchical attention networks for document classification (2016) Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1480-1489; Richardson, M., Domingos, P., Markov logic networks (2006) Mach Learn, 63 (2). , pp. 207-207; http://i.stanford.edu/hazy/tuffy/, Project Tuffy, “Meet Tuffy.” [Online] Available:; Maaten, L.V.D., Hinton, G., Visualizing data using t-SNE (2017) J Mach Learn Res, 9 (2605), pp. 2579-2605",,,,,,Article,"Final","All Open Access, Green",Scopus,2-s2.0-85078077985
"Lemos H., Avelar P., Prates M., Garcez A., Lamb L.","56938175300;57208223911;57156187700;6603397393;10045847500;","Neural-Symbolic Relational Reasoning on Graph Models: Effective Link Inference and Computation from Knowledge Bases",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12396 LNCS",,,"647","659",,,"10.1007/978-3-030-61609-0_51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096590382&doi=10.1007%2f978-3-030-61609-0_51&partnerID=40&md5=5a1cfbec9e7c060a293c64f6e616f856","The recent developments and growing interest in neural-symbolic models has shown that hybrid approaches can offer richer models for Artificial Intelligence. The integration of effective relational learning and reasoning methods is one of the key challenges in this direction, as neural learning and symbolic reasoning offer complementary characteristics that can benefit the development of AI systems. Relational labelling or link prediction on knowledge graphs has become one of the main problems in deep learning-based natural language processing research. Moreover, other fields which make use of neural-symbolic techniques may also benefit from such research endeavours. There have been several efforts towards the identification of missing facts from existing ones in knowledge graphs. Two lines of research try and predict knowledge relations between two entities by considering all known facts connecting them or several paths of facts connecting them. We propose a neural-symbolic graph neural network which applies learning over all the paths by feeding the model with the embedding of the minimal subset of the knowledge graph containing such paths. By learning to produce representations for entities and facts corresponding to word embeddings, we show how the model can be trained end-to-end to decode these representations and infer relations between entities in a multitask approach. Our contribution is two-fold: a neural-symbolic methodology leverages the resolution of relational inference in large graphs, and we also demonstrate that such neural-symbolic model is shown more effective than path-based approaches. © 2020, Springer Nature Switzerland AG.","Graph neural networks; Neural-symbolic computing; Relational learning","Deep learning; Embeddings; Graph theory; Knowledge representation; Learning systems; Natural language processing systems; Complementary characteristics; Graph neural networks; NAtural language processing; Relational inferences; Relational learning; Relational reasoning; Symbolic reasoning; Symbolic techniques; Neural networks","Battaglia, P., (2018) Relational Inductive Biases, Deep Learning, and Graph Networks, , arXiv preprint arXiv; Bordes, A., Usunier, N., García-Durán, A., Weston, J., Yakhnenko, O., Translating embeddings for modeling multi-relational data (2013) Proceedings of NIPS, pp. 2787-2795; Brockschmidt, M., Allamanis, M., Gaunt, A.L., Polozov, O., (2018) Generative Code Modeling with Graphs; Das, R., Neelakantan, A., Belanger, D., McCallum, A., Chains of reasoning over entities, relations, and text using recurrent neural networks (2017) Proceedings of EACL, pp. 132-141. , 2017; Evans, R., Grefenstette, E., Learning explanatory rules from noisy data (2018) J. Artif. Intell. Res., 61, pp. 1-64; D’Avila Garcez, A., Gori, M., Lamb, L., Serafini, L., Spranger, M., Tran, S., Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning (2019) FLAP, 6 (4), pp. 611-632; Gilmer, J., Schoenholz, S.S., Riley, P.F., Vinyals, O., Dahl, G.E., Neural message passing for quantum chemistry (2017) Proceeding of ICML, pp. 1263-1272; Hu, J., Guo, C., Yang, B., Jensen, C.S., Chen, L., (2018) Recurrent Multi-Graph Neural Networks for Travel Cost Prediction; Lao, N., Mitchell, T.M., Cohen, W.W., Random walk inference and learning in a large scale knowledge base (2011) In: Proceeding of EMNLP 2011, pp. 529-539; Mao, J., Gan, C., Kohli, P., Tenenbaum, J.B., Wu, J., The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision (2019) ICLR 2019; Neelakantan, A., Roth, B., McCallum, A., Compositional vector space models for knowledge base completion (2015) Proceedings of ACL, pp. 156-166. , 2015; Nguyen, D.Q., Sirts, K., Qu, L., Johnson, M., Stranse: A novel embedding model of entities and relationships in knowledge bases (2016) NAACL HLT, 2016, pp. 460-466. , http://aclweb.org/anthology/N/N16/N16-1054.pdf; Raghavan, S., (2020) AI Predictions from IBM Research (2019)., , https://www.ibm.com/blogs/research/2019/12/2020-ai-predictions/, Accessed 14 Jan 2020; Riedel, S., Yao, L., McCallum, A., Marlin, B.M., Relation extraction with matrix factorization and universal schemas (2013) NAACL-HLT, pp. 74-84. , http://aclweb.org/anthology/N/N13/N13-1008.pdf; Schlichtkrull, M., Kipf, T.N., Bloem, P., van den Berg, R., Titov, I., Welling, M., Modeling relational data with graph convolutional networks (2018) ESWC 2018. LNCS, 10843, pp. 593-607. , https://doi.org/10.1007/978-3-319-93417-438, Gangemi, A., et al. (eds.) , Springer, Cham; Smolensky, P., (2019) Next-Generation Architectures Bridge Gap between Neural and Symbolic Representations with Neural Symbols, , https://www.microsoft.com/en-us/research/blog/next-generation-architectures-bridge-gap-between-neural-and-symbolic-representations-with-neural-symbols/, Accessed 14 Jan 2020; Socher, R., Chen, D., Manning, C.D., Ng, A.Y., Reasoning with neural tensor networks for knowledge base completion (2013) Proceeding of NIPS, pp. 926-934; Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., Yu, P.S., (2019) A Comprehensive Survey on Graph Neural Networks, , CoRR abs/1901.00596; Xiong, W., Hoang, T., Wang, W.Y., Deeppath: A reinforcement learning method for knowledge graph reasoning (2017) Proceedings of EMNLP, pp. 564-573. , 2017; Yin, W., Yaghoobzadeh, Y., Schütze, H., Recurrent one-hop predictions for reasoning over knowledge graphs (2018) Proceedings of COLING, 2018, pp. 2369-2378; Zhang, M., Chen, Y., Link prediction based on graph neural networks (2018) Proceeding of NIPS, pp. 5171-5181",,"29th International Conference on Artificial Neural Networks, ICANN 2020","15 September 2020 through 18 September 2020",,250349,Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85096590382
"Wang Y., Xia C., Si C., Yao B., Wang T.","57217003642;7201649913;26031096800;57217002358;35070755000;","Robust reasoning over heterogeneous textual information for fact verification",2020,"IEEE Access","8",,"9178311","157140","157150",,2,"10.1109/ACCESS.2020.3019586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091207880&doi=10.1109%2fACCESS.2020.3019586&partnerID=40&md5=0dcde93954508fe534c001ed1a88ae22","Automatic fact verification (FV) based on artificial intelligence is considered as a promising approach which can be used to identify misinformation distributed on the web. Even though previous FV using deep learning have made great achievements in single dataset (e.g., FEVER), the trained systems are unlikely to be capable of extracting evidence from heterogeneous web-sources and validating claims in accordance with evidence found on the Internet. Nevertheless, the heterogeneity covers abundant semantic information, which will help FV system identify misinformation in a more accurate way. The current work is the first attempt to make the combination of knowledge graph (KG) and graph neural network (GNN) to enhance the robustness of FV systems for heterogeneous information. As a result, it can be generalized to multi-domain datasets after training on a sufficient single one. To make information update and aggregate well on the collaborative graph, the present study proposes a double graph attention network (DGAT) framework which recursively propagates the embeddings from a node's neighbors to refine the node's embedding as well as applies an attention mechanism to classify the importance of the neighbors. We train and evaluate our system on FEVER, a single and benchmark dataset for FV, and then re-evaluate our system on UKP Snopes Corpus, a new richly annotated corpus for FV tasks on the basis of heterogeneous web sources. According to experimental results, although DGAT has no excellent advantages in a single dataset, it shows outstanding performance in more realistic and multi-domain datasets. Moreover, the current study also provides a feasible method for deep learning to have the ability to infer heterogeneous information robustly. © 2013 IEEE.","Fact verification; graph neural network; heterogeneous information; robust reasoning","Deep learning; Embeddings; Knowledge representation; Learning systems; Neural networks; Semantics; Websites; Attention mechanisms; Benchmark datasets; Graph neural networks; Heterogeneous information; Information updates; Knowledge graphs; Semantic information; Textual information; Classification (of information)","Jiang, S., Baumgartner, S., Ittycheriah, A., Yu, C., Factoring factchecks: Structured information extraction from fact-checking articles (2020) Proc. Web Conf., pp. 1592-1603. , Apr; Thorne, J., Vlachos, A., Christodoulopoulos, C., Mittal, A., (2018) FEVER: A Large-scale Dataset for Fact Extraction and Verification, , http://arxiv.org/abs/1803.05355; Thorne, J., Vlachos, A., Cocarascu, O., Christodoulopoulos, C., Mittal, A., (2018) The Fact Extraction and Verification (FEVER) Shared Task, , http://arxiv.org/abs/1811.10971; Zhou, J., Han, X., Yang, C., Liu, Z., Wang, L., Li, C., Sun, M., (2019) GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification, , http://arxiv.org/abs/1908.01843; Nie, Y., Chen, H., Bansal, M., Combining fact extraction and verification with neural semantic matching networks (2019) Proc. Aaai Conf. Artif. Intell., 33, pp. 6859-6866; Fan, C.-T., Wang, Y.-K., Huang, C.-R., Heterogeneous information fusion and visualization for a large-scale intelligent video surveillance system (2017) Ieee Trans. Syst., Man, Cybern. Syst., 47 (4), pp. 593-604. , Apr; Zhang, X., Zhang, Y., Wang, S., Yao, Y., Fang, B., Yu, P.S., Improving stock market prediction via heterogeneous information fusion (2018) Knowl.-Based Syst., 143, pp. 236-247. , Mar; Wang, F., Hu, L., Zhou, J., Hu, J., Zhao, K., A semantics-based approach to multi-source heterogeneous information fusion in the Internet of Things (2017) Soft Comput., 21 (8), pp. 2005-2013. , Apr; Li, G., Kou, G., Peng, Y., A group decision making model for integrating heterogeneous information (2018) Ieee Trans. Syst., Man, Cybern. Syst., 48 (6), pp. 982-992. , Jun; Qiu, R.G., Towards ontology-driven knowledge synthesis for heterogeneous information systems (2006) J. Intell. Manuf., 17 (1), pp. 99-109; Hu, B., Shi, C., Zhao, W.X., Yang, T., Local and global information fusion for top-N recommendation in heterogeneous information network (2018) Proc. 27th Acm Int. Conf. Inf. Knowl. Manage., pp. 1683-1686. , Oct; Wang, X., Ji, H., Shi, C., Wang, B., Ye, Y., Cui, P., Yu, P.S., Heterogeneous graph attention network (2019) Proc. World Wide Web Conf. (WWW), pp. 2022-2032; Ai, Q., Azizi, V., Chen, X., Zhang, Y., Learning heterogeneous knowledge base embeddings for explainable recommendation (2018) Algorithms, 11 (9), p. 137. , Sep; Wang, X., He, X., Cao, Y., Liu, M., Chua, T.-S., KGAT: Knowledge graph attention network for recommendation (2019) Proc. 25th Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 950-958. , Jul; Zhong, W., Xu, J., Tang, D., Xu, Z., Duan, N., Zhou, M., Wang, J., Yin, J., (2019) Reasoning over Semantic-level Graph for Fact Checking, , http://arxiv.org/abs/1909.03745; Hanselowski, A., Stab, C., Schulz, C., Li, Z., Gurevych, I., (2019) A Richly Annotated Corpus for Different Tasks in Automated Fact-checking, , http://arxiv.org/abs/1911.01214; Luken, J., Jiang, N., De Marneffe, M.-C., QED: A fact verification system for the FEVER shared task (2018) Proc. 1stWorkshop Fact Extraction Verification (FEVER), pp. 156-160; Parikh, A.P., Täckström, O., Das, D., Uszkoreit, J., (2016) A Decomposable Attention Model for Natural Language Inference, , http://arxiv.org/abs/1606.01933; Hanselowski, A., Zhang, H., Li, Z., Sorokin, D., Schiller, B., Schulz, C., Gurevych, I., (2018) UKP-athene: Multi-sentence Textual Entailment for Claim Verification, , http://arxiv.org/abs/1809.01479; Yoneda, T., Mitchell, J., Welbl, J., Stenetorp, P., Riedel, S., UCL machine reading group: Four factor framework for fact finding (HexaF) (2018) Proc. 1st Workshop Fact Extraction Verification (FEVER), pp. 97-102; Hidey, C., Diab, M., Team SWEEPer: Joint sentence extraction and fact checking with pointer networks (2018) Proc. 1st Workshop Fact Extraction Verification (FEVER), pp. 150-155; Chen, Q., Zhu, X., Ling, Z., Wei, S., Jiang, H., Inkpen, D., (2016) Enhanced Lstm for Natural Language Inference, , http://arxiv.org/abs/1609.06038; Malon, C., (2019) Team Papelo: Transformer Networks at Fever, , http://arxiv.org/abs/1901.02534; Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., (2018) Improving Language Understanding by Generative Pre-Training, , https://s3-us-west-2.amazonaws.com/openai-assets/researchcovers/languageunsupervised/languageunderstandingpaper.pdf; Zhao, C., Xiong, C., Rosset, C., Song, X., Bennett, P., Tiwary, S., Transformer-XH: Multi-evidence reasoning with extra hop attention (2019) Proc. Int. Conf. Learn. Represent., pp. 1-16; Liu, Z., Xiong, C., Sun, M., Liu, Z., Fine-grained fact verification with kernel graph attention network (2020) Proc. 58th Annu. Meeting Assoc. Comput. Linguistics, pp. 7342-7351; Shi, P., Lin, J., (2019) Simple Bert Models for Relation Extraction and Semantic Role Labeling, , http://arxiv.org/abs/1904.05255; Dagan, I., Glickman, O., Magnini, B., The PASCAL recognising textual entailment challenge (2005) Proc. Mach. Learn. Challenges Workshop. Berlin, pp. 177-190. , Germany: Springer; Williams, A., Nangia, N., Bowman, S.R., (2017) A Broad-coverage Challenge Corpus for Sentence Understanding through Inference, , http://arxiv.org/abs/1704.05426; Bowman, S.R., Angeli, G., Potts, C., Manning, C.D., (2015) A Large Annotated Corpus for Learning Natural Language Inference, , http://arxiv.org/abs/1508.05326; Sha, L., Chang, B., Sui, Z., Li, S., Reading and thinking: Re-read LSTM unit for textual entailment recognition (2016) Proc. Coling, pp. 2870-2879. , 26th Int. Conf. Comput. Linguistics, Tech. Papers; Conneau, A., Kiela, D., Schwenk, H., Barrault, L., Bordes, A., (2017) Supervised Learning of Universal Sentence Representations from Natural Language Inference Data, , http://arxiv.org/abs/1705.02364; Ghaeini, R., Hasan, S.A., Datla, V., Liu, J., Lee, K., Qadir, A., Ling, Y., Farri, O., (2018) DR-BiLSTM: Dependent Reading Bidirectional Lstm for Natural Language Inference, , http://arxiv.org/abs/1802.05577; Xu, K., Hu, W., Leskovec, J., Jegelka, S., (2018) How Powerful Are Graph Neural Networks?, , http://arxiv.org/abs/1810.00826; Kipf, T.N., Welling, M., (2016) Semi-supervised Classification with Graph Convolutional Networks, , http://arxiv.org/abs/1609.02907; Velikovi, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y., (2017) Graph Attention Networks, , http://arxiv.org/abs/1710.10903; Carreras, X., Màrquez, L., Introduction to the CoNLL-2005 shared task: Semantic role labeling (2005) Proc. 9th Conf. Comput. Natural Lang. Learn. (CONLL), pp. 152-164; Fellbaum, C., Word net (2012) the Encyclopedia of Applied Linguistics. Oxford, , U.K.: Blackwell; Cao, Y., Wang, X., He, X., Hu, Z., Chua, T.-S., Unifying knowledge graph learning and recommendation: Towards a better understanding of user preferences (2019) Proc. World Wide Web Conf. (WWW), pp. 151-161; Speer, R., Chin, J., Havasi, C., ConceptNet 5.5: An open multilingual graph of general knowledge (2017) Proc. Nat. Conf. Artif. Intell., pp. 4444-4451; Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R.R., Le, Q.V., Xlnet: Generalized autoregressive pretraining for language understanding (2019) Proc. Adv. Neural Inf. Process. Syst., pp. 5753-5763; Lin, Y., Liu, Z., Sun, M., Liu, Y., Zhu, X., Learning entity and relation embeddings for knowledge graph completion (2015) Proc. 29th Aaai Conf. Artif. Intell., pp. 2181-2187; Bollacker, K., Evans, C., Paritosh, P., Sturge, T., Taylor, J., Freebase: A collaboratively created graph database for structuring human knowledge (2008) Proc. Acm Sigmod Int. Conf. Manage. Data, pp. 1247-1250; Qiu, J., Tang, J., Ma, H., Dong, Y., Wang, K., Tang, J., DeepInf: Social influence prediction with deep learning (2018) Proc. 24th Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, London, U.K., pp. 2110-2119; Hamilton, W.L., Ying, R., Leskovec, J., Inductive representation learning on large graphs (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 1024-1034. , Long Beach, CA, USA; Shen, D., Zhang, X., Henao, R., Carin, L., (2018) Improved Semanticaware Network Embedding with Fine-grained Word Alignment, , http://arxiv.org/abs/1808.09633",,,,,,Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85091207880
"Gong J., Ma H., Teng Z., Teng Q., Zhang H., Du L., Chen S., Bhuiyan M.Z.A., Li J., Liu M.","35172721500;57198976028;57212304055;57215526026;57216241085;57212309820;57204474933;35184906400;57196156907;55743438600;","Hierarchical Graph Transformer-Based Deep Learning Model for Large-Scale Multi-Label Text Classification",2020,"IEEE Access","8",,"8988213","30885","30896",,6,"10.1109/ACCESS.2020.2972751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081058031&doi=10.1109%2fACCESS.2020.2972751&partnerID=40&md5=1376cf7721ed6ff3f046f7ca9e9b4415","Traditional methods of multi-label text classification, particularly deep learning, have achieved remarkable results. However, most of these methods use word2vec technology to represent sequential text information, while ignoring the logic and internal hierarchy of the text itself. Although these approaches can learn the hypothetical hierarchy and logic of the text, it is unexplained. In addition, the traditional approach treats labels as independent individuals and ignores the relationships between them, which not only does not reflect reality but also causes significant loss of semantic information. In this paper, we propose a novel Hierarchical Graph Transformer based deep learning model for large-scale multi-label text classification. We first model the text into a graph structure that can embody the different semantics of the text and the connections between them. We then use a multi-layer transformer structure with a multi-head attention mechanism at the word, sentence, and graph levels to fully capture the features of the text and observe the importance of the separate parts. Finally, we use the hierarchical relationship of the labels to generate the representation of the labels, and design a weighted loss function based on the semantic distances of the labels. Extensive experiments conducted on three benchmark datasets demonstrated that the proposed model can realistically capture the hierarchy and logic of text and improve performance compared with the state-of-the-art methods. © 2013 IEEE.","deep learning; graph modeling; graph transformer; Multi-label text classification","Benchmarking; Classification (of information); Computer circuits; Graph structures; Learning systems; Semantics; Text processing; Attention mechanisms; Graph model; graph transformer; Multi-label text classification; State-of-the-art methods; Traditional approaches; Transformer structure; Weighted loss function; Deep learning","Ali, T., Asghar, S., Multi-label scientific document classification (2018) J. Internet Technol., 19 (6), pp. 1707-1716; Liu, L., Mu, F., Li, P., Mu, X., Tang, J., Ai, X., Fu, R., Zhou, X., Neuralclassifier: An open-source neural hierarchical multi-label text classification toolkit (2019) Proc. 57th Annu. Meeting Assoc. Comput. Linguistics, Syst. Demonstrations, pp. 87-92; Liu, J., Chang, W.-C., Wu, Y., Yang, Y., Deep learning for extreme multi-label text classification (2017) Proc. 40th Int. ACM SIGIR Conf. Res. Develop. Inf. Retr. (SIGIR), pp. 115-124; Frank Cooper, J.K., Multiobjective feature selection: Classification using educational datasets in an ensemble validation scheme (2019) Data Sci. Pattern Recognit., 3 (1), pp. 9-34; Aggarwal, C.C., Zhai, C., (2012) Mining Text Data, , Berlin, Germany: Springer; Stein, R.A., Jaques, P.A., Valiati, J.F., An analysis of hierarchical text classification using word embeddings (2019) Inf. Sci., 471, pp. 216-232. , Jan; Revanasiddappa, M.B., Harish, B.S., A novel text representation model to categorize text documents using convolution neural network (2019) Int. J. Intell. Syst. Appl., 11 (5), pp. 36-45. , May; Xie, M., Yin, H., Wang, H., Xu, F., Chen, W., Wang, S., Learning graph-based POI embedding for location-based recommendation (2016) Proc. 25th ACM Int. Conf. Inf. Knowl. Manage. (CIKM), pp. 15-24; Li, J., Peng, H., Liu, L., Xiong, G., Du, B., Ma, H., Wang, L., Zakirul Alam Bhuiyan, M., Graph CNNs for urban traffic passenger flows prediction (2018) Proc. IEEE SmartWorld, Ubiquitous Intell. Comput., Adv. Trusted Comput., Scalable Comput. Commun., Cloud Big Data Comput., Internet People Smart City Innov. (Smart-World/SCALCOM/UIC/ATC/CBDCom/IOP/SCI), pp. 29-36. , Oct; Peng, H., Li, J., Gong, Q., Song, Y., Ning, Y., Lai, K., Yu, P.S., Finegrained event categorization with heterogeneous graph convolutional networks (2019) Proc. Int. Joint Conf. Artif. Intell., pp. 1-9; Peng, H., Li, J., He, Y., Liu, Y., Bao, M., Wang, L., Song, Y., Yang, Q., Large-scale hierarchical text classification with recursively regularized deep graph-cnn (2018) Proc. World Wide Web Conf., Int. World Wide Web Conf. Steering Committee, pp. 1063-1072; Peng, H., Li, J., Wang, S., Wang, L., Gong, Q., Yang, R., Li, B., He, L., Hierarchical taxonomy-aware and attentional graph capsule RCNNs for large-scale multi-label text classification IEEE Trans. Knowl. Data Eng., , to be published; Peng, H., Du, B., Ma, H., Bhuiyan, M.Z.A.B., Jianwei, L., Wang, L., Yu, P.S., Spatial temporal incidence dynamic graph neural networks for traffic flow forecasting Inf. Sci., , to be published; He, Y., Li, J., Song, Y., He, M., Peng, H., Time-evolving text classification with deep neural networks (2018) Proc. 27th Int. Joint Conf. Artif. Intell., pp. 2241-2247. , Jul; Kao, C.-C., Chang, J.-W., Wang, T.-I., Huang, Y.-M., Chiu, P.-S., Design and development of the sentence-based collocation recommender with error detection for academic writing (2019) J. Internet Technol., 20 (1), pp. 229-236; Liu, P., Qiu, X., Huang, X., (2016) Recurrent Neural Network for Text Classification with Multi-task Learning, , http://arxiv.org/abs/1605.05101; Shen, T., Zhou, T., Long, G., Jiang, J., Zhang, C., (2018) Bi-directional Block Self-attention for Fast and Memory-efficient Sequence Modeling, , http://arxiv.org/abs/1804.00857; Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y., Show, attend and tell: Neural image caption generation with visual attention (2015) Proc. Int. Conf. Mach. Learn., pp. 2048-2057; Donahue, J., Hendricks, L.A., Rohrbach, M., Venugopalan, S., Guadarrama, S., Saenko, K., Darrell, T., Long-term recurrent convolutional networks for visual recognition and description (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (4), pp. 677-691. , Apr; Dos Santos, C., Gatti, M., Deep convolutional neural networks for sentiment analysis of short texts (2014) Proc. 25th Int. Conf. Comput. Linguistics (COLING), pp. 69-78; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. 22nd ACM Int. Conf. Multimedia, pp. 675-678; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2017) Commun. ACM, 60 (6), pp. 84-90. , May; Arif, M.H., Li, J., Iqbal, M., Peng, H., Optimizing XCSR for text classification (2017) Proc. IEEE Symp. Service-Oriented System Eng. (SOSE), pp. 86-95. , Apr; Dong, L., Zhao, H., Hierarchical feature selection with orthogonal transfer (2019) J. Internet Technol., 20 (4), pp. 1205-1212; Nickel, M., Kiela, D., Poincare embeddings for learning hierarchical representation (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 6338-6347; Ye, J., Ni, J., Yi, Y., Deep learning hierarchical representations for image steganalysis (2017) IEEE Trans. Inf. Forensics Security, 12 (11), pp. 2545-2557. , Nov; Lee, H., Grosse, R., Ranganath, R., Ng, A.Y., Unsupervised learning of hierarchical representations with convolutional deep belief networks (2011) Commun. ACM, 54 (10), p. 95. , Oct; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 5998-6008; Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, , http://arxiv.org/abs/1810.04805; Chiu, B., Crichton, G., Korhonen, A., Pyysalo, S., How to train good word embeddings for biomedical NLP (2016) Proc. 15th Workshop Biomed. Natural Lang. Process, pp. 166-174; Bengio, Y., Ducharme, R., Vincent, P., Jauvin, C., A neural probabilistic language model (2003) J. Mach. Learn. Res., 3, pp. 1137-1155. , Feb; Lewis, D.D., Yang, Y., Rose, T.G., Li, F., RCV1: A new benchmark collection for text categorization research (2004) J. Mach. Learn. Res., 5, pp. 361-397. , Dec; Agrawal, R., Gupta, A., Prabhu, Y., Varma, M., Multi-label learning with millions of labels: Recommending advertiser bid phrases for Web pages (2013) Proc. 22ndInt. Conf. World Wide Web, pp. 13-24; Conneau, A., Schwenk, H., Barrault, L., Lecun, Y., (2016) Very Deep Convolutional Networks for Text Classification, , http://arxiv.org/abs/1606.01781; Chen, H., Sun, M., Tu, C., Lin, Y., Liu, Z., Neural sentiment classification with user and product attention (2016) Proc. Conf. Empirical Methods Natural Lang. Process., pp. 1650-1659; Wehrmann, J., Cerri, R., Barros, R., Hierarchical multi-label classification networks (2018) Proc. Int. Conf. Mach. Learn., pp. 5225-5234; Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., Hovy, E., Hierarchical attention networks for document classification (2016) Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics, Hum. Lang. Technol., pp. 1480-1489; Gopal, S., Yang, Y., Hierarchical Bayesian inference and recursive regularization for large-scale classification (2015) ACM Trans. Knowl. Discov. Data, 9 (3), pp. 1-23. , Apr; Prabhu, Y., Varma, M., Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning (2014) Proc. 20th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 263-272; Bhatia, K., Jain, H., Kar, P., Varma, M., Jain, P., Sparse local embeddings for extreme multi-label classification (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 730-738; Prabhu, Y., Kag, A., Harsola, S., Agrawal, R., Varma, M., Para-bel: Partitioned label trees for extreme classification with application to dynamic search advertising (2018) Proc. World Wide Web Conf., pp. 993-1002; Pennington, J., Socher, R., Manning, C., Glove: Global vectors for word representation (2014) Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1532-1543; Liu, Y., Peng, H., Li, J., Song, Y., Li, X., Event detection and evolution in multi-lingual social streams (2019) Frontiers Comput. Sci., pp. 1-23; Myroniv, B., Wu, C., Ren, Y., Christian, A., Bajo, E., Tseng, Y.C., Analyzing user emotions via physiology signals (2017) Data Sci. Pattern Recognit., 1 (2), pp. 11-25; Zhang, Y., Jin, R., Zhou, Z.-H., Understanding bag-of-words model: A statistical framework (2010) Int. J. Mach. Learn. Cyber., 1 (11), pp. 43-52. , Dec; Filliat, D., A visual bag of words method for interactive qualitative localization and mapping (2007) Proc. IEEEInt. Conf. Robot. Autom., pp. 3921-3926. , Apr; Ramos, J., Using TF-IDF to determine word relevance in document queries (2003) Proc. 1st Instructional Conf. Mach. Learn., 242, pp. 133-142. , Piscataway, NJ, USA; Aizawa, A., An information-theoretic perspective of TF-IDF measures (2003) Inf. Process. Manage., 39 (1), pp. 45-65. , Jan; Wu, B., Li, C., Wang, B., Event detection and evolution based on entity separation (2011) Proc. 8th Int. Conf. Fuzzy Syst. Knowl. Discovery (FSKD), pp. 1-7. , Jul; Rousseau, F., Kiagias, E., Vazirgiannis, M., Text categorization as a graph classification problem (2015) Proc. 53rd Annu. Meeting Assoc. Com-put. Linguistics, 7th Int. Joint Conf. Natural Language Process., 1, pp. 1702-1712; Peng, H., Li, J., Gong, Q., Wang, S., Ning, Y., Yu, P.S., (2018) Graph Convolutional Neural Networks Via Motif-based Attention, , http://arxiv.org/abs/1811.08270; Mao, Q., Li, J., Wang, S., Zhang, Y., Peng, H., He, M., Wang, L., Aspect-based sentiment classification with attentive neural turing machines (2019) Proc. 28thInt. Joint Conf. Artif. Intell., pp. 5139-5145. , Aug; Lai, S., Xu, L., Liu, K., Zhao, J., Recurrent convolutional neural networks for text classification (2015) Proc. 29th AAAI Conf. Artif. Intell., pp. 2267-2273; Hochreiter, S., Schmidhuber, J., LSTM can solve hard long time lag problems (1997) Proc. Adv. Neural Inf. Process. Syst., pp. 473-479; Cho, K., Van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., (2014) Learning Phrase Representations Using Rnn Encoder-decoder for Statistical Machine Translation, , http://arxiv.org/abs/1406.1078; Ko-Wei Huang, Y.-M.L., Lin, C.-C., Wu, Z.-X., A deep learning and image recognition system for image recognition (2019) Data Sci. Pattern Recognit., 3 (2), pp. 1-23; Peng, H., Li, J., Song, Y., Liu, Y., Incrementally learning the hierarchical softmax function for neural language models (2017) Proc. 31st AAAI Conf. Artif. Intell., pp. 3267-3273. , London, U.K.: AAAI Press; Peng, H., Bao, M., Li, J., Bhuiyan, M., Liu, Y., He, Y., Yang, E., Incremental term representation learning for social network analysis (2018) Future Gener. Comput. Syst., 86, pp. 1503-1512. , Sep",,,,,,Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85081058031
"Sarwar S., Qayyum Z.U., García-Castro R., Safyan M., Munir R.F.","26668090800;36538522000;13404965900;26422483100;54384067100;","Ontology based E-learning framework: A personalized, adaptive and context aware model",2019,"Multimedia Tools and Applications","78","24",,"34745","34771",,15,"10.1007/s11042-019-08125-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071338621&doi=10.1007%2fs11042-019-08125-8&partnerID=40&md5=04020cef4e95df52dca712468616dd68","Enhancing the degree of learner productivity, one of the major challenges in E-Learning systems, may be catered through effective personalization, adaptivity and context awareness while recommending the learning contents to the learners. In this paper, an E-Learning framework has been proposed that profiles the learners, categorizes the learners based on profiles, makes personalized content recommendations and performs assessment based content adaptation. A mathematical model has been proposed for learner categorization using machine learning techniques (a hybrid of case based reasoning and neural networks). The learning contents have been annotated through CourseOntology in which three academic courses (each for language of C++, C# and JAVA) have been modeled for the learners. A dynamic rule based recommender has been presented targeting a ‘relative grading system’ for maximizing the learner’s productivity. Performance of proposed framework has been measured in terms of accurate learner categorization, personalized recommendation of the learning contents, completeness and correctness of ontological model and overall performance improvement of learners in academic sessions of 2015, 2016 and 2017. The comparative analysis of proposed framework exhibits visibly improved results compared to prevalent approaches. These improvements are signified to the comprehensive attribute selection in learner profiling, dynamic techniques for learner categorization and effective content recommendation while ensuring personalization and adaptivity. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Adaptivity; Content Recommender; E-Learning; Ontologies; Personalization","C++ (programming language); Case based reasoning; E-learning; Grading; Ontology; Productivity; Adaptivity; Content recommendations; Content Recommender; Context-aware models; Machine learning techniques; Ontology-based e-learning; Personalizations; Personalized recommendation; Learning systems","Aamodt, A., Plaza, E., Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches (1994) AI Commun, 7 (1), pp. 39-59; Arditi, D., Tokdemir, B., Comparison of Case-Based Reasoning and Artificial INeural Networks (1999) J Comput Civ Eng, 13 (3), pp. 578-583; Bates, T., (2005) Technology, e-learning and distance education, , Routledge, London; Bouquet, P., Molinari, A., Using Semantic Technologies in E-Learning Platforms: A Case Study (2016) International Journal of Information and Education Technology, 6 (5); Bozkurt, A., Akgun-Ozbek, E., Trends in Distance Education Research: A Content Analysis of Journals 2009-2013 (2015) Int Rev Res Open Dist Learn, 16 (1), pp. 330-363; Connolly, P., Neill, J., Constructions of locality and gender and their impact on the educational aspirations of working class children (2011) Int Stud Sociol Educ, 11 (2), pp. 107-130; David, P., A Design Requirements Framework for Distance Learning Environments (2007) J Comput, 2 (4), pp. 99-113; Ergen, T., Kozat, S.S., Neural Networks based Online Learning (2017) IEEE 25th Signal Processing and Communications Applications Conference; https://www.scribd.com/document/165064823/GAT-Subject-Syllabus, GAT Test Bank Accessed on Oct 2016; Guarino, N., Welty, C.A., An Overview of OntoClean (2004) Handbook on Ontologies, pp. 151-171. , Springer Berlin Heidelberg, Berlin, Heidelberg; Jahankhani, H., Tawil, R., Adaptive E-learning Approach based on Semantic Web Technology (2015) International Journal of Webology, 10 (2); Kaur, P., Classification and prediction based on DM algorithm for slow learners (2015) International Conference on Recent Trends in Computing; Lafore, R., (2001) Object-Oriented Programming in C++, , Sams Publishing, Published December 29th; Liem, B., Beek, W., Gracia, J., Lozano, E., DynaLearn–An Intelligent Learning Environment for Learning Conceptual Knowledge (2013) AI Mag, 34 (4), pp. 46-65; Lin, C.C., A case study on SCORM – based eLearning in computer aided drafting course with user satisfaction survey (2008) WSEAS Trans Inf Sci Appl, 5 (10), pp. 1416-1427; Luis, E., Rofio, A., A recommender system for educational resources in specific learning content (2013) International Conference on Computer Science and Education; Mihăescu, M.C., Classification of Learners Using Linear Regression (2011) Proceedings of the Federated Conference on Computer Science and Information Systems, pp. 717-721. , ISBN 978-83-60810-22-4; Mohammad, T.Z., Mahmoud, A.M., Classification Model of English Course e-Learning System for Slow Learners “Recent Advances in Information Science (2014) International Journal of Computer Science (IIJCS, , 978-960-474-304-9; (2015) OOP Quizes, , https://www.tutorialspoint.com/cplusplus/cpp_online_quiz.htm, Accessed on Sep; Poveda-Villalón, M., Suárez-Figueroa, M.C., Gómez-Pérez, A., Validating Ontologies with OOPS! (2012) Lecture Notes in Computer Science, pp. 267-281. , Springer Berlin Heidelberg, Berlin, Heidelberg; Rani, M., Srivastava, K.V., Vyas, O.P., An Ontological Learning Management System (2016) Comput Appl Eng Educ, 24 (5), pp. 706-722; Romero, C., Ventura, S., Educational Data Mining: A Survey from 1995 to 2005 (2007) Expert Syst Appl, 33 (1), pp. 135-146; Safyan, M., Qayyum, Z., Sarwar, S., (2017) Context-Aware Personalized Activity Modeling in Concurrent Environment, , Internet of Things (IoT; Salam, F., Shambour, Q., A Framework of semantic recommender system for e-learning (2015) Journal of Software, 10, pp. 317-330; Saleena, B., Srivastava, K., Using concept similarity in cross ontology for adaptive e-learning (2015) Journal of King Saud University- Computer and Information Sciences, 27 (1), pp. 1-12; Sarma Cakula, M.S., Development of Personalized e-learning model (2013) ICTE in Regional Development, 26 (4), pp. 113-120; Sarwar, S., Ul Qayyum, Z., Castro, R.G., Safyan, M., Ontology based E-learning Systems: A Step towards context aware content recommendation (2018) International Journal of Information and Educational Technology, 8 (10), pp. 10-19; Sarwar, S., García-Castro, R., Qayyum, Z.U., Safyan, M., Ontology-based Learner Categorization through Case Based Reasoning and Fuzzy Logic (2017) International Conference on E-Learning (IADIS), pp. 159-163; Sarwar, S., Ul Qayyum, Z., Safyan, M., Munir, F., (2016) Ontology Based Adaptive, Semantic E-Learning Framework (OASEF), , Springer LNEE ICISA; Seteres, V., Ossevroot, M.A., Influence of student characteristics on use of adaptive e-learning material (2012) Int Journal of Computers & Education, 58 (3), pp. 942-952; Shen, L., Shen, R., Ontology based Content Recommendation (2005) International Journal of Continued Engineering and Education, 15 (1), pp. 13-26; Shute, V., Towle, B., Adaptive e-learning (2010) Educ Psychol, 38 (2), pp. 105-114; Strumiłło, P., Kamiński, W., Radial Basis Function Neural Networks: Theory and Applications, Neural Networks and Soft Computing (2013) Advances in Soft Computing, 19 (5), pp. 107-119; Tambe, S., Kadam, G., An Efficient framework for E-Learning Recommendation system using fuzzy Logic and Ontology (2016) International Research Journal of Engineering and Technology (IRJET), 3 (6), pp. 2062-2067; Vanbelle, S., A New Interpretation of the Weighted Kappa Coefficients (2016) Psychometrica, 81 (2), pp. 399-410; Viola, S.R., Graf, S., Kinshuk, T.L., Analysis of Felder-Silverman Index of Learning Styles by a Data-driven Statistical Approach (2006) IEEE International Symposium on Multimedia (ISM'06), pp. 7695-7704; West, D.M., Learning, M., Transforming Education, Engaging Students and Improving Outcomes (2013) International Journal of ICT, E-Management and E-Learning, 4; Yarandi, M., A Personalized Adaptive E-Learning Approach Based On Semantic Web Technology (2013) Journal of Webology, 10 (2), pp. 751-766; Yarandi, M., Jahankhani, H., Tawil, A.-R., A personalized adaptive e-learning approach based on semantic web technology (2013) Webology, 10 (2); Yathongchai, C., Leamer Classification Based on Learning Behavior and Performance (2013) IEEE Conference on Open Systems, , ICOS",,,,,,Article,"Final","",Scopus,2-s2.0-85071338621
"Schon C., Siebert S., Stolzenburg F.","53881954300;57194032036;55887001400;","The CoRg Project: Cognitive Reasoning",2019,"KI - Kunstliche Intelligenz","33","3",,"293","299",,3,"10.1007/s13218-019-00601-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077011935&doi=10.1007%2fs13218-019-00601-5&partnerID=40&md5=e6edfc5075a223b3bbc5a5cbd192fc8c","The term cognitive computing refers to new hardware and/or software that mimics the functioning of the human brain. In the context of question answering and commonsense reasoning this means that the reasoning process of humans shall be modeled by adequate technical means. However, since humans do not follow the rules of classical logic, a system designed to model these abilities must be very versatile. The aim of the CoRg project (Cognitive Reasoning) is to successfully complete a reasoning task with commonsense reasoning. We address different benchmarks with focus on the COPA benchmark set (Choice of Plausible Alternatives). Since humans naturally use background knowledge, we have to deal with large background knowledge bases and must be able to reason with multiple input formats and sources in the CoRg system, in order to draw explainable conclusions. For this, we have to find appropriate logics for cognitive reasoning. For a successful reasoning system, nowadays it seems to be important to combine automated reasoning with machine learning technology like recurrent neural networks. © 2019, Gesellschaft für Informatik e.V. and Springer-Verlag GmbH Germany, part of Springer Nature.","Automated reasoning; Cognitive reasoning; Commonsense reasoning; Machine learning",,"Álvez, J., Lucio, P., Rigau, G., Adimen-SUMO: reengineering an ontology for first-order reasoning (2012) Int J Semant Web Inf Syst, 8 (4), pp. 80-116; Basile, V., Cabrio, E., Schon, C., KNEWS: Using logical and lexical semantics to extract knowledge from natural language (2016) Proceedings of the European Conference on Artificial Intelligence (ECAI) 2016 Conference; Bender, M., Pelzer, B., Schon, C., System description: E-KRHyper 1.4 (2013) International Conference on Automated Deduction, pp. 126-134. , Springer; Byrne, R.M.J., Johnson-Laird, P.N., ’if’ and the problems of conditional reasoning (2009) Trends Cogn Sci, 13, pp. 282-287; Cariani, F., Grossi, D., Meheus, J., Parent, X., (2014) Deontic Logic and Normative systems—12th International Conference, DEON 2014, Ghent, Belgium, Proceedings, p. 8554. , https://doi.org/10.1007/978-3-319-08615-6, LNAI, Springer; d’Avila Garcez, A.S., Broda, K., Gabbay, D.M., Symbolic knowledge extraction from trained neural networks: a sound approach (2001) Artif Intell, 125 (1-2), pp. 155-207; Furbach, U., Schon, C., Commonsense reasoning meets theorem proving (2016) Proceedings, Lecture Notes in Computer Science, 9872, pp. 3-17. , https://doi.org/10.1007/978-3-319-45889-2_1, M. Klusch, R. Unland, O. Shehory, A. Pokahr, S. Ahrndt (eds.) Multiagent System Technologies—14th German Conference, MATES 2016, Klagenfurt, Österreich, September 27-30, Springer; Furbach, U., Schon, C., Stolzenburg, F., Weis, K.H., Wirth, C.P., The RatioLog project: rational extensions of logical reasoning (2015) KI, 29 (3), pp. 271-277; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Hoder, K., Voronkov, A., Sine qua non for large theory reasoning (2011) Automated deduction - CADE-23, 6803, pp. 299-314. , Bjørner N, Sofronie-Stokkermans V, (eds), Lecture notes computer science, Springer, Berlin; Johnson-Laird, P.N., (1983) Mental models: towards a cognitive science of language, inference, and consciousness, , Cambridge University Press, Cambridge; Khemlani, S.S., Barbey, A.K., Johnson-Laird, P.N., Causal reasoning with mental models (2014) Front Hum Neurosci, 8, p. 849; Lenat, D.B., Cyc: a large-scale investment in knowledge infrastructure (1995) Commun ACM, 38 (11), pp. 33-38; Levesque, H.J., The winograd schema challenge (2011) Logical Formalizations of Commonsense Reasoning, Papers from the 2011 AAAI Spring Symposium, Technical Report SS-11-06, , http://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2502, Stanford, California, USA, March 21-23, 2011. AAAI; Luo, Z., Sha, Y., Zhu, K.Q., Won Hwang S, Wang Z Commonsense causal reasoning between short texts (2016) Proceeding of 15Th Int. Conf. on Principles of Knowledge Representation and Reasonging (KR’2016, , Cape Town, South Africa; Maslan, N., Roemmele, M., Gordon, A.S., One hundred challenge problems for logical formalizations of commonsense psychology (2015) Twelfth International Symposium on Logical Formalizations of Commonsense Reasoning, , Stanford, CA; Miller, G.A., WordNet: a lexical database for english (1995) Commun ACM, 38 (11), pp. 39-41; Mostafazadeh, N., Roth, M., Louis, A., Chambers, N., Allen, J., LSDSem 2017 shared task: The story cloze test (2017) Proceedings of the 2Nd Workshop on Linking Models of Lexical, Sentential and Discourse-Level Semantics, pp. 46-51; Niles, I., Pease, A., Towards a standard upper ontology (2001) Proceedings of the International Conference on Formal Ontology in Information Systems-, 2001, pp. 2-9. , ACM; Nute, D., Defeasible deontic logic (1997) Synthese Library: Studies in Epistemology, Logic, Methodology, and Philosophy of Science, 263. , https://doi.org/10.1007/978-94-015-8851-5, Springer, Berlin; Ostermann, S., Roth, M., Modi, A., Thater, S., Pinkal, M., SemEval-2018 task 11: Machine comprehension using commonsense knowledge (2018) Proceedings of the 12Th International Workshop on Semantic Evaluation, pp. 747-757; Roemmele, M., Bejan, C.A., Gordon, A.S., Choice of plausible alternatives: An evaluation of commonsense causal reasoning (2011) AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning; Siebert, S., Schon, C., Stolzenburg, F., Commonsense reasoning using theorem proving and machine learning (2019) CD-MAKE 2019 – Machine Learning and Knowledge Extraction, , Holzinger A, Kieseberg P, Weippl E, Tjoa AM, LNCS. Springer Nature Switzerland, Canterbury, UK. To appear; Speer, R., Chin, J., Havasi, C., ConceptNet 5.5: An open multilingual graph of general knowledge (2017) AAAI Conference on Artificial Intelligence, pp. 4444-4451. , http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972; Spohn, W., (2012) The laws of belief: ranking theory and its philosophical applications, , Oxford University Press, Wiesbaden; Suchanek, F.M., Kasneci, G., Weikum, G., YAGO: a large ontology from wikipedia and WordNet (2008) Web Semant, 6 (3), pp. 203-217; Wirth, C.P., Stolzenburg, F., A series of revisions of David Poole’s specificity (2016) Ann Math Artif Intell, 78 (3), pp. 205-258. , Special issue on Belief Change and Argumentation Multi-Agent Scenarios. Issue editors: Jürgen Dix, Sven Ove Hansson, Gabriele Kern-Isberner, Guillermo Simari",,,,,,Article,"Final","",Scopus,2-s2.0-85077011935
"Chaturvedi I., Satapathy R., Cavallari S., Cambria E.","12646151300;57190950346;57195682394;56140547500;","Fuzzy commonsense reasoning for multimodal sentiment analysis",2019,"Pattern Recognition Letters","125",,,"264","270",,83,"10.1016/j.patrec.2019.04.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065463296&doi=10.1016%2fj.patrec.2019.04.024&partnerID=40&md5=e809ca1e1a16b6df5b2a4aa1287fff8d","The majority of user-generated content posted online is in the form of text, images and videos but also physiological signals in games. AffectiveSpace is a vector space of affective commonsense available for English text but not for other languages nor other modalities such as electrocardiogram signals. We overcome this limitation by using deep learning to extract features from each modality and then projecting them to a common AffectiveSpace that has been clustered into different emotions. Because, in the real world, individuals tend to have partial or mixed sentiments about an opinion target, we use a fuzzy logic classifier to predict the degree of a particular emotion in AffectiveSpace. The combined model of deep convolutional neural networks and fuzzy logic is termed Convolutional Fuzzy Sentiment Classifier. Lastly, because the computational complexity of a fuzzy classifier is exponential with respect to the number of features, we project features to a four dimensional emotion space in order to speed up the classification performance. © 2019","Deep learning; Fuzzy logic; Multi-modal; Sentiment prediction","Biomedical signal processing; Computer circuits; Convolution; Deep learning; Deep neural networks; Fuzzy neural networks; Fuzzy sets; Sentiment analysis; Vector spaces; Classification performance; Commonsense reasoning; Convolutional neural network; Electrocardiogram signal; Fuzzy logic classifiers; Multi-modal; Physiological signals; User-generated content; Fuzzy logic","Cambria, E., Rajagopal, D., Olsher, D., Das, D., Big Social Data Analysis (2013) Big Data Computing, pp. 401-414. , R. Akerkar Chapman and Hall/CRC; Chaturvedi, I., Ragusa, E., Gastaldo, P., Zunino, R., Cambria, E., Bayesian network based extreme learning machine for subjectivity detection (2018) J. Franklin Inst., 355 (4), pp. 1780-1797; Cheng, K., Li, J., Tang, J., Liu, H., Unsupervised sentiment analysis with signed social networks (2017) AAAI; Howard, N., Cambria, E., Intention awareness: improving upon situation awareness in human-centric environments (2013) Human-centric Comput. Inf. Sci., 3 (9); Abdon Miranda-Correa, J., Khomami, M., Sebe, N., Patras, I., (2017), Amigos: A dataset for mood, personality and affect research on individuals and groups; Huang, X., Rao, Y., Xie, H., Wong, T.-L., Wang, F.L., Cross-domain sentiment classification via topic-related tradaboost (2017) AAAI; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS, pp. 1097-1105. , Curran Associates, Inc; Cambria, E., Fu, J., Bisio, F., Poria, S., Affectivespace 2: enabling affective intuition for concept-level sentiment analysis (2015) AAAI, pp. 508-514; Cambria, E., Hussain, A., Havasi, C., Eckl, C., Common sense computing: from the society of mind to digital intuition and beyond (2009) Biometric ID Management and Multimodal Communication, Lecture Notes in Computer Science, 5707, pp. 252-259. , J. Fierrez J. Ortega A. Esposito A. Drygajlo M. Faundez-Zanuy Springer Berlin Heidelberg; Cambria, E., Poria, S., Hazarika, D., Kwok, K., SenticNet 5: discovering conceptual primitives for sentiment analysis by means of context embeddings (2018) AAAI, pp. 1795-1802; Cambria, E., Hussain, A., Havasi, C., Eckl, C., Sentic computing: exploitation of common sense for the development of emotion-sensitive systems (2010) Development of Multimodal Interfaces: Active Listening and Synchrony, pp. 148-156. , A. Esposito N. Campbell C. Vogel A. Hussain A. Nijholt Springer Berlin; Cambria, E., Livingstone, A., Hussain, A., The hourglass of emotions (2012) Cognitive Behavioral Systems, Lecture Notes in Computer Science, 7403, pp. 144-157. , A. Esposito A. Vinciarelli R. Hoffmann V. Muller Springer Berlin Heidelberg; Cambria, E., Hussain, A., Havasi, C., Eckl, C., SenticSpace: visualizing opinions and sentiments in a multi-dimensional vector space (2010) Knowledge-Based and Intelligent Information and Engineering Systems, Lecture Notes in Artificial Intelligence, 6279, pp. 385-393. , R. Setchi I. Jordanov R. Howlett L. Jain Springer Berlin; Poria, S., Chaturvedi, I., Cambria, E., Hussain, A., Convolutional MKL based multimodal emotion recognition and sentiment analysis (2016) ICDM, Barcelona, pp. 439-448; Giatsoglou, M., Vozalis, M.G., Diamantaras, K., Vakali, A., Sarigiannidis, G., Chatzisavvas, K.C., Sentiment analysis leveraging emotions and word embeddings (2017) Expert Syst. Appl., 69, pp. 214-224; Tang, D., Qin, B., Liu, T., Aspect level sentiment classification with deep memory network (2016) EMNLP, pp. 214-224; Yang, M., Tu, W., Wang, J., Xu, F., Chen, X., Attention based LSTM for target dependent sentiment classification (2017) AAAI; Xu, J., Chen, D., Qiu, X., Huang, X., Cached long short-term memory neural networks for document-level sentiment classification (2016) EMNLP, pp. 1660-1669; Fischer, A., Igel, C., An introduction to restricted Boltzmann machines (2012) ICPR, pp. 14-36. , Springer; Chaturvedi, I., Ong, Y.-S., Tsang, I.W., Welsch, R.E., Cambria, E., Learning word dependencies in text by means of a deep recurrent belief network (2016) Knowl. Based Syst., 108, pp. 144-154; Lee, H., Grosse, R., Ranganath, R., Ng, A.Y., Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009) Proceedings of the 26th annual international conference on machine learning, pp. 609-616. , ACM; Rajagopal, D., Cambria, E., Olsher, D., Kwok, K., A graph-based approach to commonsense concept extraction and semantic similarity detection (2013) WWW, pp. 565-570; Tanaka, M., Okutomi, M., A novel inference of a restricted Boltzmann machine (2014) ICPR, pp. 1526-1531; Baranyi, P., Lei, K.-F., Yam, Y., Complexity reduction of singleton based neuro-fuzzy algorithm (2000) IEEE SMC, 4, pp. 2503-2508 vol.4; Morency, L.-P., Mihalcea, R., Doshi, P., Towards multimodal sentiment analysis: Harvesting opinions from the web (2011) ICMI, pp. 169-176. , ACM; Pérez-Rosas, V., Mihalcea, R., Morency, L.-P., Utterance-level multimodal sentiment analysis (2013) ACL, pp. 973-982; Bollegala, D., Mu, T., Goulermas, J.Y., Cross-domain sentiment classification using sentiment sensitive embeddings (2016) IEEE Trans. Knowl. Data Eng., 28 (2), pp. 398-410; Long, M., Wang, J., Cao, Y., Sun, J., Yu, P.S., Deep learning of transferable representation for scalable domain adaptation (2016) IEEE TKDE, 28 (8), pp. 2027-2040; Dredze, M., Crammer, K., Pereira, F., Confidence-weighted linear classification (2008) ICML, pp. 264-271; Kim, Y., Convolutional neural networks for sentence classification (2014) EMNLP, pp. 1746-1751",,,,,,Article,"Final","",Scopus,2-s2.0-85065463296
"Honda H., Hagiwara M.","57215077154;7201487333;","Question Answering Systems with Deep Learning-Based Symbolic Processing",2019,"IEEE Access","7",,"8873551","152368","152378",,2,"10.1109/ACCESS.2019.2948081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078352116&doi=10.1109%2fACCESS.2019.2948081&partnerID=40&md5=dd4f6f6b24f6bb01178c87f12ce8cb5e","The authors propose methods to learn symbolic processing with deep learning and to build question answering systems by means of learned models. Symbolic processing, performed by the Prolog processing systems which execute unification, resolution, and list operations, is learned by a combination of deep learning models, Neural Machine Translation (NMT) and Word2Vec training. To our knowledge, the implementation of a Prolog-like processing system using deep learning is a new experiment that has not been conducted in the past. The results of their experiments revealed that the proposed methods are superior to the conventional methods because symbolic processing (1) has rich representations, (2) can interpret inputs even if they include unknown symbols, and (3) can be learned with a small amount of training data. In particular (2), handling of unknown data, which is a major task in artificial intelligence research, is solved using Word2Vec. Furthermore, question answering systems can be built from knowledge bases written in Prolog with learned symbolic processing, which, with conventional methods, is extremely difficult to accomplish. Their proposed systems can not only answer questions through powerful inferences by utilizing facts that harbor unknown data but also have the potential to build knowledge bases from a large amount of data, including unknown data, on the Web. The proposed systems are a completely new trial, there is no state-of-the-art methods in the sense of 'newest'. Therefore, to evaluate their efficiency, they are compared with the most traditional and robust system i.e., the Prolog system. This is new research that encompasses the subjects of conventional artificial intelligence and neural network, and their systems have higher potential to build applications such as FAQ chatbots, decision support systems and energy-efficient estimation using a large amount of information on the Web. Mining hidden information through these applications will provide great value. © 2013 IEEE.","Deep learning; knowledge base; neural machine translation; prolog; question answering system; symbolic processing; Word2Vec","Artificial intelligence; Computational linguistics; Computer aided language translation; Data handling; Decision support systems; Energy efficiency; Knowledge based systems; Knowledge base; Machine translations; prolog; Question answering systems; Symbolic processing; Word2Vec; Deep learning","Lindsay, R.K., Buchanan, B.G., Feigenbaum, E.A., Lederberg, J., (1980) Applications of Artificial Intelligence for Organic Chemistry: The Dendral Project, , New York NY USA, McGraw-Hill; Quinlan, J.R., Induction of decision trees (1986) Mach. Learn, 1 (1), pp. 81-106; Muggleton, S., Inductive logic programming (1991) New Gener. Comput, 8 (4), pp. 295-318. , http://www.doc.ic.ac.uk/~shm/Papers/ilp.pdf, Feb, [Online]; Brewka, G., (1991) Nonmonotonic Reasoning: Logical Foundations of Common-sense, , Cambridge, U.K.: Cambridge Univ. Press; Doyle, J., The ins and outs of reason maintenance (1983) Proc. 8th Int. Joint Conf. Artif Intell. IJCAI, pp. 349-351. , Los Altos, CA, USA; Kakas, A.C., Kowalski, R.A., Toni, F., Abductive logic programming (1993) J. Log. Comput, 2 (6), pp. 719-770. , Dec; Hinton, G.E., Preface to the special issue on connectionist symbol processing (1990) Artif. Intell, 46 (1-2), p. 1. , Nov; Touretzky, D.S., BoltzCONS: Dynamic symbol structures in a connectionist network (1990) Artif. Intell, 46 (1-2), pp. 5-6. , Nov; Schlichtkrull, M., Kipf, T.N., Bloem, P., van den Berg, R., Titov, I., Welling, M., Modeling relational data with graph convolutional networks (2018) Proc. Eur. Semantic Web Conf. (ESWC, pp. 593-607; Trouillon, T., Welbl, J., Riedel, S., Gaussier, E., Bouchard, G., Complex embeddings for simple link prediction (2016) Proc. 33nd Int. Conf. Mach. Learn. (ICML, 2016, pp. 2071-2080. , New York, NY, USA; Rocktaschel, T., Riedel, S., End-to-end differentiable proving (2017) Proc. Annu. Conf. Neural Inf. Process. Syst, pp. 3788-3800; Minervini, P., Bosnjak, M., Rocktaschel, T., Riedel, S., (2018) Towards Neural Theorem Proving at Scale, , https://arxiv.org/abs/1807.08204, arXiv: 1807, 08204, [Online]; Dong, H., Mao, J., Lin, T., Wang, C., Li, L., Zhou, D., Neural logic machines (2019) Proc. Int. Conf. Learn. Represent, pp. 1-22. , New Orleans, LA, USA; Tellex, S., Katz, B., Lin, J., Marton, G., Fernandes, A., Quantitative evaluation of passage retrieval algorithms for question answering (2003) Proc. 26th Annu. Int. ACM SIGIR Conf. Res. Develop. Inf. Retr, pp. 41-47. , Toronto, ON, Canada, Aug; Sequiera, R., Baruah, G., Tu, Z., Mohammed, S., Rao, J., Zhang, H., Lin, J., (2017) Exploring the Effectiveness of Convolutional Neural Networks for Answer Selection in End-to-end Question Answering, , https://arxiv.org/abs/1707.07804, arXiv: 1707.07804, [Online]; Thomas, N.T., An e-business chatbot using AIML and LSA (2016) Proc. Int. Conf. Adv. Comput., Commun. Inform. ICACCI, pp. 2740-2742. , Jaipur, India, Sep; Cui, L., Wei, F., Huang, S., Tan, C., Duan, C., Zhou, M., SuperA-Gent: A customer service chatbot for e-commerce websites (2017) Proc. 55th Annu. Meeting Assoc. Comput. Linguistics-Syst. Demonstrations, pp. 97-102. , Jul; Bhargava, H., Power, D., Decision support systems and Web technologies: A status report (2001) Proc. Amer. Conf. Inf. Syst, p. 46. , Boston, MA, USA, Dec; Kohn, M.S., Sun, J., Knoop, S., Shabo, A., Carmeli, B., Sow, D., Syed-Mahmood, T., Rapp, W., IBM's health analytics and clinical decision support (2014) Yearbook Med. Inf, 9 (1), pp. 154-162. , Aug; Sodhro, A., Li, Y., Shah, M., Energy-efficient adaptive transmission power control for wireless body area networks (2016) IET Commun, 10 (1), pp. 81-90. , Jan; Sodhro, A., Pirbhulal, S., Lodro, M., Shah, M., Energy-efficiency in wireless body sensor networks (2017) Networks of the Future Architectures, Technologies, and Implementations, p. 492. , Boca Raton, FL, USA, CRC Press; Sodhro, A., Sangaiah, A., Sodhro, G., Sekhari, A., Ouzrout, Y., Pirbhulal, S., Energy-efficiency of tools and applications on Internet (2018) Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications (Intelligent Data-Centric Systems: Sensor Collected Intelligence), , Amsterdam, The Netherlands, Elsevier; A. S. d'Avila Garcez*K. Broda*D. M. Gabbay (2002) Neural-Symbolic Learning Systems: Foundations and Applications, , London, U.K.: Springer, Verlag; Shavlik, J.W., Towell, G.G., An approach to combining explanation-based and neural learning algorithms (1989) Connection Set, 1 (3), pp. 231-253; Towell, G.G., Shavlik, J.W., Knowledge-based artificial neural networks (1994) Artif. Intell, 70 (1-2), pp. 119-165. , Oct; Garcez, A.S.A., Zaverucha, G., The connectionist inductive learning and logic programming system (1999) Appl. Intell, 11 (1), pp. 59-77. , Jul; Shastri, L., Neurally motivated constraints on the working memory capacity of a production system for parallel processing: Implications of a connectionist model based on temporal synchrony (1992) Proc. 14th Annu. Conf. Cognit. Sci. Soc, 14, p. 159. , Bloomington, IN, USA: Psychology Press, Jul./Aug; Ding, L., Neural prolog-the concepts, construction and mechanism (1995) Proc. IEEE Int. Conf. Syst., Man Cybern., Intell. Syst. 21st Century, 4, pp. 3603-3608. , Oct; Franca, M.V.M., Zaverucha, G., D'Avila Garcez, A.S., Fast relational learning using bottom clause propositionalization with artificial neural networks (2014) Mach. Learn, 94 (1), pp. 81-104. , Jan; Komendantskaya, E., Unification neural networks: Unification by error-correction learning (2011) Log. J. IGPL, 19 (6), pp. 821-847. , Dec; Holldobler, S., A structured connectionist unification algorithm (1990) Proc. 8th Nat. Conf. Artif. Intell, 2, pp. 587-593. , Boston, MA, USA; Sourek, G., Aschenbrenner, V., Zelezny, F., Kuzelka, O., Lifted relational neural networks (2015) Proc. Int. Conf. Cogn. Comput., Integrating Neural Symbolic Approaches, , Montreal, QC, Canada; Cohen, W.W., (2016) Tensorlog: A Differentiable Deductive Database, , https://arxiv.org/abs/1605.06523, arXiv: 1605.06523, [Online]; Serafini, L., D'Avila Garcez, A.S., Logic tensor networks: Deep learning and logical reasoning from data and knowledge (2016) Proc. 11th Int. Workshop Neural-Symbolic Learn. Reasoning NeSy, pp. 1-12. , New York, NY, USA; Lai, T., Bui, T., Li, S., Lipka, N., A simple end-to-end question answering model for product information (2018) Proc. 1st Workshop Econ. Natural Lang. Process, pp. 38-43. , Jul; Tay, Y., Tuan, L.A., Hui, S.C., Hyperbolic representation learning for fast and efficient neural question answering (2018) Proc. 11th ACM Int. Conf. Web Search Data Mining, pp. 583-591. , Los Angeles, CA, USA, Feb; Peng, B., Lu, Z., Li, H., Wong, K., (2015) Towards Neural Network-based Reasoning, , https://arxiv.org/abs/1508.05508, arXiv: 1508.05508, [Online]; Weissenborn, D., (2016) Separating Answers from Queries for Neural Reading Comprehension, , https://arxiv.org/abs/1607.03316, arXiv: 1607.03316, [Online]; Shen, Y., Huang, P., Gao, J., Chen, W., Reasonet: Learning to stop reading in machine comprehension (2017) Proc. 23rd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 1047-1055. , Barcelona, Spain, Aug; Bratko, I., (1990) Prolog Programming for Artificial Intelligence, p. 597. , 2nd ed. Reading, MA, USA, Addison-Wesley; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Proc. NIPS, pp. 3104-3112. , Montreal, QC, Canada; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) Proc. ICLR, pp. 1-15. , San Diego, CA, USA; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A., Kaiser, L., Polosukhi, I., Attention Is All You Need (2017) Proc. 31st Conf. Neural Inf. Process. Syst, pp. 5998-6008. , Long Beach, CA, USA; Mikolov, T., Chen, K., Corrado, G., Dean, J., Efficient estimation of word representations in vector space (2013) Proc. ICLR, pp. 1-12. , Scottsdale, AZ, USA; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Proc. NIPS, pp. 3111-3119. , Lake Tahoe, NV, USA; Mikolov, T., Yih, W., Zweig, G., Linguistic regularities in continuous space word representations (2013) Proc. NAACL HLT, pp. 746-751. , Atlanta, GA, USA; Gray, F., (1953) Pulse Code Communication, , U.S, Patent 2632 058 A, Mar. 17; Kanayama, H., Miyao, Y., Prager, J., Answering Yes/no questions via question inversion Proc. 24th Int. Conf. Comput. Linguistics, 201, pp. 1377-1392. , Mumbai, India, Dec; Ravichandran, D., Hovy, E., Learning surface text patterns for a question answering system (2002) Proc. 40th Annu. Meeting Assoc. Comput. Linguistics, pp. 41-47. , Jul; Higashinaka, R., Isozaki, H., Corpus-based question answering for why-questions (2008) Proc. IJCNLP, pp. 418-425. , Hyderabad, India; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Elman, J.L., Finding structure in time (1990) Cognit. Sci, 14 (2), pp. 179-211. , Mar; Goodfellow, I., Warde-Farley, D., Mirza, M., Courville, A., Bengio, Y., Maxout networks (2013) Proc. 30th Int. Conf. Mach. Learn, pp. 1-9. , Atlanta, GA, USA; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , https://arxiv.org/abs/1412.6980, arXiv: 1412.6980, [Online]; Maas, A., Hannu, A., Ng, A., Rectifier nonlinearities improve neural network acoustic models (2013) Proc. 30th Int. Conf. Mach. Learn, p. 3. , Atlanta, GA, USA; (2018), https://www.kinsources.net, Kinsources: A Collaborative Web Platform for Kinship Data Sharing. Accessed, May 19, [Online]; Tang, L.R., Mooney, R.J., Automated construction of database interfaces: Integrating statistical and relational learning for semantic parsing (2000) Proc. SIGDAT Conf. Empirical Methods Natural Lang. Process. Very Large Corpora (EMNLP/VLC), Hong Kong, pp. 133-141. , Oct",,,,,,Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85078352116
"Yao Y., Xu J., Shi J., Xu B.","57192304629;55898934000;57192310411;56424377800;","Learning to activate logic rules for textual reasoning",2018,"Neural Networks","106",,,"42","49",,2,"10.1016/j.neunet.2018.06.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049856582&doi=10.1016%2fj.neunet.2018.06.012&partnerID=40&md5=47e0384962823cd19727841570859356","Most current textual reasoning models cannotlearn human-like reasoning process, and thus lack interpretability and logical accuracy. To help address this issue, we propose a novel reasoning model which learns to activate logic rules explicitly via deep reinforcement learning. It takes the form of Memory Networks but features a special memory that stores relational tuples, mimicking the “Image Schema” in human cognitive activities. We redefine textual reasoning as a sequential decision-making process modifying or retrieving from the memory, where logic rules serve as state-transition functions. Activating logic rules for reasoning involves two problems: variable binding and relation activating, and this is a first step to solve them jointly. Our model achieves an average error rate of 0.7% on bAbI-20, a widely-used synthetic reasoning benchmark, using less than 1k training samples and no supporting facts. © 2018 Elsevier Ltd","Image schema; Logic rules; Memory networks; Natural language reasoning; Reinforcement learning","Chemical activation; Decision making; Deep learning; Reinforcement learning; Cognitive activities; Image schemata; Logic rules; Memory network; Natural languages; Reasoning process; Sequential decision making; State transition functions; Computer circuits; analytical error; Article; benchmarking; cognition; controlled study; decision making; logic; memory network; nerve cell network; priority journal; recall; reinforcement; textual reasoning; artificial intelligence; decision making; human; learning; logic; memory; physiology; problem solving; trends; Artificial Intelligence; Decision Making; Humans; Learning; Logic; Memory; Problem Solving","Ahn, S., Choi, H., Pärnamaa, T., Bengio, Y., (2016), A neural knowledge language model. arXiv preprint. arXiv:1608.00318; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) ICLR; Dhingra, B., Li, L., Li, X., Gao, J., Chen, Y.-N., Ahmed, F., End-to-end reinforcement learning of dialogue agents for information access (2017) ACL; Fatemi, M., El Asri, L., Schulz, H., Suleman, H.J., K. (2016). Policy networks with two-stage training for dialogue systems. In 17th annual meeting of the special interest group on discourse and dialogue (p. 101); Graves, A., Wayne, G., Danihelka, I., (2014), Neural turing machines. arXiv preprint. arXiv:1410.5401; Graves, A., Wayne, G., Reynolds, M., Harley, T., Danihelka, I., Grabska-Barwińska, A., Hybrid computing using a neural network with dynamic external memory (2016) Nature, 538 (7626), pp. 471-476; Gulcehre, C., Chandar, S., Cho, K., Bengio, Y., (2016), Dynamic neural turing machine with soft and hard addressing schemes. arXiv preprint. arXiv:1607.00036; He, J., Chen, J., He, X., Gao, J., Li, L., Deng, L., (2015), Deep reinforcement learning with a natural language action space. arXiv preprint. arXiv:1511.04636; Henaff, M., Weston, J., Szlam, A., Bordes, A., LeCun, Y., Tracking the world state with recurrent entity networks (2017) ICLR; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Hu, Z., Ma, X., Liu, Z., Hovy, E., Xing, E., Harnessing deep neural networks with logic rules (2016) ACL; Johnson, M., The body in the mind: The bodily basis of meaning, imagination, and reason (2013), University of Chicago Press; Johnson, D.D., Learning graphical state transitions (2017) ICLR; Kansky, K., Silver, T., Mély, D.A., Eldawy, M., Lázaro-Gredilla, M., Lou, X., (2017), Schema networks: Zero-shot transfer with a generative causal model of intuitive physics. arXiv preprint. arXiv:1706.04317; Kumar, A., Irsoy, O., Su, J., Bradbury, J., English, R., Pierce, B., Ask me anything: Dynamic memory networks for natural language processing (2016) ICLR; Kurach, K., Andrychowicz, M., Sutskever, I., Neural random-access machines (2016) ICLR; Lakoff, G., Women, fire, and dangerous things: What categories reveal about the mind (1989), University of Chicago Press; Langacker, R.W., Grammar and conceptualization, Vol. 14 (1999), Walter de Gruyter; Lee, M., Yih, H.X., W.-t., Gao, J., Deng, L., & Smolensky, P. (2015). Reasoning in vector space: An exploratory study of question answering. arXiv preprint. arXiv:1511.06426; Marblestone, A.H., Wayne, G., Kording, K.P., Toward an integration of deep learning and neuroscience (2016) Frontiers in Computational Neuroscience, 10; Santoro, A., Raposo, D., Barrett, D.G., Malinowski, M., Pascanu, R., Battaglia, P., A simple neural network module for relational reasoning (2017) Advances in neural information processing systems, pp. 4974-4983; Sukhbaatar, S., Weston, J., Fergus, R., End-to-end memory networks (2015) NIPS; Tieleman, T., Hinton, G., Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude (2012) COURSERA: Neural Networks for Machine Learning, 4 (2); Weston, J., Bordes, A., Chopra, S., Rush, A.M., van Merriënboer, B., Joulin, A., (2015), Towards ai-complete question answering: A set of prerequisite toy tasks. arXiv preprint. arxiv:1502.05698; Weston, J., Chopra, S., Bordes, A., Memory networks (2015) ICLR; Williams, R.J., Simple statistical gradient-following algorithms for connectionist reinforcement learning (1992) Machine Learning, 8 (3-4), pp. 229-256; Xiong, C., Merity, S., Socher, R., Dynamic memory networks for visual and textual question answering (2016) ICLR",,,,,,Article,"Final","",Scopus,2-s2.0-85049856582
"Hussain A., Cambria E.","19734290900;56140547500;","Semi-supervised learning for big social data analysis",2018,"Neurocomputing","275",,,"1662","1673",,125,"10.1016/j.neucom.2017.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032371736&doi=10.1016%2fj.neucom.2017.10.010&partnerID=40&md5=8ba4edf6e121c55005f6c8a0894821a8","In an era of social media and connectivity, web users are becoming increasingly enthusiastic about interacting, sharing, and working together through online collaborative media. More recently, this collective intelligence has spread to many different areas, with a growing impact on everyday life, such as in education, health, commerce and tourism, leading to an exponential growth in the size of the social Web. However, the distillation of knowledge from such unstructured Big data is, an extremely challenging task. Consequently, the semantic and multimodal contents of the Web in this present day are, whilst being well suited for human use, still barely accessible to machines. In this work, we explore the potential of a novel semi-supervised learning model based on the combined use of random projection scaling as part of a vector space model, and support vector machines to perform reasoning on a knowledge base. The latter is developed by merging a graph representation of commonsense with a linguistic resource for the lexical representation of affect. Comparative simulation results show a significant improvement in tasks such as emotion recognition and polarity detection, and pave the way for development of future semi-supervised learning approaches to big social data analytics. © 2017 Elsevier B.V.","Big social data analysis; Semi-supervised learning; Sentiment analysis","Big data; Data handling; Distillation; Education; Information analysis; Knowledge based systems; Semantics; Vector spaces; Collective intelligences; Comparative simulation; Emotion recognition; Graph representation; Linguistic resources; Semi- supervised learning; Sentiment analysis; Vector space models; Supervised learning; Article; automated pattern recognition; data analysis; Internet; knowledge base; least square analysis; machine learning; priority journal; semi supervised learning; simulation; social media; social network; support vector machine","Poria, S., Cambria, E., Bajpai, R., Hussain, A., A review of affective computing: from unimodal analysis to multimodal fusion (2017) Inf. Fus., 37, pp. 98-125; Cambria, E., Hussain, A., Sentic Computing: A Common-Sense-Based Framework for Concept-Level Sentiment Analysis (2015), Springer Cham, Switzerland; Cambria, E., Olsher, D., Kwok, K., Sentic activation: a two-level affective common sense reasoning framework (2012) Proceedings of the AAAI, pp. 186-192. , Toronto; Speer, R., Havasi, C., ConceptNet 5: A large semantic network for relational knowledge (2012) Theory and Applications of Natural Language Processing, , E. Hovy M. Johnson G. Hirst Springer; Strapparava, C., Valitutti, A., WordNet-Affect: an affective extension of WordNet (2004) Proceedings of the International Conference on Language Resources and Evaluation, pp. 1083-1086. , Lisbon; Cambria, E., Das, D., Bandyopadhyay, S., Feraco, A., A Practical Guide to Sentiment Analysis (2017), Springer Cham, Switzerland; Bisio, F., Gastaldo, P., Zunino, R., Decherchi, S., Semi-supervised machine learning approach for unknown malicious software detection (2014) Proceedings of the IEEE International Symposium on Innovations in Intelligent Systems and Applications (INISTA), pp. 52-59. , IEEE; Poria, S., Cambria, E., Hazarika, D., Mazumder, N., Zadeh, A., Morency, L.-P., Context-dependent sentiment analysis in user-generated videos (2017) Proceedings of the ACL, pp. 873-883; Chaturvedi, I., Ragusa, E., Gastaldo, P., Zunino, R., Cambria, E., Bayesian network based extreme learning machine for subjectivity detection (2017) J. Frankl. Inst.; Xing, F., Cambria, E., Welsch, R., Natural language based financial forecasting: a survey (2018) Artif. Intell. Rev.; Ebrahimi, M., Hossein, A., Sheth, A., Challenges of sentiment analysis for dynamicevents (2017) IEEE Intell. Syst., 32 (5); Cambria, E., Hussain, A., Durrani, T., Havasi, C., Eckl, C., Munro, J., Sentic computing for patient centered application (2010) Proceedings of the IEEE International Conference on Signal Processing, pp. 1279-1282. , Beijing; Valdivia, A., Luzon, V., Herrera, F., Sentiment analysis in tripadvisor (2017) IEEE Intell. Syst., 32 (4), pp. 2-7; Cavallari, S., Zheng, V., Cai, H., Chang, K., Cambria, E., Joint node and community embedding on graphs (2017) Proceedings of the International Conference on Information and Knowledge Management; Mihalcea, R., Garimella, A., What men say, what women hear: finding gender-specific meaning shades (2016) IEEE Intell. Syst., 31 (4), pp. 62-67; Cambria, E., Poria, S., Gelbukh, A., Thelwall, M., Sentiment analysis is a big suitcase (2017) IEEE Intell. Syst., 32 (6); Poria, S., Chaturvedi, I., Cambria, E., Bisio, F., Sentic LDA: improving on LDA with semantic similarity for aspect-based sentiment analysis (2016) Proceedings of the International Joint Conference on Neural Networks, pp. 4465-4473; Ma, Y., Cambria, E., Gao, S., Label embedding for zero-shot fine-grained named entity typing (2016) Proceedings of the International Conference on Computational Linguistics, pp. 171-180. , Osaka; Xia, Y., Cambria, E., Hussain, A., Zhao, H., Word polarity disambiguation using Bayesian model and opinion-level features (2015) Cognit. Comput., 7 (3), pp. 369-380; Zhong, X., Sun, A., Cambria, E., Time expression analysis and recognition using syntactic token types and general heuristic rules (2017) Proceedings of the ACL, pp. 420-429; Majumder, N., Poria, S., Gelbukh, A., Cambria, E., Deep learning-based document modeling for personality detection from text (2017) IEEE Intell. Syst., 32 (2), pp. 74-79; Poria, S., Cambria, E., Hazarika, D., Vij, P., A deeper look into sarcastic tweets using deep convolutional neural networks (2016) Proceedings of the International Conference on Computational Linguistics, pp. 1601-1612; Oneto, L., Bisio, F., Cambria, E., Anguita, D., Statistical learning theory and ELM for big social data analysis (2016) IEEE Comput. Intell. Mag., 11 (3), pp. 45-55; Elliott, C.D., (1992) The affective reasoner: a process model of emotions in a multi-agent system, , Northwestern University Evanston Ph.D. thesis; Ortony, A., Clore, G., Collins, A., The Cognitive Structure of Emotions (1988), Cambridge University Press Cambridge; Wiebe, J., Wilson, T., Cardie, C., Annotating expressions of opinions and emotions in language (2005) Lang. Resour. Eval., 39 (2), pp. 165-210; Wilson, T., Wiebe, J., Hoffmann, P., Recognizing contextual polarity in phrase-level sentiment analysis (2005) Proceedings of the Human Language Technology Conference and Empirical Methods in Natural Language Processing, pp. 347-354. , Vancouver; Stevenson, R., Mikels, J., James, T., Characterization of the affective norms for english words by discrete emotional categories (2007) Behav. Res. Methods, 39, pp. 1020-1024; Somasundaran, S., Wiebe, J., Ruppenhofer, J., Discourse level opinion interpretation (2008) Proceedings of the International Conference on Computational Linguistics, pp. 801-808. , Manchester; Pang, B., Lee, L., Vaithyanathan, S., Thumbs up? Sentiment classification using machine learning techniques (2002) Proceedings of the Empirical Methods for Natural Language Processing, pp. 79-86. , Philadelphia; Goertzel, B., Silverman, K., Hartley, C., Bugaj, S., Ross, M., The Baby Webmind project (2000) Proceedings of the Adaptation in Artificial and Biological Systems, , Birmingham; Pang, B., Lee, L., Seeing stars: exploiting class relationships for sentiment categorization with respect to rating scales (2005) Proceedings of the ACL, pp. 115-124. , Ann Arbor; Hu, M., Liu, B., Mining and summarizing customer reviews (2004) Proceedings of the Conference on Knowledge Discovery and Data Mining, , Seattle; Velikovich, L., Goldensohn, S., Hannan, K., McDonald, R., The viability of web-derived polarity lexicons (2010) Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics, pp. 777-785. , Los Angeles; Gangemi, A., Presutti, V., Reforgiato, D., Frame-based detection of opinion holders and topics: a model and a tool (2014) IEEE Comput. Intell. Mag., 9 (1), pp. 20-30; Cambria, E., Poria, S., Bajpai, R., Schuller, B., SenticNet 4: a semantic resource for sentiment analysis based on conceptual primitives (2016) Proceedings of the International Conference on Computational Linguistics, pp. 2666-2677; Fellbaum, C., WordNet: An Electronic Lexical Database (Language, Speech, and Communication) (1998), The MIT Press; Lenat, D., Guha, R., Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project (1989), Addison-Wesley Boston; Mueller, E., Commonsense Reasoning (2006), Morgan Kaufmann; Fauconnier, G., Turner, M., The Way We Think: Conceptual Blending and the Mind's Hidden Complexities (2003), Basic Books; Jolliffe, I., Principal Component Analysis (2005), Wiley Online Library; Menon, A.K., Elkan, C., Fast algorithms for approximating the singular value decomposition (2011) ACM Trans. Knowl. Discov. Data (TKDD), 5 (2), p. 13; Osgood, C., May, W., Miron, M., Cross-Cultural Universals of Affective Meaning (1975), University of Illinois Press; Balduzzi, D., Randomized co-training: from cortical neurons to machine learning and back again, (2013)., arXiv:1310.6536; Lee, H., Grosse, R., Ranganath, R., Ng, A.Y., Unsupervised learning of hierarchical representations with convolutional deep belief networks (2011) Commun. ACM, 54 (10), pp. 95-103; Bingham, E., Mannila, H., Random projection in dimensionality reduction: applications to image and text data (2001) Proceedings of the ACM SIGKDD, pp. 245-250; Sarlos, T., Improved approximation algorithms for large matrices via random projections (2006) Proceedings of the Foundations of Computer Science, pp. 143-152; Achlioptas, D., Database-friendly random projections: Johnson–lindenstrauss with binary coins (2003) J. Comput. Syst. Sci., 66 (4), pp. 671-687; Lu, Y., Dhillon, P., Foster, D.P., Ungar, L., Faster ridge regression via the subsampled randomized Hadamard transform (2013) Advances in Neural Information Processing Systems, pp. 369-377; Tropp, J.A., Improved analysis of the subsampled randomized Hadamard transform (2011) Adv. Adapt. Data Anal., 3 (01n02), pp. 115-126; Ailon, N., Chazelle, B., Faster dimension reduction (2010) Commun. ACM, 53 (2), pp. 97-104; Cambria, E., Fu, J., Bisio, F., Poria, S., AffectiveSpace 2: enabling affective intuition for concept-level sentiment analysis (2015) Proceedings of the AAAI, pp. 508-514. , Austin; Yu, T., Simoff, S., Jan, T., VQSVM: a case study for incorporating prior domain knowledge into inductive machine learning (2010) Neurocomputing, 73 (13), pp. 2614-2623; Socher, R., Huval, B., Manning, C.D., Ng, A.Y., Semantic compositionality through recursive matrix-vector spaces (2012) Proceedings of the Empirical Methods for Natural Language Processing, pp. 1201-1211; Socher, R., Perelygin, A., Wu, J.Y., Chuang, J., Manning, C.D., Ng, A.Y., Potts, C., Recursive deep models for semantic compositionality over a sentiment treebank (2013) Proceedings of the Empirical Methods for Natural Language Processing, pp. 1642-1654",,,,,,Article,"Final","All Open Access, Green",Scopus,2-s2.0-85032371736
"Diligenti M., Gori M., Saccà C.","55972544500;7005254436;55061200200;","Semantic-based regularization for learning and inference",2017,"Artificial Intelligence","244",,,"143","165",,40,"10.1016/j.artint.2015.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940937276&doi=10.1016%2fj.artint.2015.08.011&partnerID=40&md5=3333e89077342ba6c46a593809d11eb2","This paper proposes a unified approach to learning from constraints, which integrates the ability of classical machine learning techniques to learn from continuous feature-based representations with the ability of reasoning using higher-level semantic knowledge typical of Statistical Relational Learning. Learning tasks are modeled in the general framework of multi-objective optimization, where a set of constraints must be satisfied in addition to the traditional smoothness regularization term. The constraints translate First Order Logic formulas, which can express learning-from-example supervisions and general prior knowledge about the environment by using fuzzy logic. By enforcing the constraints also on the test set, this paper presents a natural extension of the framework to perform collective classification. Interestingly, the theory holds for both the case of data represented by feature vectors and the case of data simply expressed by pattern identifiers, thus extending classic kernel machines and graph regularization, respectively. This paper also proposes a probabilistic interpretation of the proposed learning scheme, and highlights intriguing connections with probabilistic approaches like Markov Logic Networks. Experimental results on classic benchmarks provide clear evidence of the remarkable improvements that are obtained with respect to related approaches. © 2015 Elsevier B.V.","FOL; Kernel machines; Learning with constraints","Artificial intelligence; Classification (of information); Formal logic; Learning systems; Multiobjective optimization; Semantics; Collective classifications; FOL; Kernel machine; Learning with constraints; Machine learning techniques; Probabilistic interpretation; Semantic-based regularizations; Statistical relational learning; Fuzzy logic","Baader, F., The Description Logic Handbook: Theory, Implementation, and Applications (2003), Cambridge University Press; Bard, J.F., Practical Bilevel Optimization: Algorithms and Applications (1998) Nonconvex Optimization and Its Applications, 30. , Springer; Belkin, M., Niyogi, P., Sindhwani, V., Manifold regularization: a geometric framework for learning from labeled and unlabeled examples (2006) J. Mach. Learn. Res., 7, p. 2434; Bengio, Y., Curriculum learning (2009) Proceedings of the 26th Annual International Conference on Machine Learning, ICML0, pp. 41-48; Broecheler, M., Mihalkova, L., Getoor, L., Probabilistic similarity logic (2010) Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence, UAI, pp. 73-82; Caponnetto, A., Micchelli, C.A., Pontil, M., Ying, Y., Universal multi-task kernels (2008) J. Mach. Learn. Res., 9, pp. 1615-1646; Craven, M., Slattery, S., Relational learning with statistical predicate invention: better models for hypertext (2001) Mach. Learn., pp. 97-119; Cumby, C., Roth, D., Learning with feature description logics (2003) Proceedings of the 12th International Conference on Inductive Logic Programming, pp. 32-47. , Springer; Cumby, C., Roth, D., On kernel methods for relational learning (2003) Proceedings of the Twentieth International Conference on Machine Learning, ICML, pp. 107-114; Diligenti, M., Gori, M., Maggini, M., Rigutini, L., Bridging logic and kernel machines (2012) Mach. Learn., 86, pp. 57-88; Domingos, P., Richardson, M., Markov logic: a unifying framework for statistical relational learning (2004) ICML-2004 Workshop on Statistical Relational Learning, pp. 49-54; Domingos, P., Sumner, M., The alchemy tutorial (2010), http://alchemy.cs.washington.edu/tutorial/tutorial.pdf; Friedman, N., Getoor, L., Koller, D., Pfeffer, A., Learning probabilistic relational models (1999) Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI, pp. 1300-1309; Fung, G.M., Mangasarian, O.L., Shavlik, J.W., Knowledge-based support vector machine classifiers (2002) Advances in Neural Information Processing Systems, pp. 521-528; Fung, G.M., Mangasarian, O.L., Shavlik, J.W., Knowledge-based nonlinear kernel classifiers (2003) Learning Theory and Kernel Machines, pp. 102-113. , Springer; Golomb, S.W., Baumert, L.D., Backtrack programming (1965) J. ACM, 12, pp. 516-524; Gupta, M., Qi, J., Theory of t-norms and fuzzy inference methods (1991) Fuzzy Sets Syst., 40, pp. 431-450; Hajek, P., The Metamathematics of Fuzzy Logic (1998), Kluwer; Haralick, R.M., Elliott, G.L., Increasing tree search efficiency for constraint satisfaction problems (1980) Artif. Intell., 14, pp. 263-313; Haussler, D., Convolution kernels on discrete structures (1999), Technical report Department of Computer Science, University of California at Santa Cruz; Hitzler, P., Holldobler, S., Sedab, A.K., Logic programs and connectionist networks (2004) J. Appl. Log., 2, pp. 245-272; Huynh, T.N., Mooney, R.J., Discriminative structure and parameter learning for Markov logic networks (2008) Proceedings of the 25th International Conference on Machine Learning, ICML, pp. 416-423. , ACM; Kok, S., Domingos, P., Learning the structure of Markov logic networks (2005) Proceedings of the 22nd International Conference on Machine Learning, ICML, pp. 441-448. , ACM; Landwehr, N., Passerini, A., De Raedt, L., Frasconi, P., kfoil: learning simple relational kernels (2006) Proceedings of the AAAI Conference on Artificial Intelligence, pp. 389-394; Landwehr, N., Passerini, A., Raedt, L., Frasconi, P., Fast learning of relational kernels (2010) Mach. Learn.; Laurer, F., Bloch, G., Incorporating prior knowledge in support vector machines for classification: a review (2009) Neurocomputing, 71, pp. 1578-1594; Le, Q.V., Smola, A.J., Gärtner, T., Simpler knowledge-based support vector machines (2006) Proceedings of the 23rd International Conference on Machine Learning, ICML, pp. 521-528. , ACM; Lippi, M., Frasconi, P., Prediction of protein β-residue contacts by Markov logic networks with grounding-specific weights (2009) Bioinformatics, 25, pp. 2326-2333; Lowd, D., Domingos, P., Efficient weight learning for Markov logic networks (2007) Proceedings of the Eleventh European Conference on Principles and Practice of Knowledge Discovery in Databases, pp. 200-211; McCallum, A., Nigam, K., Rennie, J., Seymore, K., Automating the construction of Internet portals with machine learning (2000) Inf. Retr., 3, pp. 127-163; Melacci, S., Belkin, M., Laplacian support vector machines trained in the primal (2011) J. Mach. Learn. Res., 12, pp. 1149-1184; Mihalkova, L., Mooney, R.J., Bottom-up learning of Markov logic network structure (2007) Proceedings of the 24th International Conference on Machine Learning, pp. 625-632. , ACM New York, NY, USA; Muggleton, S., Lodhi, H., Amini, A., Sternberg, M.J., Support vector inductive logic programming (2005) Discovery Science, pp. 163-175. , Springer; Neville, J., Jensen, D., Relational dependency networks (2007) J. Mach. Learn. Res., 8, pp. 653-692; Niu, F., Ré, C., Doan, A., Shavlik, J., Tuffy: scaling up statistical inference in Markov logic networks using an RDBMS (2011) Proceedings of the VLDB, pp. 373-384; Novák, V., First-order fuzzy logic (1987) Stud. Log., 46, pp. 87-109; Piaget, J., La psychologie de l'intelligence (1961), Armand Colin Paris; Poggio, T., Girosi, F., A theory of networks for approximation and learning (1989), Technical report MIT; Raedt, L.D., Frasconi, P., Kersting, K.S.M., (2008) Probabilistic Inductive Logic Programming, Lecture Notes in Artificial Intelligence, 4911. , Springer; Richardson, M., Domingos, P., Markov logic networks (2006) Mach. Learn., 62, pp. 107-136; Rossi, F., Van Beek, P., Walsh, T., Handbook of Constraint Programming (2006), Elsevier; Scholkopf, B., Smola, A.J., Learning with Kernels (2001), MIT Press Cambridge, MA, USA; Shavlik, J.W., Natarajan, S., Speeding up inference in Markov logic networks by preprocessing to reduce the size of the resulting grounded network (2009) Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI, pp. 1951-1956; Singla, P., Domingos, P., Memory-efficient inference in relational domains (2006) Proceedings of the 21st AAAI Conference on Artificial Intelligence, pp. 488-493. , AAAI Press; Starczewski, J.T., Advanced Concepts in Fuzzy Logic and Systems with Membership Uncertainty (2012), Springer; Tran, S.D., Davis, L.S., Event modeling and recognition using Markov logic networks (2008) Proceedings of the European Conference of Computer Vision, ECCV, pp. 610-623. , Springer; Tsochantaridis, I., Joachims, T., Hofmann, T., Altun, Y., Large margin methods for structured and interdependent output variables (2005) J. Mach. Learn. Res., pp. 1453-1484; Vapnik, V., The Nature of Statistical Learning Theory (2000), 2nd edn. Springer Verlag; Wang, J., Domingos, P., Hybrid Markov logic networks (2008) Proceedings of the 23-rd AAAI Conference on Artificial Intelligence, pp. 1106-1111; Williams, P.M., Bayesian regularization and pruning using a Laplace prior (1995) Neural Comput., 7, pp. 117-143; Zadeh, L.A., Fuzzy sets (1965) Inf. Control, 8, pp. 338-353; Zhou, D., Schölkopf, B., Regularization on discrete spaces (2005) Pattern Recognit., pp. 361-368",,,,,,Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-84940937276
"Carmantini G.S., beim Graben P., Desroches M., Rodrigues S.","57190120060;23110284000;23990353700;57202415938;","A modular architecture for transparent computation in recurrent neural networks",2017,"Neural Networks","85",,,"85","105",,5,"10.1016/j.neunet.2016.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994319086&doi=10.1016%2fj.neunet.2016.09.001&partnerID=40&md5=748c2c3637c624ca09c0929de9c95e1d","Computation is classically studied in terms of automata, formal languages and algorithms; yet, the relation between neural dynamics and symbolic representations and operations is still unclear in traditional eliminative connectionism. Therefore, we suggest a unique perspective on this central issue, to which we would like to refer as transparent connectionism, by proposing accounts of how symbolic computation can be implemented in neural substrates. In this study we first introduce a new model of dynamics on a symbolic space, the versatile shift, showing that it supports the real-time simulation of a range of automata. We then show that the Gödelization of versatile shifts defines nonlinear dynamical automata, dynamical systems evolving on a vectorial space. Finally, we present a mapping between nonlinear dynamical automata and recurrent artificial neural networks. The mapping defines an architecture characterized by its granular modularity, where data, symbolic operations and their control are not only distinguishable in activation space, but also spatially localizable in the network itself, while maintaining a distributed encoding of symbolic representations. The resulting networks simulate automata in real-time and are programmed directly, in the absence of network training. To discuss the unique characteristics of the architecture and their consequences, we present two examples: (i) the design of a Central Pattern Generator from a finite-state locomotive controller, and (ii) the creation of a network simulating a system of interactive automata that supports the parsing of garden-path sentences as investigated in psycholinguistics experiments. © 2016 Elsevier Ltd","Automata Theory; Neural symbolic computation; Nonlinear dynamical automata; Recurrent artificial neural networks; Representation theory; Versatile shift","Automata theory; Dynamical systems; Formal languages; Mapping; Network architecture; Syntactics; Nonlinear dynamical automata; Recurrent artificial neural networks; Representation theory; Symbolic computation; Versatile shift; Recurrent neural networks; Article; artificial neural network; central pattern generator; linguistics; mathematical model; nonlinear system; priority journal; recurrent artificial neural network; simulation; symbolism; algorithm; software; Algorithms; Neural Networks (Computer); Software","Aho, A.V., Nested stack automata (1969) Journal of the Association for Computing Machinery, 16 (3), pp. 383-406; Aho, A.V., Ullman, J.D., The theory of parsing, translation and compiling (1972), Prentice-Hall; Albert, R., Barabási, A.-L., Statistical mechanics of complex networks (2002) Reviews of Modern Physics, 74 (1), pp. 47-97; Alvarez-Alvarez, A., Trivino, G., Cordón, O., Human gait modeling using a genetic fuzzy finite state machine (2012) IEEE Transactions on Fuzzy Systems, 20 (2), pp. 205-223; Amari, S.-I., A method of statistical neurodynamics (1974) Kybernetik, 14, pp. 201-215; Barrès, V., Simons, A., 3rd, Arbib, M., Synthetic event-related potentials: A computational bridge between neurolinguistic models and experiments (2013) Neural Networks, 37, pp. 66-92; beim Graben, P., Drenhaus, H., Computationelle neurolinguistik (2012) Zeitschrift für Germanistische Linguistik, 40 (1), pp. 97-125; beim Graben, P., Gerth, S., Vasishth, S., Towards dynamical system models of language-related brain potentials (2008) Cognitive Neurodynamics, 2 (3), pp. 229-255; beim Graben, P., Jurish, B., Saddy, D., Frisch, S., Language processing by dynamical systems (2004) International Journal of Bifurcation and Chaos, 14 (2), pp. 599-621; beim Graben, P., Potthast, R., Inverse problems in dynamic cognitive modeling (2009) Chaos: An Interdisciplinary Journal of Nonlinear Science, 19 (1). , 015103; beim Graben, P., Rodrigues, S., A biophysical observation model for field potentials of networks of leaky integrate-and-fire neurons (2013) Frontiers in Computational Neuroscience, 6 (100); Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828; Blutner, R., Taking a broader view: Abstraction and idealization (2011) Theoretical Linguistics, 37 (1-2), pp. 27-35; Cabessa, J., Siegelmann, H.T., The computational power of interactive recurrent neural networks (2012) Neural Computation, 24 (4), pp. 996-1019; Cabessa, J., Villa, A.E., The expressive power of analog recurrent neural networks on infinite input streams (2012) Theoretical Computer Science, 436, pp. 23-34; Cabessa, J., Villa, A.E., The super-turing computational power of interactive evolving recurrent neural networks (2013) Artificial neural networks and machine learning–ICANN 2013, pp. 58-65. , Springer; Carmantini, G.S., (2015) Turing neural networks. GitHub repository, , https://github.com/TuringMachinegun/Turing_Neural_Networks; Carmantini, G.S., Beim Graben, P., Desroches, M., Rodrigues, S., Turing computation with recurrent artificial neural networks (2015) Proceedings of the NIPS workshop on cognitive computation: integrating neural and symbolic approaches, pp. 5-13. , [cs.NE]. arXiv:1511.01427; Christiansen, M.H., Chater, N., Toward a connectionist model of recursion in human linguistic performance (1999) Cognitive Science, 23 (4), pp. 157-205; Collins, J.J., Richmond, S.A., Hard-wired central pattern generators for quadrupedal locomotion (1994) Biological Cybernetics, 71 (5), pp. 375-385; Collins, S.H., Ruina, A., A bipedal walking robot with efficient and human-like gait (2005) Proceedings of the 2005 IEEE international conference on robotics and automation, ICRA 2005, pp. 1983-1988. , IEEE; Davis, M.D., Sigal, R., Weyuker, E.J., (1994) Computability, complexity, and languages: fundamentals of theoretical computer science, , Academic Press, Harcourt, Brace and Company; Desroches, M., Krupa, M., Rodrigues, S., Inflection, canards and excitability threshold in neuronal models (2013) Journal of Mathematical Biology, 67 (4), pp. 989-1017; Dominey, P.F., Complex sensory-motor sequence learning based on recurrent state representation and reinforcement learning (1995) Biological Cybernetics, 73 (3), pp. 265-274; Eliasmith, C., Stewart, T.C., Choo, X., Bekolay, T., DeWolf, T., Tang, Y., A large-scale model of the functioning brain (2012) Science, 338 (6111), pp. 1202-1205; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14, pp. 179-211; Elman, J.L., Distributed representations, simple recurrent networks, and grammatical structure (1991) Machine Learning, 7, pp. 195-225; Elman, J.L., Language as a dynamical system (1995) Mind as motion: explorations in the dynamics of cognition, pp. 195-223. , R.F. Port T. van Gelder MIT Press Cambridge (MA); Farkas, I., Crocker, M.W., Syntactic systematicity in sentence processing with a recurrent self-organizing network (2008) Neurocomputing, 71, pp. 1172-1179; Fernández-García, S., Desroches, M., Krupa, M., Clément, F., A multiple time scale coupling of piecewise linear oscillators. Application to a neuroendocrine system (2015) SIAM Journal on Applied Dynamical Systems, 14 (2), pp. 643-673; Frank, S.L., Otten, L.J., Galli, G., Vigliocco, G., The ERP response to the amount of information conveyed by words in sentences (2015) Brain and Language, 140, pp. 1-11; Frisch, S., beim Graben, P., Schlesewsky, M., Parallelizing grammatical functions: P600 and P345 reflect different cost of reanalysis (2004) International Journal of Bifurcation and Chaos, 14 (2), pp. 531-549; Gayler, R.W., Vector symbolic architectures are a viable alternative for Jackendoff's challenges (2006) Behavioral and Brain Sciences, 29, pp. 78-79; Gayler, R.W., Levy, S.D., Bod, R., Explanatory aspirations and the scandal of cognitive neuroscience (2010) Proceedings of the 2010 conference on biologically inspired cognitive architectures 2010: proceedings of the first annual meeting of the BICA society, pp. 42-51. , A.V. Samsonovich K.R. Johannsdottir A. Chella B. Goertzel IOS Press Amsterdam; Gigley, H.M., Computational neurolinguistics: What is it all about? (1985) Proceedings of the 9th international joint conference on artificial intelligence, 1, pp. 260-266. , IJCAI’85, San Francisco (CA); Girardi-Schappo, M., Tragtenberg, M., Kinouchi, O., A brief history of excitable map-based neurons and neural networks (2013) Journal of Neuroscience Methods, 220 (2), pp. 116-130; Gödel, K., Über formal unentscheidbare sätze der Principia mathematica und verwandter systeme I (1931) Monatshefte für Mathematik und Physik, 38, pp. 173-198; Golubitsky, M., Stewart, I., Buono, P.-L., Collins, J.J., A modular network for legged locomotion (1998) Physica D, 115 (1-2), pp. 56-72; Golubitsky, M., Stewart, I., Buono, P.-L., Collins, J.J., Symmetry in locomotor central pattern generators and animal gaits (1999) Nature, 401 (6754), pp. 693-695; Graves, A., Wayne, G., Danihelka, I., (2014) Neural turing machines, , Preprint. [cs.NE]. arXiv:1511.01427; Grefenstette, E., Hermann, K.M., Suleyman, M., Blunsom, P., Learning to transduce with unbounded memory (2015) Advances in neural information processing systems, pp. 1819-1827; Grillner, S., Zangger, P., How detailed is the central pattern generation for locomotion? (1975) Brain Research, 88 (2), pp. 367-371; Hebb, D.O., The organization of behavior (1949), Wiley New York (NY) Partly reprinted in J. A. Anderson and E. Rosenfeld (1988), pp. 45ff; Hertz, J., Krogh, A., Palmer, R.G., (1991) Introduction to the theory of neural computation, Lecture notes of the Santa Fe institute studies in the science of complexity, , Perseus Books Cambridge (MA); Hinaut, X., Dominey, P.F., Real-time parallel processing of grammatical structure in the fronto-striatal system: A recurrent network simulation study using reservoir computing (2013) PLoS One, 8 (2), p. e52946; Hinaut, X., Petit, M., Pointeau, G., Dominey, P.F., Exploring the acquisition and production of grammatical constructions through human–robot interaction with echo state networks (2014) Frontiers in Neurorobotics, 8 (16); Hodgkin, A.L., Huxley, A.F., A quantitative description of membrane current and its application to conduction and excitation in nerve (1952) The Journal of Physiology, 117 (4), p. 500; Hopcroft, J.E., Ullman, J.D., Introduction to automata theory, languages, and computation (1979), Addison–Wesley Menlo Park, California; Huyck, C.R., A psycholinguistic model of natural language parsing implemented in simulated neurons (2009) Cognitive Neurodynamics, 3 (4), pp. 317-330; Ibarz, B., Casado, J.M., Sanjuán, M.A., Map-based models in neuronal dynamics (2011) Physics Reports, 501 (1), pp. 1-74; Ijspeert, A.J., Central pattern generators for locomotion control in animals and robots: a review (2008) Neural Networks, 21 (4), pp. 642-653; Jaeger, H., The echo state approach to analysing and training recurrent neural networks-with an erratum note. Bonn, Germany: German National Research Center for Information Technology GMD Technical Report, 148:34 (2001); Jansen, B.H., Rit, V.G., Electroencephalogram and visual evoked potential generation in a mathematical model of coupled cortical columns (1995) Biological Cybernetics, 73, pp. 357-366; Joulin, A., Mikolov, T., Inferring algorithmic patterns with stack-augmented recurrent nets (2015) Advances in neural information processing systems, pp. 190-198; Kleene, S., Neural nets and automata (1956) Automata studies, pp. 3-43; Kohonen, T., Self-organized formation of topologically correct feature maps (1982) Biological Cybernetics, 43 (1), pp. 59-69; Kohonen, T., Somervuo, P., Self-organizing maps of symbol strings (1998) Neurocomputing, 21 (1), pp. 19-30; Krupa, M., Robust heteroclinic cycles (1997) Journal of Nonlinear Science, 7 (2), pp. 129-176; Lawrence, S., Giles, C.L., Fong, S., Natural language grammatical inference with recurrent neural networks (2000) The IEEE Transactions on Knowledge and Data Engineering, 12 (1), pp. 126-140; Lewis, R.L., Reanalysis and limited repair parsing: Leaping off the garden path (1998) Reanalysis in sentence processing, pp. 247-285. , J.D. Fodor F. Ferreira Kluwer Dordrecht; Li, D., A tutorial survey of architectures, algorithms, and applications for deep learning (2014) APSIPA Transactions on Signal and Information Processing, 3; Lind, D., Marcus, B., An introduction to symbolic dynamics and coding (1995), Cambridge University Press Cambridge (UK) Reprint 1999; Lopes da Silva, F.H., Hoecks, A., Smits, H., Zetterberg, L.H., Model of brain rhythmic activity: The Alpha-rhythm of the thalamus (1974) Kybernetik, 15, pp. 27-37; Maass, W., Natschläger, T., Markram, H., Real-time computing without stable states: A new framework for neural computation based on perturbations (2002) Neural Computation, 14 (11), pp. 2531-2560; McClelland, J.L., Elman, J.L., The TRACE model of speech perception (1986) Cognitive Psychology, 18 (1), pp. 1-86; McCulloch, W.S., Pitts, W., A logical calculus of ideas immanent in nervous activity (1943) Bulletin of Mathematical Biophysics, 5, pp. 115-133; McGhee, R.B., Some finite state aspects of legged locomotion (1968) Mathematical Biosciences, 2 (1-2), pp. 67-84; Minsky, M., Size and structure of universal Turing machines using tag systems (1962) Recursive function theory: proceedings, symposium in pure mathematics, 5, pp. 229-238; Minsky, M.L., Computation: finite and infinite machines (1967), Prentice-Hall, Inc; Mizraji, E., Context-dependent associations in linear distributed memories (1989) Bulletin of Mathematical Biology, 51 (2), pp. 195-205; Moore, C., Unpredictability and undecidability in dynamical systems (1990) Physical Review Letters, 64 (20), pp. 2354-2357; Moore, C., Generalized shifts: unpredictability and undecidability in dynamical systems (1991) Nonlinearity, 4, pp. 199-230; Neary, T., Woods, D., Four small universal Turing machines (2009) Fundamenta Informaticae, 91 (1), pp. 123-144; Osterhout, L., Holcomb, P.J., Swinney, D.A., Brain potentials elicited by garden-path sentences: Evidence of the application of verb information during parsing (1994) Journal of Experimental Psychology: Learning, Memory, and Cognition, 20 (4), pp. 786-803; Rabinovich, M.I., Huerta, R., Varona, P., Afraimovich, V.S., Transient cognitive dynamics, metastability, and decision making (2008) PLoS Computational Biology, 4 (5), p. e1000072; Schöner, G., Jiang, W.Y., Kelso, J.A.S., A synergetic theory of quadrupedal gaits and gait transitions (1990) Journal of Theoretical Biology, 142 (3), pp. 359-391; Sejnowski, T.J., Rosenberg, C.R., Parallel networks that learn to pronounce English text (1987) Complex Systems, 1, pp. 145-168; Shik, M.L., Severin, F.V., Orlovsky, G.N., Control of walking and running by means of electrical stimulation of mid-brain (1966) Biophysics-USSR, 11 (4), p. 756; Siegelmann, H.T., Sontag, E.D., Turing computability with neural nets (1991) Applied Mathematics Letters, 4 (6), pp. 77-80; Siegelmann, H.T., Sontag, E.D., On the computational power of neural nets (1995) Journal of Computer and System Sciences, 50 (1), pp. 132-150; Sipser, M., Introduction to the theory of computation (2006), Thomson Course Technology Boston; Smith, J.C., Abdala, A.P., Borgmann, A., Rybak, I.A., Paton, J.F., Brainstem respiratory networks: building blocks and microcircuits (2013) Trends in Neurosciences, 36 (3), pp. 152-162; Smith, J.C., Abdala, A., Koizumi, H., Rybak, I.A., Paton, J.F., Spatial and functional architecture of the mammalian brain stem respiratory network: a hierarchy of three oscillatory mechanisms (2007) Journal of Neurophysiology, 98 (6), pp. 3370-3387; Smolensky, P., Information processing in dynamical systems: Foundations of harmony theory (1986) Parallel distributed processing: explorations in the microstructure of cognition, Vol. I, pp. 194-281. , D.E. Rumelhart J.L. McClelland MIT Press Cambridge (MA) PDP Research Group (Chapter 6); Smolensky, P., Tensor product variable binding and the representation of symbolic structures in connectionist systems (1990) Artificial Intelligence, 46 (1-2), pp. 159-216; Smolensky, P., Legendre, G., The harmonic mind. From neural computation to optimality-theoretic grammar (2006) Cognitive architecture, 1. , MIT Press Cambridge (MA); Smolensky, P., Legendre, G., (2006) The harmonic mind. From neural computation to optimality-theoretic grammar, Linguistic and philosophic implications, 2. , MIT Press Cambridge (MA); Spröwitz, A., Moeckel, R., Vespignani, M., Bonardi, S., Ijspeert, A.J., Roombots: A hardware perspective on 3d self-reconfiguration and locomotion with a homogeneous modular robot (2014) Robotics and Autonomous Systems, 62 (7), pp. 1016-1033; Steil, J.J., Backpropagation-decorrelation: online recurrent learning with O(N) complexity (2004) Proceedings of the 2004 IEEE international joint conference on neural networks, Vol. 2, pp. 843-848. , IEEE; Stewart, T.C., Choo, X., Eliasmith, C., Sentence processing in spiking neurons: A biologically plausible left-corner parser (2014) Proceedings of the cognitive science conference; Sukhbaatar, S., Weston, J., Fergus, R., End-to-end memory networks (2015) Advances in neural information processing systems, pp. 2431-2439; Tabor, W., Fractal encoding of context-free grammars in connectionist networks (2000) Expert Systems: The International Journal of Knowledge Engineering and Neural Networks, 17 (1), pp. 41-56; Tabor, W., Learning exponential state-growth languages by hill climbing (2003) IEEE Transactions on Neural Networks, 14 (2), pp. 444-446; Tabor, W., Recursion and recursion-like structure in ensembles of neural elements (2011) Proceedings of the VIII international conference on complex systems, pp. 1494-1508; Tabor, W., Cho, P.W., Szkudlarek, E., Fractal analyis illuminates the form of connectionist structural gradualness (2013) Topics in Cognitive Science, 5, pp. 634-667; Tabor, W., Juliano, C., Tanenhaus, M.K., Parsing in a dynamical system: An attractor-based account of the interaction of lexical and structural constraints in sentence processing (1997) Language and Cognitive Processes, 12 (2-3), pp. 211-271; Tsuda, I., Toward an interpretation of dynamic neural activity in terms of chaotic dynamical systems (2001) Behavioral and Brain Sciences, 24, pp. 793-810; Turing, A.M., On computable numbers, with an application to the Entscheidungsproblem (1937) Proceedings of the London Mathematical Society, 42; Wegner, P., Interactive foundations of computing (1998) Theoretical Computer Science, 192, pp. 315-351; Weir, D.J., Linear iterated pushdowns (1994) Computational Intelligence, 10 (4), pp. 431-439; Wennekers, T., Palm, G., Syntactic sequencing in Hebbian cell assemblies (2009) Cognitive Neurodynamics, 3 (4), pp. 429-441; Werbos, P.J., Backpropagation through time: What it does and how to do it (1990) Proceedings of the IEEE, 78 (10), pp. 1550-1560; Weston, J., Chopra, S., Bordes, A., (2014) Memory networks. preprint, , [cs:AI]. arXiv:1410.3916",,,,,,Article,"Final","All Open Access, Green",Scopus,2-s2.0-84994319086
"Belkebir R., Guessoum A.","55926109200;35934255800;","Concept generalization and fusion for abstractive sentence generation",2016,"Expert Systems with Applications","53",,,"43","56",,10,"10.1016/j.eswa.2016.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957598648&doi=10.1016%2fj.eswa.2016.01.007&partnerID=40&md5=8192da646ba41a5baa360966c2509e34","Text summarization is either extractive or abstractive. Extractive summarization is to select the most salient pieces of information (words, phrases, and/or sentences) from a source document without adding any external information. Abstractive summarization allows an internal representation of the source document so as to produce a faithful summary of the source. In this case, external text can be inserted into the generated summary. Because of the complexity of the abstractive approach, the vast majority of work in text summarization has adopted an extractive approach. In this work, we focus on concepts fusion and generalization, i.e. where different concepts appearing in a sentence can be replaced by one concept which covers the meanings of all of them. This is one operation that can be used as part of an abstractive text summarization system. The main goal of this contribution is to enrich the research efforts on abstractive text summarization with a novel approach that allows the generalization of sentences using semantic resources. This work should be useful in intelligent systems more generally since it introduces a means to shorten sentences by producing more general (hence abstractions of the) sentences. It could be used, for instance, to display shorter texts in applications for mobile devices. It should also improve the quality of the generated text summaries by mentioning key (general) concepts. One can think of using the approach in reasoning systems where different concepts appearing in the same context are related to one another with the aim of finding a more general representation of the concepts. This could be in the context of Goal Formulation, expert systems, scenario recognition, and cognitive reasoning more generally. We present our methodology for the generalization and fusion of concepts that appear in sentences. This is achieved through (1) the detection and extraction of what we define as generalizable sentences and (2) the generation and reduction of the space of generalization versions. We introduce two approaches we have designed to select the best sentences from the space of generalization versions. Using four NLTK1 corpora, the first approach estimates the ""acceptability"" of a given generalization version. The second approach is Machine Learning-based and uses contextual and specific features. The recall, precision and F1-score measures resulting from the evaluation of the concept generalization and fusion approach are presented. © 2016 Elsevier Ltd. All rights reserved.","Artificial intelligence; Concept fusion; Concept generalization; Natural language processing; Text summarization; WordNet","Artificial intelligence; Cognitive systems; Display devices; Expert systems; Intelligent systems; Learning algorithms; Learning systems; Mobile devices; Semantics; Text processing; Concept generalization; External informations; Extractive summarizations; Internal representation; NAtural language processing; Scenario recognition; Text summarization; Wordnet; Natural language processing systems","Barzilay, R., McKeown, K.R., Sentence fusion for multidocument news summarization (2005) Computational Linguistics, 31 (3), pp. 297-328; Bing, L., Li, P., Liao, Y., Lam, W., Guo, W., Passonneau, R., Abstractive multi-document summarization via phrase selection and merging (2015) Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 1587-1597. , Association for Computational Linguistics Beijing, China; Bouckaert, R.R., Frank, E., Hall, M., Kirkby, R., Reutemann, P., Seewald, A., Scuse, D., (2013) Weka Manual for Version 3-7-8; Boudin, F., Mougard, H., Favre, B., Concept-based summarization using integer linear programming: From concept pruning to multiple optimal solutions (2015) Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 1914-1918. , Association for Computational Linguistics Lisbon, Portugal; Chang, C.-C., Lin, C.-J., Libsvm: A library for support vector machines (2011) ACM Transactions on Intelligent Systems and Technology, 2 (3), p. 27; Clarke, J., Lapata, M., Global inference for sentence compression: An integer linear programming approach (2008) Journal of Artificial Intelligence Research, 31, pp. 399-429; Cohn, T., Lapata, M., An abstractive approach to sentence compression (2013) ACM Transactions on Intelligent Systems and Technology, 4 (3), pp. 411-4135; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297; Coster, W., Kauchak, D., Simple english wikipedia: A new text simplification task (2011) Acl (Short Papers), pp. 665-669; De Marneffe, M.-C., Manning, C.D., Stanford typed dependencies manual (2008) URL Http://nlp. Stanford. Edu/software/dependencies Manual. Pdf; Edmundson, H.P., New methods in automatic extracting (1969) Journal of the ACM, 16 (2), pp. 264-285; Feblowitz, D., Kauchak, D., Sentence simplification as tree transduction (2013) Proceedings of the Second Workshop on Predicting and Improving Text Readability for Target Reader Populations, pp. 1-10. , Association for Computational Linguistics Sofia, Bulgaria; Ferreira, R., Lins, R.D., Freitas, F., Cavalcanti, G.D., Lima, R., Simske, S.J., Favaro, L., Assessing sentence scoring techniques for extractive text summarization (2013) Expert Systems with Applications, 40 (14), pp. 5755-5764; Floridi, L., The method of levels of abstraction (2008) Minds and Machines, 18 (3), pp. 303-329; Floridi, L., (2009) Philosophical Conceptions of Information, , Springer; Floridi, L., (2011) The Philosophy of Information, , Oxford University Press; Floridi, L., (2013) The Ethics of Information, , Oxford University Press; Ganascia, J.-G., Abstraction of levels of abstraction (2015) Journal of Experimental & Theoretical Artificial Intelligence, 27 (1), pp. 23-35; Genest, P.-E., Lapalme, G., Framework for abstractive summarization using text-to-text generation (2011) Proceedings of the Workshop on Monolingual Text-to-text Generation, pp. 64-73. , Association for Computational Linguistics; Hasler, L., (2007) From Extracts to Abstracts: Human Summary Production Operations for Computer-aided Summarisation, , University of Wolverhampton Ph.D. thesis; Hovy, E., Lin, C.-Y., Automated text summarization and the summarist system (1998) Proceedings of A Workshop on Held at Baltimore, Maryland: October 13-15, 1998, pp. 197-214. , Association for Computational Linguistics; Hovy, E., Marcu, D., Automated text summarization (2005) The Oxford Handbook of Computational Linguistics, pp. 583-598. , Ruslan Mitkov Oxford University Press; Huang, M., Shi, X., Jin, F., Zhu, X., Using first-order logic to compress sentences (2012) Aaai; Jing, H., Using hidden markov modeling to decompose human-written summaries (2002) Computational Linguistics, 28 (4), pp. 527-543; Jing, H., McKeown, K.R., Cut and paste based text summarization (2000) Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, pp. 178-185. , Association for Computational Linguistics; Kauchak, D., Improving text simplification language modeling using unsimplified text data (2013) Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1537-1546. , Association for Computational Linguistics Sofia, Bulgaria; Khan, A., Salim, N., Kumar, Y.J., A framework for multi-document abstractive summarization based on semantic role labelling (2015) Applied Soft Computing, 30, pp. 737-747; Kumar, M., Das, D., Agarwal, S., Rudnicky, A.I., Non-textual event summarization by applying machine learning to template-based language generation (2009) Proceedings of the 2009 Workshop on Language Generation and Summarisation, pp. 67-71. , Association for Computational Linguistics; Lin, C.-Y., Knowledge-based automatic topic identification (1995) Proceedings of the 33rd Annual Meeting on Association for Computational Linguistics, pp. 308-310. , Association for Computational Linguistics; Liu, F., Flanigan, J., Thomson, S., Sadeh, N., Smith, N.A., Toward abstractive summarization using semantic representations (2015) Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1077-1086. , Association for Computational Linguistics Denver, Colorado; Lloret, E., Boldrini, E., Vodolazova, T., Martínez-Barco, P., Muñoz, R., Palomar, M., A novel concept-level approach for ultra-concise opinion summarization (2015) Expert Systems with Applications, 42 (20), pp. 7148-7156; Lloret, E., Palomar, M., Analyzing the use of word graphs for abstractive text summarization (2011) Proceedings of the First International Conference on Advances in Information Mining and Management, Barcelona, Spain, pp. 61-66; Lloret, E., Palomar, M., Text summarisation in progress: A literature review (2012) Artificial Intelligence Review, 37 (1), pp. 1-41; Luhn, H.P., The automatic creation of literature abstracts (1958) IBM Journal of Research and Development, 2 (2), pp. 159-165; Mani, I., Maybury, M.T., (1999) Advances in Automatic Text Summarization, , the MIT Press; McKeown, K., Rosenthal, S., Thadani, K., Moore, C., Time-efficient creation of an accurate sentence fusion corpus (2010) Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pp. 317-320. , Association for Computational Linguistics; Mehdad, Y., Carenini, G., Ng, R.T., Abstractive summarization of spoken and written conversations based on phrasal queries (2014) Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1220-1230. , Association for Computational Linguistics Baltimore, Maryland; Miller, G.A., Wordnet: A lexical database for english (1995) Communications of the ACM, 38 (11), pp. 39-41; Nenkova, A., Entity-driven rewrite for multidocument summarization (2008) Proceedings of IJCNLP08; Pighin, D., Cornolti, M., Alfonseca, E., Filippova, K., Modelling events through memory-based, open-ie patterns for abstractive summarization (2014) Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, 1, pp. 892-901; Platt, J.C., (1999) Advances in Kernel Methods, pp. 185-208. , MIT Press Cambridge, MA, USA; Radev, D.R., McKeown, K.R., Generating natural language summaries from multiple on-line sources (1998) Computational Linguistics, 24 (3), pp. 470-500; Rush, A.M., Chopra, S., Weston, J., A neural attention model for abstractive sentence summarization (2015) Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 379-389. , Association for Computational Linguistics Lisbon, Portugal; Saggion, H., A classification algorithm for predicting the structure of summaries (2009) Proceedings of the 2009 Workshop on Language Generation and Summarisation, pp. 31-38. , Association for Computational Linguistics; Siddharthan, A., An architecture for a text simplification system (2002) Language Engineering Conference, 2002. Proceedings, pp. 64-71. , IEEE; Tanaka, H., Kinoshita, A., Kobayakawa, T., Kumano, T., Kato, N., Syntax-driven sentence revision for broadcast news summarization (2009) Proceedings of the 2009 Workshop on Language Generation and Summarisation, pp. 39-47. , Association for Computational Linguistics; Woodsend, K., Lapata, M., Wikisimple: Automatic simplification of wikipedia articles (2011) Aaai; Wubben, S., Van Den Bosch, A., Krahmer, E., Sentence simplification by monolingual machine translation (2012) Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-volume 1, pp. 1015-1024. , Association for Computational Linguistics; Yamangil, E., Shieber, S.M., Bayesian synchronous tree-substitution grammar induction and its application to sentence compression (2010) Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pp. 937-947. , Association for Computational Linguistics; Yoshikawa, K., Hirao, T., Iida, R., Okumura, M., Sentence compression with semantic role constraints (2012) Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-volume 2, pp. 349-353. , Association for Computational Linguistics; Zajic, D., Dorr, B.J., Lin, J., Schwartz, R., Multi-candidate reduction: Sentence compression as a tool for document summarization tasks (2007) Information Processing & Management, 43 (6), pp. 1549-1570",,,,,,Article,"Final","",Scopus,2-s2.0-84957598648
"Mehler A., Lücking A., Menke P.","13907942400;55918401600;37007738900;","Assessing cognitive alignment in different types of dialog by means of a network model",2012,"Neural Networks","32",,,"159","164",,4,"10.1016/j.neunet.2012.02.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861762399&doi=10.1016%2fj.neunet.2012.02.013&partnerID=40&md5=26a67baacbef087092153f8439bfccda","We present a network model of dialog lexica, called TiTAN (Two-layer Time-Aligned Network) series. TiTAN series capture the formation and structure of dialog lexica in terms of serialized graph representations. The dynamic update of TiTAN series is driven by the dialog-inherent timing of turn-taking. The model provides a link between neural, connectionist underpinnings of dialog lexica on the one hand and observable symbolic behavior on the other. On the neural side, priming and spreading activation are modeled in terms of TiTAN networking. On the symbolic side, TiTAN series account for cognitive alignment in terms of the structural coupling of the linguistic representations of dialog partners. This structural stance allows us to apply TiTAN in machine learning of data of dialogical alignment. In previous studies, it has been shown that aligned dialogs can be distinguished from non-aligned ones by means of TiTAN -based modeling. Now, we simultaneously apply this model to two types of dialog: task-oriented, experimentally controlled dialogs on the one hand and more spontaneous, direction giving dialogs on the other. We ask whether it is possible to separate aligned dialogs from non-aligned ones in a type-crossing way. Starting from a recent experiment (. Mehler, Lücking, & Menke, 2011a), we show that such a type-crossing classification is indeed possible. This hints at a structural fingerprint left by alignment in networks of linguistic items that are routinely co-activated during conversation. © 2012 Elsevier Ltd.","Alignment; Networks; Similarity; Spontaneous dialog; Task-oriented dialog","Dynamic update; Graph representation; Linguistic representations; Network models; Similarity; Spontaneous dialog; Structural coupling; Task-oriented dialog; Turn-taking; Two layers; Classification (of information); Networks (circuits); Alignment; article; artificial neural network; cognition; communication protocol; communication skill; computer simulation; data analysis software; intermethod comparison; language ability; learning algorithm; mathematical computing; mathematical model; priority journal; process development; quantitative analysis; reinforcement; social interaction; stimulus response; task performance; Algorithms; Artificial Intelligence; Cognition; Communication; Humans; Neural Networks (Computer)","Anderson, A.H., Bader, M., Bard, E.G., Boyle, E., Doherty, G., Garrod, S., The HCRC Map Task corpus (1991) Language and Speech, 34 (4), pp. 351-366; (1996) Repetition in dialogue, , Niemeyer, Tübingen, C. Bazzanella (Ed.); Branigan, H.P., Pickering, M.J., Cleland, A.A., Syntactic co-ordination in dialogue (2000) Cognition, 25, pp. B13-B25; Čermák, F., Idioms and morphology (2007) Phraseology. An international handbook of contemporary research, pp. 20-26. , Walter de Gruyter, Berlin, New York, H. Burger, D. Dobrovolskij, P. Kühn, N.R. Norrick (Eds.); Church, K.W., (2000), pp. 180-186. , Empirical estimates of adaptation: the chance of two noriegas is closer to p/2 than p2. In Proceedings of coling 2000, Saarbrücken; Clark, H.H., Wilkes-Gibbs, D., Referring as a collaborative process (1986) Cognition, 22, pp. 1-39; Dehmer, M., Information processing in complex networks: graph entropy and information functionals (2008) Applied Mathematics and Computation, 201, pp. 82-94; Garrod, S., Anderson, A., Saying what you mean in dialogue: a study in conceptual and semantic co-ordination (1987) Cognition, 27, pp. 181-218; Garrod, S., Pickering, M.J., Why is conversation so easy? (2004) Trends in Cognitive Sciences, 8 (1), pp. 8-11; Garrod, S., Pickering, M.J., Alignment in dialogue (2007) Oxford handbook of psycholinguistics, pp. 443-451. , Oxford University Press, Oxford, UK, (Chapter 26), G. Gaskell (Ed.); Giles, H., Powesland, P.F., (1975) Speech styles and social evaluation, , Academic Press, London; Godfrey, J.J., Holliman, E.C., McDaniel, J., SWITCHBOARD: telephone speech corpus for research and development (1992), 1, pp. 517-520. , In Proc. of IEEE ICASSP-92; Hadelich, K., Pickering, M.J., Branigan, H.P., Crocker, M.W., Alignment in dialogue: effects of visual versus verbal-feedback (2004), pp. 35-40. , In Proc. of catalog'04; Healey, P.G.T., Howes, C., Purver, M., Does structural priming occur in ordinary conversation? (2010) In Proc. of conference on linguistic evidence., , Tübingen, Germany; Howes, C., Healey, P.G.T., Purver, M., Tracking lexical and syntactic alignment in conversation (2010), pp. 2004-2009. , In Proc. of CogSci'10; Jackendoff, R., (2002) Foundations of language. Brain, meaning, grammar, evolution, , Oxford University Press, Oxford, UK; Kövecses, Z., (2002) Metaphor: a practical introduction, , Oxford University Press, Cary; Kraskov, A., Grassberger, P., MIC: mutual information based hierarchical clustering (2008) Information theory and statistical learning, pp. 101-123. , Springer, New York, F. Emmert-Streib, M. Dehmer (Eds.); Kuiper, K., (1996) Smooth talkers: the linguistic performance of auctioneers and sportscasters, , Lawrence Earlbaum Associates, Inc., Mahwah, New Jersey; Kuiper, K., On the linguistic properties of formulaic speech (2000) Oral Tradition, 15 (2), pp. 279-305; Lücking, A., Bergmann, K., Hahn, F., Kopp, S., Rieser, H., The Bielefeld speech and gesture alignment corpus (SaGA) (2010), 5, pp. 92-98. , In Multimodal corpora: advances in capturing, coding and analyzing multimodality. LREC 2010. Malta; Mehler, A., Lücking, A., Menke, P., From neural activation to symbolic alignment: a network-based approach to the formation of dialogue lexica (2011), 8, pp. 527-536. , In Proc. of IJCNN 2011. San Jose; Mehler, A., Lücking, A., Menke, P., Modelling lexical alignment in spontaneous direction dialogue data by means of a lexicon network model (2011), 2. , In Proc. of CICLing 2011. Tokyo; Mehler, A., Lücking, A., Weiß, P., A network model of interpersonal alignment in dialogue (2010) Entropy, 12 (6), pp. 1440-1483; Miller, G., Towards ethnographies of institutional discourse: proposals and suggestions (1994) Journal of Contemporary Ethnography, 23 (3), pp. 280-306; Newman, M.E.J., The structure and function of complex networks (2003) SIAM Review, 45, pp. 167-256; Norrick, N.R., Proverbs as set phrases (2007) Phraseology. An international handbook of contemporary research, pp. 381-393. , Walter de Gruyter, Berlin, New York, H. Burger, D. Dobrovolskij, P. Kühn, N.R. Norrick (Eds.); Pickering, M.J., Garrod, S., Toward a mechanistic psychology of dialogue (2004) Journal of Behavioral and Brain Science, 27 (2), pp. 169-190; Pulvermüller, F., (2002) The neuroscience of language: on brain circuits of words and serial order, , Cambridge University Press, Cambridge, UK; Reitter, D., Keller, F., Moore, J.D., Computational modelling of structural priming in dialogue (2006), pp. 121-124. , In Proc. of NAACL-Short'06. ACL; Reitter, D., Moore, J.D., Keller, F., Priming of syntactic rules in task-oriented dialogue and spontaneous conversation (2006), pp. 685-690. , In Proc. of CogSci'06; Sacks, H., Schegloff, E.A., Jefferson, G., A simplest systematics for the organization of turn-taking for conversation (1974) Language, 50 (4), pp. 696-735; Tannen, D., (2007) Talking voices: repetition, dialogue, and imagery in conversational discourse, , Cambridge University Press, Cambridge, UK; Weiß, P., Pfeiffer, T., Schaffranietz, G., Rickheit, G., Coordination in dialog (2008) In Proc. of 8th Annual Meeting of the Cognitive Science Society of Germany, 4, pp. 1-17. , Saarbrücken",,,,,,Article,"Final","",Scopus,2-s2.0-84861762399
"Silva J., Coheur L., Mendes A.C., Wichert A.","57188734069;8075360000;25031944200;24470073300;","From symbolic to sub-symbolic information in question classification",2011,"Artificial Intelligence Review","35","2",,"137","154",,126,"10.1007/s10462-010-9188-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956078298&doi=10.1007%2fs10462-010-9188-4&partnerID=40&md5=122e6c4f8a49ee3c6e33182ffe606bf9","Question Answering (QA) is undoubtedly a growing field of current research in Artificial Intelligence. Question classification, a QA subtask, aims to associate a category to each question, typically representing the semantic class of its answer. This step is of major importance in the QA process, since it is the basis of several key decisions. For instance, classification helps reducing the number of possible answer candidates, as only answers matching the question category should be taken into account. This paper presents and evaluates a rulebased question classifier that partially founds its performance in the detection of the question headword and in its mapping into the target category through the use ofWordNet. Moreover, we use the rule-based classifier as a features' provider of a machine learning-based question classifier. A detailed analysis of the rule-base contribution is presented. Despite using a very compact feature space, state of the art results are obtained. © Springer Science+Business Media B.V. 2010.","(Sub)symbolic information; Headword; Question classification; WordNet","(Sub)symbolic information; Feature space; Headword; Question Answering; Question categories; Question classification; Rule base; Rule based; Rule-based classifier; Semantic class; State of the art; Sub-symbolic; Wordnet; Artificial intelligence; Semantics","Amaral, C., Cassan, A., Figueira, H., Martins, A., Mendes, A., Mendes, P., Pinto, C., Vidal, D., Priberam's question answering system in QA@CLEF 2007 (2008) Advances in Multilingual and Multimodal Information Retrieval: 8th Workshop of the Cross-language Evaluation Forum, CLEF 2007, pp. 364-371. , http://dx.doi.org/10.1007/978-3-540-85760-0_46, Budapest, Hungary, September 19-21, 2007. Revised Selected Papers, Berlin, Heidelberg, 2008. Springer. ISBN 978-3-540-85759-4; Bhagat, R., Leuski, A., Hovy, E., Shallow semantic parsing despite little training data (2005) Proceedings of the ACL/SIGPARSE 9th International Workshop on Parsing Technologies, , Vancouver, Canada; Blunsom, P., Kocik, K., Curran, J.R., Question classification with log-linear models (2006) SIGIR '06: Proceedings of the 29th Annual International ACM SIGIR conference on research and development in information retrieval, pp. 615-616. , ACM, New York, USA, ISBN 1-59593-369-7; Carlson, A.J., Cumby, C.M., Rosen, J.L., Roth, D., (1999) Snow User Guide, , Technical report UIUC-DCS-R-99-210, Champaign, IL; Chang, C-.C., Lin, C-.J., (2001) LIBSVM: A Library for Support Vectormachines, , http://wwwcsie.ntu.edu.tw/cjlin/libsvm, Software available at; Collins, M.J., (1999) Head-driven Statistical Models for Natural Language Parsing, , PhD thesis, Philadelphia, PA, USA; Fellbaum, C., (1998) WordNet: An Electronic Lexical Database., , http://books.google.es/books?hl=es&lr=&id=Rehu8OOzMIMC&oi= fnd&pg=PR11, MIT, Cambridge. URL; Hermjakob, U., Hovy, E., Lin, C-.Y., Automated question answering in Webclopedia: A demonstration. In: Proceedings of the second international conference on human language technology research (2002) Morgan Kaufmann Publishers, pp. 370-371. , Inc, San Francisco; Huang, Z., Thint, M., Qin, Z., Question classification using head words and their hypernyms (2008) EMNLP, pp. 927-936; Judge, J., Cahill, A., Van Genabith, J., Questionbank: Creating a corpus of parse-annotated questions (2006) ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pp. 497-504. , http://dx.doi.org/10.3115/1220175.1220238, Association for Computational Linguistics, Morristown, NJ, USA; Krishnan, V., Das, S., Chakrabarti, S., Enhanced answer type inference from questions using sequential models (2005) HLT '05: Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pp. 315-322. , http://dx.doi.org/10.3115/1220575.1220615, Association for Computational Linguistics, Morristown, NJ, USA; Kwok, C.C.T., Etzioni, O., Weld, D.S., Scaling question answering to the web (2001) WWW '01: Proceedings of the 10th International Conference on World Wide Web, pp. 150-161. , http://doi.acm.org/10.1145/371920.371973, ACMNew York, NY, USA, ISBN 1-58113-348-0; Li, F., Zhang, X., Yuan, J., Zhu, X., Classifying what-type questions by head noun tagging (2008) Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pp. 481-488. , http://www.aclweb.org/anthology/C08-1061, August, Manchester, UK, Coling 2008 Organizing Committee. URL; Li, X., Roth, D., Learning question classifiers (2002) Proceedings of the 19th International Conference on Computational Linguistics, pp. 1-7. , http://dx.doi.org/10.3115/1072228.1072378, Association for Computational Linguistics, Morristown, NJ, USA; Mendes, A., Coheur, L., Mamede, N.J., Ribeiro, R.D., De Matos, D.M., Batista, F., QA@L2F, first steps at QA@CLEF (2008) Advances in Multilingual and Multimodal Information Retrieval Volume 5152 of Lecture Notes in Computer Science, , Springer, Berlin; Metzler, D., Croft, W.B., Analysis of statistical question classification for fact-based questions (2005) Information Retrieval, 8 (3), pp. 481-504. , DOI 10.1007/s10791-005-6995-3; Moldovan, D., Paşca, M., Harabagiu, S., Surdeanu, M., Performance issues and error analysis in an open-domain question answering system (2003) ACM Trans Inf Syst, 21 (2), pp. 133-154; Moldovan, D.I., Harabagiu, S.M., Paşca, M., Mihalcea, R., Girju, R., Goodrum, R., Rus, V., The structure and performance of an open-domain question answering system (2000) ACL; Newell, A., (1990) Unified Theories of Cognition, , Harvard University Press, Harvard; Pan, Y., Tang, Y., Lin, L., Luo, Y., Question classification with semantic tree kernel (2008) SIGIR '08: Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 837-838. , http://doi.acm.org/10.1145/1390334.1390530, ACM, New York, NY, USA,ISBN:978-1-60558-164-4; Petrov, S., Klein, D., Improved inference for unlexicalized parsing (2007) Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, Association for Computational Linguistics, pp. 404-411. , http://www.aclweb.org/anthology/N/N07/N07-1051, Rochester, New York; Saquete, E., Vicedo, J.L., Martínez-Barco, P., Munoz, R., Llorens, H., Enhancing QA systems with complex temporal question processing capabilities (2009) J Artif Intell Res, 35, pp. 299-330; Sharada, B.A., Girish, P.M., (2004) Wordnet has No 'Recycle Bin'; Simon Herbert, A., (1969) The Sciences of the Artificial, , 1st edn MIT, Cambridge; Sun, R., A two-level hybrid architecture for structuring knowledge for commonsense reasoning (1995) Computational Architectures Integrating Neural and Symbolic Processing, pp. 247-282. , Sun R, Bookman LA (eds), chap 8. Kluwer, Dordrecht; Tarski, A., (1956) Logic, Semantics, Metamathematics, , Oxford University Press, London; Zhang, D., Lee, W.S., Question classification using support vector machines (2003) SIGIR '03: Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 26-32. , http://doi.acm.org/10.1145/860435.860443, ACM, New York, NY, USA, ISBN:1-58113-646-3",,,,,,Article,"Final","",Scopus,2-s2.0-79956078298
"Es-Sabery F., Hair A., Qadir J., Sainz-De-Abajo B., Garcia-Zapirain B., Torre-DIez I.","57216687150;6603926985;57213299572;36186036700;35732954700;57224052173;","Sentence-Level Classification Using Parallel Fuzzy Deep Learning Classifier",2021,"IEEE Access","9",,"9333555","17943","17985",,2,"10.1109/ACCESS.2021.3053917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106847388&doi=10.1109%2fACCESS.2021.3053917&partnerID=40&md5=0ac6e3c956a44104600e5c8a92fc0476","At present, with the growing number of Web 2.0 platforms such as Instagram, Facebook, and Twitter, users honestly communicate their opinions and ideas about events, services, and products. Owing to this rise in the number of social platforms and their extensive use by people, enormous amounts of data are produced hourly. However, sentiment analysis or opinion mining is considered as a useful tool that aims to extract the emotion and attitude from the user-posted data on social media platforms by using different computational methods to linguistic terms and various Natural Language Processing (NLP). Therefore, enhancing text sentiment classification accuracy has become feasible, and an interesting research area for many community researchers. In this study, a new Fuzzy Deep Learning Classifier (FDLC) is suggested for improving the performance of data-sentiment classification. Our proposed FDLC integrates Convolutional Neural Network (CNN) to build an effective automatic process for extracting the features from collected unstructured data and Feedforward Neural Network (FFNN) to compute both positive and negative sentimental scores. Then, we used the Mamdani Fuzzy System (MFS) as a fuzzy classifier to classify the outcomes of the two used deep (CNN+FFNN) learning models in three classes, which are: Neutral, Negative, and Positive. Also, to prevent the long execution time taking by our hybrid proposed FDLC, we have implemented our proposal under the Hadoop cluster. An experimental comparative study between our FDLC and some other suggestions from the literature is performed to demonstrate our offered classifier's effectiveness. The empirical result proved that our FDLC performs better than other classifiers in terms of true positive rate, true negative rate, false positive rate, false negative rate, error rate, precision, classification rate, kappa statistic, F1-score and time consumption, complexity, convergence, and stability. © 2013 IEEE.","convolutional neural network (CNN); Deep learning; feedforward neural network (FFNN); fuzzy logic; Hadoop Distributed File System (HDFS); Hadoop framework; MapReduce; sentiment analysis","Classification (of information); Clustering algorithms; Convolutional neural networks; Data mining; Feedforward neural networks; Fuzzy sets; Linguistics; Sentiment analysis; Social networking (online); Classification rates; False positive rates; Feedforward neural networks (FFNN); Learning classifiers; Mamdani fuzzy system; NAtural language processing; Sentiment classification; Social media platforms; Deep learning","Anagha, M., Kumar, R.R., Sreetha, K., Reghu Raj, P.C., Fuzzy logic based hybrid approach for sentiment analysisl of malayalam movie reviews (2015) Proc. IEEE Int. Conf. Signal Process., Informat., Com-mun. Energy Syst. (SPICES), pp. 1-4. , Feb; Sathe, J.B., Mali, M.P., A hybrid sentiment classification method using neural network and fuzzy logic (2017) Proc. 11th Int. Conf. Intell. Syst. Control (ISCO), pp. 93-96. , Jan; Biltawi, M., Etaiwi, W., Tedmori, S., Shaout, A., Fuzzy based sentiment classification in the Arabic language (2019) Intelligent Systems and Applica-tions (Advances in Intelligent Systems and Computing), 868. , K. Arai, S. Kapoor, and R. Bhatia, Eds. Cham, Switzerland: Springer; Kumari, U., Sharma, A.K., Soni, D., Sentiment analysis of smart phone product review using SVM classification technique (2017) Proc. Int. Conf. Energy, Commun., Data Anal. Soft Comput. (ICECDS), pp. 1469-1474. , Aug; Thein, Y., Khin, T.N., Comparing SVM and KNN algorithms for Myanmar news sentiment analysis system Proc. 6th Int. Conf. Comput. Data Eng. (ICCDE), New York, NY, USA: Association for Computing Machinery, 2020, pp. 65-69; Singh, S.N., Sarraf, T., Sentiment analysis of a product based on user reviews using random forests algorithm (2020) Proc. 10th Int. Conf. Cloud Comput., Data Sci. Eng. (Confluence), pp. 112-116. , Jan; Ramadhan, W.P., Astri Novianty, S.T.M.T., Casi Setianingsih, S.T.M.T., Sentiment analysis using multinomial logistic regression (2017) Proc. Int. Conf. Control, Electron., Renew. Energy Commun. (ICCREC), pp. 46-49. , Sep; Chakraborty, S., Biswas, A., Bose, B., Tiwari, S., Sentiment analysis of review datasets using naive Bayes and K-NN classifier (2016) Proc. IJIEEB, Kolkata, India, 8, pp. 54-62; Es-Sabery, F., Hair, A., An improved ID3 classification algorithm based on correlation function and weighted attribute* (2019) Proc. Int. Conf. Intell. Syst. Adv. Comput. Sci. (ISACS), pp. 1-8. , Dec; Severyn, A., Moschitti, A., Twitter sentiment analysis with deep convolutional neural networks (2015) Proc. 38th Int. ACM SIGIR Conf. Res. Develop. Inf. Retr., pp. 959-962. , Aug; Vassilev, A., (2019) BowTie-A Deep Learning Feedforward Neural Network for Sentiment Analysis, , Gaithersburg, MD, USA: National Institute of Standards and Technology; Li, D., Qian, J., Text sentiment analysis based on long short-term memory (2016) Proc. 1st IEEE Int. Conf. Comput. Commun. Internet (ICCCI), pp. 471-475. , Oct; Kuta, M., Morawiec, M., Kitowski, J., Sentiment analysis with tree-structured gated recurrent units (2017) Text, Speech, and Dialogue, K. Ekstein, and V. Matousek, Eds. Cham, Switzerland: Springer, pp. 74-82; Al-Smadi, M., Qawasmeh, O., Al-Ayyoub, M., Jararweh, Y., Gupta, B., Deep recurrent neural network vs. Support vector machine for aspectbased sentiment analysis of arabic hotels' reviews (2018) J. Comput. Sci., 27, pp. 386-393. , Jul; Rezaeinia, S.M., Rahmani, R., Ghodsi, A., Veisi, H., Sentiment analysis based on improved pre-trained word embeddings (2019) Expert Syst. Appl., 117, pp. 139-147. , Mar; Li, Y., Shen, B., Research on sentiment analysis of microblogging based on LSA and TF-IDF (2017) Proc. 3rd IEEE Int. Conf. Com-put. Commun. (ICCC), pp. 2584-2588. , Dec; Cummins, N., Amiriparian, S., Ottl, S., Gerczuk, M., Schmitt, M., Schuller, B., Multimodal bag-of-words for cross domains sentiment analysis (2018) Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), pp. 4954-4958. , Apr; Liu, B., Zhou, Y., Sun, W., Character-level hybrid convolutional and recurrent neural network for fast-text categorization (2020) Proc. ELM, J. Cao, C. M. Vong, Y. Miche, and A. Lendasse, Eds. Cham, Switzerland: Springer, pp. 108-117; Modha, S., Mandl, T., Majumder, P., Patel, D., Tracking hate in social media: Evaluation, challenges and approaches (2020) SN Comput. Sci., 1, p. 105. , Mar; Devi, B.L., Bai, V.V., Ramasubbareddy, S., Govinda, K., Sentiment analysis on movie reviews (2020) Emerging Research in Data Engineering Systems and Computer Communications, P. V. Krishna and M. S. Obaidat, Eds. Singapore: Springer, pp. 321-328; Bose, R., Dey, R.K., Roy, S., Sarddar, D., Sentiment Analysis on Online Product Reviews (2020) In: M. Tuba, S. Akashe, and A. Joshi, (Eds.) Inf. Commun. Technol. For Sustain. Develop., pp. 559-569. , Springer, Singapore; Uban, A.-S., Dinu, L.P., On transfer learning for detecting abusive language online (2019) Advances in Computational Intelligence, I. Rojas, G. Joya, and A. Catala, Eds. Cham, Switzerland: Springer, pp. 688-700; Rosa, H., Pereira, N., Ribeiro, R., Ferreira, P.C., Carvalho, J.P., Oliveira, S., Coheur, L., Trancoso, I., Automatic cyberbullying detection: A systematic review (2019) Comput. Hum. Behav., 93, pp. 333-345. , Apr; Sharma, D., Sabharwal, M., Goyal, V., Vij, M., Sentiment analysis techniques for social media data: A review (2020) Proc. 1st Int. Conf. Sus-tain. Technol. Comput. Intell., A. K. Luhach, J. A. Kosa, R. C. Poonia, X.-Z. Gao, and D. Singh, Eds. Singapore: Springer, pp. 75-90; Alom, M.Z., Taha, T.M., Yakopcic, C., Westberg, S., Sidike, P., Nasrin, M.S., Hasan, M., Asari, V.K., A stateof-the-art survey on deep learning theory and architectures (2019) Electronics, 8 (3), p. 292. , Mar; Beer, C., Fuzzy thinking: The new science of fuzzy logic. Bart Kosko (1995) Quart. Rev. Biol., 70 (2), p. 210; Zadeh, L.A., Fuzzy logic = computing with words (1996) IEEE Trans. Fuzzy Syst., 4 (2), pp. 103-111. , May; Es-Sabery, F., Hair, A., A MapReduce C4.5 decision tree algorithm based on fuzzy rule-based system (2020) Fuzzy Inf. Eng., pp. 1-28. , Jun; Jin, N., Wu, J., Ma, X., Yan, K., Mo, Y., Multi-task learning model based on multi-scale CNN and LSTM for sentiment classification (2020) IEEE Access, 8, pp. 77060-77072; Almeida, F., Xexéo, G., (2019) Word Embeddings: A Survey, , http://arxiv.org/abs/1901.09069, arXiv:1901.09069; Lan, Y., Hao, Y., Xia, K., Qian, B., Li, C., Stacked residual recurrent neural networks with cross-layer attention for text classification (2020) IEEE Access, 8, pp. 70401-70410; Lin, Y., Li, J., Yang, L., Xu, K., Lin, H., Sentiment analysis with comparison enhanced deep neural network (2020) IEEE Access, 8, pp. 78378-78384; Liu, G., Xu, X., Deng, B., Chen, S., Li, L., A hybrid method for bilingual text sentiment classification based on deep learning (2016) Proc. 17th IEEE/ACIS Int. Conf. Softw. Eng., Artif. Intell., Netw. Paral-lel/Distrib. Comput. (SNPD), pp. 93-98. , May; Jain, A., Jain, V., Sentiment classification of Twitter data belonging to renewable energy using machine learning (2019) J. Inf. Optim. Sci., 40 (2), pp. 521-533. , Feb; Yenter, A., Verma, A., Deep CNN-LSTM with combined kernels from multiple branches for IMDb review sentiment analysis (2017) Proc. IEEE 8th Annu. Ubiquitous Comput., Electron. Mobile Commun. Conf. (UEMCON), pp. 540-546. , Oct; Xing, F.Z., Cambria, E., Welsch, R.E., Intelligent asset allocation via market sentiment views (2018) IEEE Comput. Intell. Mag., 13 (4), pp. 25-34. , Nov; González, J.-A., Pla, F., Hurtado, L.-F., ELiRF-UPV at SemEval-2017 task 4: Sentiment analysis using deep learning (2017) Proc. 11th Int. Workshop Semantic Eval. (SemEval-), pp. 723-727; Wang, G., Qiao, J., Bi, J., Li, W., Zhou, M., TL-GDBN: Growing deep belief network with transfer learning (2019) IEEE Trans. Autom. Sci. Eng., 16 (2), pp. 874-885. , Apr; Hameed, Z., Garcia-Zapirain, B., Sentiment classification using a single-layered BiLSTM model (2020) IEEE Access, 8, pp. 73992-74001; Han, L., Mihaela, C., Fuzzy rule based systems for interpretable sentiment analysis (2017) Proc. 9th Int. Conf. Adv. Comput. Intell., pp. 129-136. , Feb; Wu, K., Zhou, M., Lu, X.S., Huang, L., A fuzzy logic-based text classification method for social media data (2017) Proc. IEEE Int. Conf. Syst., Man, Cybern. (SMC), pp. 1942-1947. , Oct; Vashishtha, S., Susan, S., Fuzzy rule based unsupervised sentiment analysis from social media posts (2019) Expert Syst. Appl., 138. , Dec; Abdul-Jaleel, M., Ali, Y.H., Ibrahim, N.J., Fuzzy logic and genetic algorithm based text classification Twitter (2019) Proc. 2nd Sci. Conf. Comput. Sci. (SCCS), pp. 93-98. , Mar; Wang, G., Jia, Q.-S., Qiao, J., Bi, J., Liu, C., A sparse deep belief network with efficient fuzzy learning framework (2020) Neural Netw., 121, pp. 430-440. , Jan; Kim, Y., Convolutional neural networks for sentence classification (2014) Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1746-1751; Svozil, D., Kvasnicka, V., Pospichal, J., Introduction to multi-layer feed-forward neural networks (1997) Chemometrics Intell. Lab. Syst., 39 (1), pp. 43-62; Pourjavad, E., Mayorga, R.V., A comparative study and measuring performance of manufacturing systems with mamdani fuzzy inference system (2019) J. Intell. Manuf., 30 (3), pp. 1085-1097. , Mar; Fukushima, K., Neocognitron: A hierarchical neural network capable of visual pattern recognition (1988) Neural Netw., 1 (2), pp. 119-130; Chen, Y., (2015) Convolutional Neural Network for Sentence Clas-sification. UWSpace, , http://hdl.handle.net/10012/9592, (Aug.), Accessed: Dec. 29 2020; (2020) The Most Popular Research, Guides, News and More in Artificial Intelli-gence, , https://deepai.org/, Accessed: Dec. 29; Yousuf, H., Salloum, S., Survey analysis: Enhancing the security of vectorization by using word2vec and CryptDB (2020) Adv. Sci., Technol. Eng. Syst. J., 5 (4), pp. 374-380; (2020) COVID-19-Sentiments India[20/03/20-31/05/20], , https://kaggle.com/abhaydhiman/covid19-sentiments, Accessed: Dec. 30; Gangadharan, V., Gupta, D., Amritha, L., Athira, T.A., Paraphrase detection using deep neural network based word embedding techniques (2020) Proc. 4th Int. Conf. Trends Electron. Informat. (ICOEI), pp. 517-521. , Jun; Pennington, J., Socher, R., Manning, C., Glove: Global vectors for word representation (2014) Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1532-1543; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., (2013) Distributed Representations of Words and Phrases and Their Compositionality, , http://arxiv.org/abs/1310.4546, arXiv:1310.4546; Es-Sabery, F., Hair, A., Big data solutions proposed for cluster computing systems challenges: A survey (2020) Proc. 3rd Int. Conf. Netw., Inf. Syst. Secur., pp. 1-7. , Mar",,,,,,Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85106847388
