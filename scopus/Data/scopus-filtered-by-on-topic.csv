Key,Item Type,Publication Year,Author,Title,"Include (0,1)",Notes/Criteria,Input data,Abstract Note,Publication Title,DOI,Url,Date,Date Added,Date Modified,Scopus relevance order
YGHML3ZJ,journalArticle,2013,"Dagan, I.; Roth, D.; Sammons, M.; Zanzotto, F.",Recognizing Textual Entailment: Models and Applications,1,book,,"Download Free Sample In the last few years, a number of NLP researchers have developed and participated in the task of Recognizing Textual Entailment (RTE). This task encapsulates Natural Language Understanding capabilities within a very simple interface: Recognizing when the meaning of a text snippet is contained in the meaning of a second piece of text. This simple abstraction of an exceedingly complex problem has broad appeal partly because it can be conceived also as a component in other NLP applications, from Machine Translation to Semantic Search to Information Extraction. It also avoids commitment to any specific meaning representation and reasoning framework, broadening its appeal within the research community. This level of abstraction also facilitates evaluation, a crucial component of any technological advancement program. This book explains the RTE task formulation adopted by the NLP research community, and gives a clear overview of research in this area. It draws out commonalities in this research, detailing the intuitions behind dominant approaches and their theoretical underpinnings. This book has been written with a wide audience in mind, but is intended to inform all readers about the state of the art in this fascinating field, to give a clear understanding of the principles underlying RTE research to date, and to highlight the short- A nd long-term research goals that will advance this technology. © Morgan and Claypool Publishers. All rights reserved.",Synthesis Lectures on Human Language Technologies,10.2200/S00509ED1V01Y201305HLT023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044727708&doi=10.2200%2fS00509ED1V01Y201305HLT023&partnerID=40&md5=a84d226bcb23ac1ce56a2a02c9430a3f,2013,7/20/21 15:50,7/20/21 15:50,1459
5JDIL466,journalArticle,2018,"Chesani, F.; Galassi, A.; Lippi, M.; Mello, P.",Can deep networks learn to play by the rules? A case study on nine Men's Morris,1,case against combining symbolic with subsymbolic,,"Deep networks have been successfully applied to a wide range of tasks in artificial intelligence, and game playing is certainly not an exception. In this paper, we present an experimental study to assess whether purely subsymbolic systems, such as deep networks, are capable of learning to play by the rules, without any a priori knowledge neither of the game, nor of its rules, but only by observing the matches played by another player. Similar problems arise in many other application domains, where the goal is to learn rules, policies, behaviors, or decisions, simply by the observation of the dynamics of a system.We present a case study conducted with residual networks on the popular board game of Nine Men's Morris, showing that this kind of subsymbolic architecture is capable of correctly discriminating legal from illegal decisions, just from the observation of past matches of a single player. 2017 IEEE. © 2018 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",IEEE Transactions on Games,10.1109/TG.2018.2804039,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077818519&doi=10.1109%2fTG.2018.2804039&partnerID=40&md5=ece5775b2e637ab476fe1d5cab8d448f,2018,7/20/21 15:48,7/20/21 15:48,38
WLW49ADY,journalArticle,2020,"Hitzler, P.; Bianchi, F.; Ebrahimi, M.; Sarker, M.K.",Neural-symbolic integration and the Semantic Web,1,survey,,"Symbolic Systems in Artificial Intelligence which are based on formal logic and deductive reasoning are fundamentally different from Artificial Intelligence systems based on artificial neural networks, such as deep learning approaches. The difference is not only in their inner workings and general approach, but also with respect to capabilities. Neural-symbolic Integration, as a field of study, aims to bridge between the two paradigms. In this paper, we will discuss neural-symbolic integration in its relation to the Semantic Web field, with a focus on promises and possible benefits for both, and report on some current research on the topic. © 2020-IOS Press and the authors. All rights reserved.",Semantic Web,10.3233/SW-190368,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078979352&doi=10.3233%2fSW-190368&partnerID=40&md5=eb9a74a48c2b1364b7000bd5b95c322a,2020,7/20/21 15:48,7/20/21 15:48,1
YXUZIQIU,journalArticle,2021,"Ebrahimi, M.; Eberhart, A.; Bianchi, F.; Hitzler, P.",Towards bridging the neuro-symbolic gap: deep deductive reasoners,1,survey,,"Symbolic knowledge representation and reasoning and deep learning are fundamentally different approaches to artificial intelligence with complementary capabilities. The former are transparent and data-efficient, but they are sensitive to noise and cannot be applied to non-symbolic domains where the data is ambiguous. The latter can learn complex tasks from examples, are robust to noise, but are black boxes; require large amounts of –not necessarily easily obtained– data, and are slow to learn and prone to adversarial examples. Either paradigm excels at certain types of problems where the other paradigm performs poorly. In order to develop stronger AI systems, integrated neuro-symbolic systems that combine artificial neural networks and symbolic reasoning are being sought. In this context, one of the fundamental open problems is how to perform logic-based deductive reasoning over knowledge bases by means of trainable artificial neural networks. This paper provides a brief summary of the authors’ recent efforts to bridge the neural and symbolic divide in the context of deep deductive reasoners. Throughout the paper we will discuss strengths and limitations of models in term of accuracy, scalability, transferability, generalizabiliy, speed, and interpretability, and finally, will talk about possible modifications to enhance desirable capabilities. More specifically, in terms of architectures, we are looking at Memory-augmented networks, Logic Tensor Networks, and compositions of LSTM models to explore their capabilities and limitations in conducting deductive reasoning. We are applying these models on Resource Description Framework (RDF), first-order logic, and the description logic EL+ respectively. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.",Applied Intelligence,10.1007/s10489-020-02165-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100570972&doi=10.1007%2fs10489-020-02165-6&partnerID=40&md5=0003bc9ef2baca0720a980936c047d5a,2021,7/20/21 15:48,7/20/21 15:48,2
LIJBLYR5,journalArticle,2019,"Gromann, D.; Espinosa Anke, L.; Declerck, T.",Special issue on Semantic Deep Learning,1,survey,,"Numerous success use cases involving deep learning have recently started to be propagated to the Semantic Web. Approaches range from utilizing structured knowledge in the training process of neural networks to enriching such architectures with ontological reasoning mechanisms. Bridging the neural-symbolic gap by joining deep learning and Semantic Web not only holds the potential of improving performance but also of opening up new avenues of research. This editorial introduces the Semantic Web Journal special issue on Semantic Deep Learning, which brings together Semantic Web and deep learning research. After a general introduction to the topic and a brief overview of recent contributions, we continue to introduce the submissions published in this special issue. © 2019 - IOS Press and the authors. All rights reserved.",Semantic Web,10.3233/SW-180364,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072388130&doi=10.3233%2fSW-180364&partnerID=40&md5=d257ab8eba9e946dcca7bf59caecf60e,2019,7/20/21 15:48,7/20/21 15:48,7
KIRM4EBZ,journalArticle,2021,"Vonrueden, L.; Mayer, S.; Beckh, K.; Georgiev, B.; Giesselbach, S.; Heese, R.; Kirsch, B.; Walczak, M.; Pfrommer, J.; Pick, A.; Ramamurthy, R.; Garcke, J.; Bauckhage, C.; Schuecker, J.",Informed Machine Learning - A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems,1,survey,,"Despite its great success, machine learning can have its limits when dealing with insufficient training data. A potential solution is the additional integration of prior knowledge into the training process which leads to the notion of informed machine learning. In this paper, we present a structured overview of various approaches in this field. We provide a definition and propose a concept for informed machine learning which illustrates its building blocks and distinguishes it from conventional machine learning. We introduce a taxonomy that serves as a classification framework for informed machine learning approaches. It considers the source of knowledge, its representation, and its integration into the machine learning pipeline. Based on this taxonomy, we survey related research and describe how different knowledge representations such as algebraic equations, logic rules, or simulation results can be used in learning systems. This evaluation of numerous papers on the basis of our taxonomy uncovers key methods in the field of informed machine learning. CCBY",IEEE Transactions on Knowledge and Data Engineering,10.1109/TKDE.2021.3079836,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105863468&doi=10.1109%2fTKDE.2021.3079836&partnerID=40&md5=3945f72c7aa111fb2c91e6d4636de977,2021,7/20/21 15:48,7/20/21 15:48,11
2TUT8Z5S,journalArticle,2021,"van Bekkum, M.; de Boer, M.; van Harmelen, F.; Meyer-Vitali, A.; Teije, A.","Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases",1,survey,,"The unification of statistical (data-driven) and symbolic (knowledge-driven) methods is widely recognized as one of the key challenges of modern AI. Recent years have seen a large number of publications on such hybrid neuro-symbolic AI systems. That rapidly growing literature is highly diverse, mostly empirical, and is lacking a unifying view of the large variety of these hybrid systems. In this paper, we analyze a large body of recent literature and we propose a set of modular design patterns for such hybrid, neuro-symbolic systems. We are able to describe the architecture of a very large number of hybrid systems by composing only a small set of elementary patterns as building blocks. The main contributions of this paper are: 1) a taxonomically organised vocabulary to describe both processes and data structures used in hybrid systems; 2) a set of 15+ design patterns for hybrid AI systems organized in a set of elementary patterns and a set of compositional patterns; 3) an application of these design patterns in two realistic use-cases for hybrid AI systems. Our patterns reveal similarities between systems that were not recognized until now. Finally, our design patterns extend and refine Kautz’s earlier attempt at categorizing neuro-symbolic architectures. © 2021, The Author(s).",Applied Intelligence,10.1007/s10489-021-02394-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108116690&doi=10.1007%2fs10489-021-02394-3&partnerID=40&md5=d23e1c358cf7b9ded5d7fb5ce7d6ad33,2021,7/20/21 15:48,7/20/21 15:48,14
9VD974LX,journalArticle,2020,"Spelda, P.","Machine learning, inductive reasoning, and reliability of generalisations",1,survey,,"The present paper shows how statistical learning theory and machine learning models can be used to enhance understanding of AI-related epistemological issues regarding inductive reasoning and reliability of generalisations. Towards this aim, the paper proceeds as follows. First, it expounds Price’s dual image of representation in terms of the notions of e-representations and i-representations that constitute subject naturalism. For Price, this is not a strictly anti-representationalist position but rather a dualist one (e- and i-representations). Second, the paper links this debate with machine learning in terms of statistical learning theory becoming more viable epistemological tool when it abandons the perspective of object naturalism. The paper then argues that machine learning grounds a form of knowing that can be understood in terms of e- and i-representation learning. Third, this synthesis shows a way of analysing inductive reasoning in terms of reliability of generalisations stemming from a structure of e- and i-representations. In the age of Artificial Intelligence, connecting Price’s dual view of representation with Deep Learning provides an epistemological way forward and even perhaps an approach to how knowing is possible. © 2018, Springer-Verlag London Ltd., part of Springer Nature.",AI and Society,10.1007/s00146-018-0860-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052563918&doi=10.1007%2fs00146-018-0860-6&partnerID=40&md5=d325aae4df228fd7019070f5e8e682bf,2020,7/20/21 15:48,7/20/21 15:48,24
WQ7KRNXL,journalArticle,2011,"Polkowski, L.","Reasoning with Rough Inclusions: Granular Computing, Granular Logics, Perception Calculus, Cognitive and MAS Reasoning",1,survey,UNK,"Rough mereology allows for a plethora of applications in various reasoning schemes due to universality of its primitive predicate of a part to a degree. We have already stressed that by its nature, rough mereology is especially suited to reasoning with collective concepts like geometric figures or solids, or, concepts learned by machine learning methods, i.e., with collective concepts. Those applications are presented in Ch. 8 and Ch. 9. In this chapter, we begin this discussion with a formal approach to the problem of granulation of knowledge and then we examine rough mereological logics: from our results in Ch. 6 it follows that representing implication with a rough inclusion μ leads to logics which extend and generalize fuzzy logics. As an application, we propose a formal rendering of the idea of perception calculus, due to Zadeh [67]. We apply rough mereological schemes to reasoning by multi-agent (MAS) systems, and finally we present a rough mereological variant of cognitive reasoning in neural-like systems.",Intelligent Systems Reference Library,10.1007/978-3-642-22279-5_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885585030&doi=10.1007%2f978-3-642-22279-5_7&partnerID=40&md5=221e2f59d06c09311f92b2904d9fe5d9,2011,7/20/21 15:48,7/20/21 15:48,52
A8RPZG9Y,journalArticle,2019,"Tangiuchi, T.; Mochihashi, D.; Nagai, T.; Uchida, S.; Inoue, N.; Kobayashi, I.; Nakamura, T.; Hagiwara, Y.; Iwahashi, N.; Inamura, T.",Survey on frontiers of language and robotics,1,survey,text,"The understanding and acquisition of a language in a real-world environment is an important task for future robotics services. Natural language processing and cognitive robotics have both been focusing on the problem for decades using machine learning. However, many problems remain unsolved despite significant progress in machine learning (such as deep learning and probabilistic generative models) during the past decade. The remaining problems have not been systematically surveyed and organized, as most of them are highly interdisciplinary challenges for language and robotics. This study conducts a survey on the frontier of the intersection of the research fields of language and robotics, ranging from logic probabilistic programming to designing a competition to evaluate language understanding systems. We focus on cognitive developmental robots that can learn a language from interaction with their environment and unsupervised learning methods that enable robots to learn a language without hand-crafted training data. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",Advanced Robotics,10.1080/01691864.2019.1632223,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068064287&doi=10.1080%2f01691864.2019.1632223&partnerID=40&md5=fb9809699eafb5cf9f5835a69d53fd47,2019,7/20/21 15:48,7/20/21 15:48,60
M36TNPXK,journalArticle,2021,"Cozman, F.G.; Munhoz, H.N.",Some thoughts on knowledge-enhanced machine learning,1,survey,position paper,"How can we employ theoretical insights and practical tools from knowledge representation and reasoning to enhance machine learning, and when is it worthwhile to do so? This paper is based on an invited talk delivered at ECSQARU2019 around this question. It emphasizes the knowledge representation and reasoning side of knowledge-enhanced machine learning, looking at a few case studies: the finite model theory of probabilistic languages, the generation of explanations for embeddings, and an “explainable” version of the Winograd Challenge. © 2021 Elsevier Inc.",International Journal of Approximate Reasoning,10.1016/j.ijar.2021.06.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109146391&doi=10.1016%2fj.ijar.2021.06.003&partnerID=40&md5=fd187a6fb7b604ab8b39c82f94a80793,2021,7/20/21 15:48,7/20/21 15:48,72
DFVAQCYK,journalArticle,2015,"Hüllermeier, E.",Does machine learning need fuzzy logic?,1,survey,,"This article is a short position paper in which the author outlines his (necessarily subjective) perception of current research in fuzzy machine learning, that is, the use of formal concepts and mathematical tools from fuzzy sets and fuzzy logic in the field of machine learning. The paper starts with a critical appraisal of previous contributions to fuzzy machine learning and ends with a suggestion of some directions for future work. © 2015 Elsevier B.V. All rights reserved.",Fuzzy Sets and Systems,10.1016/j.fss.2015.09.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945489768&doi=10.1016%2fj.fss.2015.09.001&partnerID=40&md5=b1842c1a461d20de00951b4effc44cbd,2015,7/20/21 15:48,7/20/21 15:48,75
G7A2MTFU,journalArticle,2019,"Khemlani, S.; Johnson-Laird, P.N.",Why Machines Don’t (yet) Reason Like People,1,survey,,"AI has never come to grips with how human beings reason in daily life. Many automated theorem-proving technologies exist, but they cannot serve as a foundation for automated reasoning systems. In this paper, we trace their limitations back to two historical developments in AI: the motivation to establish automated theorem-provers for systems of mathematical logic, and the formulation of nonmonotonic systems of reasoning. We then describe why human reasoning cannot be simulated by current machine reasoning or deep learning methodologies. People can generate inferences on their own instead of just evaluating them. They use strategies and fallible shortcuts when they reason. The discovery of an inconsistency does not result in an explosion of inferences—instead, it often prompts reasoners to abandon a premise. And the connectives they use in natural language have different meanings than those in classical logic. Only recently have cognitive scientists begun to implement automated reasoning systems that reflect these human patterns of reasoning. A key constraint of these recent implementations is that they compute, not proofs or truth values, but possibilities. © 2019, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.",KI - Kunstliche Intelligenz,10.1007/s13218-019-00599-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074617318&doi=10.1007%2fs13218-019-00599-w&partnerID=40&md5=a6f38ebad9483391866b21845ea15e4f,2019,7/20/21 15:48,7/20/21 15:48,85
JQNQNRGA,journalArticle,2019,"Leeuwenberg, A.; Moens, M.-F.",A survey on temporal reasoning for temporal information extraction from text,1,survey,,"Time is deeply woven into how people perceive, and communicate about the world. Almost unconsciously, we provide our language utterances with temporal cues, like verb tenses, and we can hardly produce sentences without such cues. Extracting temporal cues from text, and constructing a global temporal view about the order of described events is a major challenge of automatic natural language understanding. Temporal reasoning, the process of combining different temporal cues into a coherent temporal view, plays a central role in temporal information extraction. This article presents a comprehensive survey of the research from the past decades on temporal reasoning for automatic temporal information extraction from text, providing a case study on how combining symbolic reasoning with machine learning-based information extraction systems can improve performance. It gives a clear overview of the used methodologies for temporal reasoning, and explains how temporal reasoning can be, and has been successfully integrated into temporal information extraction systems. Based on the distillation of existing work, this survey also suggests currently unexplored research areas. We argue that the level of temporal reasoning that current systems use is still incomplete for the full task of temporal information extraction, and that a deeper understanding of how the various types of temporal information can be integrated into temporal reasoning is required to drive future research in this area. © 2019 AI Access Foundation. All rights reserved.",Journal of Artificial Intelligence Research,10.1613/jair.1.11727,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075483377&doi=10.1613%2fjair.1.11727&partnerID=40&md5=1db8d20cce9d93aa12e06ec9ad74540f,2019,7/20/21 15:48,7/20/21 15:48,87
N74Z86UI,journalArticle,2014,"Bottou, L.",From machine learning to machine reasoning: An essay,1,survey,,"A plausible definition of ""reasoning"" could be ""algebraically manipulating previously acquired knowledge in order to answer a new question"". This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated ""all-purpose"" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up. © 2013 The Author(s).",Machine Learning,10.1007/s10994-013-5335-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894902026&doi=10.1007%2fs10994-013-5335-x&partnerID=40&md5=294e90e9a10ef0743770ebe073caba74,2014,7/20/21 15:48,7/20/21 15:48,150
UN2ELMEG,journalArticle,2011,"Prentzas, J.; Hatzilygeroudis, I.",Neurules-A Type of Neuro-symbolic Rules: An Overview,1,survey,,"Neurules are a kind of integrated rules integrating neurocomputing and production rules. Each neurule is represented as an adaline unit. Thus, the corresponding neurule base consists of a number of autonomous adaline units (neurules). Due to this fact, a modular and natural knowledge base is constructed, in contrast to existing connectionist knowledge bases. In this paper, we present an overview of our main work involving neurules. We focus on aspects concerning construction of neurules, efficient updates of neurule bases, neurule-based inference and combination of neurules with case-based reasoning. Neurules may be constructed from either symbolic rule bases or empirical data in the form of training examples. Due to the fact that the source knowledge of neurules may change with time, efficient updates of corresponding neurule bases to reflect such changes are performed. Furthermore, the neurule-based inference mechanism is interactive and more efficient than the inference mechanism used in connectionist expert systems. Finally, neurules can be naturally combined with case-based reasoning to provide a more effective representation scheme that exploits multiple knowledge sources and provides enhanced reasoning capabilities. © Springer-Verlag Berlin Heidelberg 2011.","Smart Innovation, Systems and Technologies",10.1007/978-3-642-19618-8_9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875611088&doi=10.1007%2f978-3-642-19618-8_9&partnerID=40&md5=28cfe0939e764527c00dabf882416579,2011,7/20/21 15:48,7/20/21 15:48,182
E9QRNUBD,journalArticle,2019,"Couso, I.; Borgelt, C.; Hullermeier, E.; Kruse, R.",Fuzzy sets in data analysis: From statistical foundations to machine learning,1,survey,fuzzy logic,"Basic ideas and formal concepts from fuzzy sets and fuzzy logic have been used successfully in various branches of science and engineering. This paper elaborates on the use of fuzzy sets in the broad field of data analysis and statistical sciences, including modern manifestations such as data mining and machine learning. In the fuzzy logic community, this branch of research has recently gained in importance, especially due to the emergence of data science as a new scientific discipline, and the increasing relevance of machine learning as a key methodology of modern artificial intelligence. This development has been accompanied by an internal shift from largely knowledge-based to strongly data-driven fuzzy modeling and systems design. Reflecting on the historical dimension and evolution of the area, we discuss the role of fuzzy logic in data analysis and related fields, highlight existing contributions of fuzzy sets in these fields, and outline interesting directions for future work. © 2005-2012 IEEE.",IEEE Computational Intelligence Magazine,10.1109/MCI.2018.2881642,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060024760&doi=10.1109%2fMCI.2018.2881642&partnerID=40&md5=6ec75e137f0fed53d6fb882182688cd1,2019,7/20/21 15:48,7/20/21 15:48,214
TZPURNF3,journalArticle,2012,"Rettinger, A.; Lösch, U.; Tresp, V.; D'Amato, C.; Fanizzi, N.",Mining the semantic web: Statistical learning for next generation knowledge bases,1,survey,,"In the SemanticWeb vision of theWorldWideWeb, content will not only be accessible to humans but will also be available in machine interpretable form as ontological knowledge bases. Ontological knowledge bases enable formal querying and reasoning and, consequently, a main research focus has been the investigation of how deductive reasoning can be utilized in ontological representations to enable more advanced applications. However, purely logic methods have not yet proven to be very effective for several reasons: First, there still is the unsolved problem of scalability of reasoning to Web scale. Second, logical reasoning has problems with uncertain information, which is abundant on SemanticWeb data due to its distributed and heterogeneous nature. Third, the construction of ontological knowledge bases suitable for advanced reasoning techniques is complex, which ultimately results in a lack of such expressive real-world data sets with large amounts of instance data. From another perspective, the more expressive structured representations open up new opportunities for data mining, knowledge extraction and machine learning techniques. If moving towards the idea that part of the knowledge already lies in the data, inductive methods appear promising, in particular since inductive methods can inherently handle noisy, inconsistent, uncertain and missing data. While there has been broad coverage of inducing concept structures from less structured sources (text, Web pages), like in ontology learning, given the problems mentioned above, we focus on new methods for dealing with Semantic Web knowledge bases, relying on statistical inference on their standard representations. We argue that machine learning research has to offer a wide variety of methods applicable to different expressivity levels of SemanticWeb knowledge bases: ranging from weakly expressive but widely available knowledge bases in RDF to highly expressive first-order knowledge bases, this paper surveys statistical approaches to mining the Semantic Web. We specifically cover similarity and distance-based methods, kernel machines, multivariate prediction models, relational graphical models and first-order probabilistic learning approaches and discuss their applicability to Semantic Web representations. Finally, we present selected experimentswhich were conducted on SemanticWebmining tasks for some of the algorithms presented before. This is intended to show the breadth and general potential of this exiting new research and application area for data mining. © The Author(s) 2012.",Data Mining and Knowledge Discovery,10.1007/s10618-012-0253-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870679926&doi=10.1007%2fs10618-012-0253-2&partnerID=40&md5=57b77f00f808fa74152d2e71b6e46930,2012,7/20/21 15:48,7/20/21 15:48,228
BHHRLTYN,journalArticle,2011,"Dodig-Crnkovic, G.","Significance of models of computation, from turing model to natural computation",1,survey,,"The increased interactivity and connectivity of computational devices along with the spreading of computational tools and computational thinking across the fields, has changed our understanding of the nature of computing. In the course of this development computing models have been extended from the initial abstract symbol manipulating mechanisms of stand-alone, discrete sequential machines, to the models of natural computing in the physical world, generally concurrent asynchronous processes capable of modelling living systems, their informational structures and dynamics on both symbolic and sub-symbolic information processing levels. Present account of models of computation highlights several topics of importance for the development of new understanding of computing and its role: natural computation and the relationship between the model and physical implementation, interactivity as fundamental for computational modelling of concurrent information processing systems such as living organisms and their networks, and the new developments in logic needed to support this generalized framework. Computing understood as information processing is closely related to natural sciences; it helps us recognize connections between sciences, and provides a unified approach for modeling and simulating of both living and non-living systems. © Springer Science+Business Media B.V. 2011.",Minds and Machines,10.1007/s11023-011-9235-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959541227&doi=10.1007%2fs11023-011-9235-1&partnerID=40&md5=45e543febfe4fb73c47ee2543f846541,2011,7/20/21 15:48,7/20/21 15:48,252
T3BYK5QU,journalArticle,2014,"Rossi, F.",Collective decision making: A great opportunity for constraint reasoning,1,survey,,"Collective decision making is an area of increasingly growing interest, mainly due to the rise of many IT-enabled environments where people connect and share information with others. We believe that constraint reasoning can have a major impact in this field, by providing general and flexible frameworks to model agents' preferences over the alternative decisions, efficient algorithms to compute the best individual and collective decisions, and innovative approaches to deal with missing information. However, in order to do this, we claim that constraint reasoning should increase its efforts to open up to other research areas, such as voting and game theory, multi-agent systems, machine learning, and reasoning under uncertainty. © 2013 Springer Science+Business Media New York.",Constraints,10.1007/s10601-013-9153-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898774890&doi=10.1007%2fs10601-013-9153-3&partnerID=40&md5=8d339a0c3d54927ae9ca7f5f6aec796f,2014,7/20/21 15:48,7/20/21 15:48,298
NZDFEZUF,journalArticle,2019,"Sheth, A.; Gaur, M.; Kursuncu, U.; Wickramarachchi, R.",Shades of Knowledge-Infused Learning for Enhancing Deep Learning,1,survey,,"Deep Learning has already proven to be the primary technique to address a number of problems. It holds further promise in solving more challenging problems if we can overcome obstacles, such as the lack of quality training data and poor interpretability. The exploitation of domain knowledge and application semantics can enhance existing deep learning methods by infusing relevant conceptual information into a statistical, data-driven computational approach. This will require resolving the impedance mismatch due to different representational forms and abstractions between symbolic and statistical AI techniques. In this article, we describe a continuum that comprises of three stages for infusion of knowledge into the machine/deep learning architectures. As this continuum progresses across these three stages, it starts with shallow infusion in the form of embeddings, and attention and knowledge-based constraints improve with a semideep infusion. Toward the end reflecting deeper incorporation of knowledge, we articulate the value of incorporating knowledge at different levels of abstractions in the latent layers of neural networks. While shallow infusion is well studied and semideep infusion is in progress, we consider Deep Infusion of Knowledge as a new paradigm that will significantly advance the capabilities and promises of deep learning. © 1997-2012 IEEE.",IEEE Internet Computing,10.1109/MIC.2019.2960071,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078880219&doi=10.1109%2fMIC.2019.2960071&partnerID=40&md5=b40371358e6addc357267e24838743f7,2019,7/20/21 15:48,7/20/21 15:48,299
2C3YIFAI,journalArticle,2019,"Guo, L.; Wu, J.; Li, J.",Complexity at Mesoscales: A Common Challenge in Developing Artificial Intelligence,1,survey,,"Exploring the physical mechanisms of complex systems and making effective use of them are the keys to dealing with the complexity of the world. The emergence of big data and the enhancement of computing power, in conjunction with the improvement of optimization algorithms, are leading to the development of artificial intelligence (AI) driven by deep learning. However, deep learning fails to reveal the underlying logic and physical connotations of the problems being solved. Mesoscience provides a concept to understand the mechanism of the spatiotemporal multiscale structure of complex systems, and its capability for analyzing complex problems has been validated in different fields. This paper proposes a research paradigm for AI, which introduces the analytical principles of mesoscience into the design of deep learning models. This is done to address the fundamental problem of deep learning models detaching the physical prototype from the problem being solved; the purpose is to promote the sustainable development of AI. © 2019 THE AUTHORS",Engineering,10.1016/j.eng.2019.08.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072045193&doi=10.1016%2fj.eng.2019.08.005&partnerID=40&md5=708378b1411cf987624c0a08ccac9c33,2019,7/20/21 15:48,7/20/21 15:48,328
PEWIPSFT,journalArticle,2017,"Forbus, K.D.; Liang, C.; Rabkina, I.",Representation and Computation in Cognitive Models,1,survey,,"One of the central issues in cognitive science is the nature of human representations. We argue that symbolic representations are essential for capturing human cognitive capabilities. We start by examining some common misconceptions found in discussions of representations and models. Next we examine evidence that symbolic representations are essential for capturing human cognitive capabilities, drawing on the analogy literature. Then we examine fundamental limitations of feature vectors and other distributed representations that, despite their recent successes on various practical problems, suggest that they are insufficient to capture many aspects of human cognition. After that, we describe the implications for cognitive architecture of our view that analogy is central, and we speculate on roles for hybrid approaches. We close with an analogy that might help bridge the gap. Copyright © 2017 Cognitive Science Society, Inc.",Topics in Cognitive Science,10.1111/tops.12277,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021324802&doi=10.1111%2ftops.12277&partnerID=40&md5=c3e0b2d59cc2ae1e283bc2530ca7ad23,2017,7/20/21 15:48,7/20/21 15:48,412
7KQW8ICA,journalArticle,2019,"Fuller, T.J.","Cognitive Architecture, Holistic Inference and Bayesian Networks",1,survey,,"Two long-standing arguments in cognitive science invoke the assumption that holistic inference is computationally infeasible. The first is Fodor’s skeptical argument toward computational modeling of ordinary inductive reasoning. The second advocates modular computational mechanisms of the kind posited by Cosmides, Tooby and Sperber. Based on advances in machine learning related to Bayes nets, as well as investigations into the structure of scientific and ordinary information, I maintain neither argument establishes its architectural conclusion. Similar considerations also undermine Fodor’s decades-long diagnosis of artificial intelligence research as confounded by an inability to circumscribe the amount of information relevant to inferential processes. This diagnosis is particularly inapposite with respect to Bayes nets, since one of their strengths as machine learning systems has been their capacity to reason probabilistically about large data sets whose size overwhelms the capacities of individual human reasoners. A general moral follows from these criticisms: Insights into artificial and human cognitive systems are likely to be cultivated by focusing greater attention on the structure and density of connections among items of information that are available to them. © 2019, Springer Nature B.V.",Minds and Machines,10.1007/s11023-019-09505-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073679712&doi=10.1007%2fs11023-019-09505-7&partnerID=40&md5=8aaf0c92ff8a3adb2183866b036b611e,2019,7/20/21 15:49,7/20/21 15:49,617
J2MLKV49,journalArticle,2019,"Licato, J.; Zhang, Z.",Evaluating representational systems in artificial intelligence,1,survey,,"All artificial reasoners work within representational systems. These systems, which may have varying levels of formality or detail, determine the space of possible representations over which the artificial reasoner can operate, by defining the syntactic and semantic properties of the symbols, structures, and inferences that they manipulate. But we are now seeing an increasing need for the ability to reason over representational systems, rather than just working within them. A prerequisite of performing such reasoning is the ability to evaluate and compare representational objects (and to know the difference between them). We survey the criteria that are used for such evaluations in AI, machine learning, and other AI-related fields. To aid our survey, we introduce a formalism of representations, representational systems, and representational spaces that lends itself nicely to an analysis of the criteria typically used for evaluating them. © 2017, Springer Science+Business Media B.V., part of Springer Nature.",Artificial Intelligence Review,10.1007/s10462-017-9598-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037661853&doi=10.1007%2fs10462-017-9598-7&partnerID=40&md5=65fe7e56115110773c6f7d3c0abdcd7f,2019,7/20/21 15:49,7/20/21 15:49,657
GUQ353EH,journalArticle,2017,"Olier, J.S.; Barakova, E.; Regazzoni, C.; Rauterberg, M.",Re-framing the characteristics of concepts and their relation to learning and cognition in artificial agents,1,survey,,"In this work, the problems of knowledge acquisition and information processing are explored in relation to the definitions of concepts and conceptual processing, and their implications for artificial agents. The discussion focuses on views of cognition as a dynamic property in which the world is actively represented in grounded mental states which only have meaning in the action context. Reasoning is understood as an emerging property consequence of actions-environment couplings achieved through experience, and concepts as situated and dynamic phenomena enabling behaviours. Re-framing the characteristics of concepts is considered crucial to overcoming settled beliefs and reinterpreting new understandings in artificial systems. The first part presents a review of concepts from cognitive sciences. Support is found for views on grounded and embodied cognition, describing concepts as dynamic, flexible, context-dependent, and distributedly coded. That is argued to contrast with many technical implementations assuming concepts as categories, whilst explains limitations when grounding amodal symbols, or in unifying learning, perception and reasoning. The characteristics of concepts are linked to methods of active inference, self-organization, and deep learning to address challenges posed and to reinterpret emerging techniques. In a second part, an architecture based on deep generative models is presented to illustrate arguments elaborated. It is evaluated in a navigation task, showing that sufficient representations are created regarding situated behaviours with no semantics imposed on data. Moreover, adequate behaviours are achieved through a dynamic integration of perception and action in a single representational domain and process. © 2017 Elsevier B.V.",Cognitive Systems Research,10.1016/j.cogsys.2017.03.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017450328&doi=10.1016%2fj.cogsys.2017.03.005&partnerID=40&md5=0fece0df38c76170cacc3d42c6b6dc74,2017,7/20/21 15:49,7/20/21 15:49,665
EX5ZGV3N,journalArticle,2021,"Manhaeve, R.; Dumančić, S.; Kimmig, A.; Demeester, T.; De Raedt, L.",Neural probabilistic logic programming in DeepProbLog,1,,UNK,"We introduce DeepProbLog, a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques of the underlying probabilistic logic programming language ProbLog can be adapted for the new language. We theoretically and experimentally demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples. © 2021 Elsevier B.V.",Artificial Intelligence,10.1016/j.artint.2021.103504,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104453726&doi=10.1016%2fj.artint.2021.103504&partnerID=40&md5=9b46926a1251f8176c535e6027367e8f,2021,7/20/21 15:48,7/20/21 15:48,3
YCQKU49S,journalArticle,2018,"Harder, F.; Besold, T.R.",Learning Łukasiewicz logic,1,,UNK,"The integration between connectionist learning and logic-based reasoning is a longstanding foundational question in artificial intelligence, cognitive systems, and computer science in general. Research into neural-symbolic integration aims to tackle this challenge, developing approaches bridging the gap between sub-symbolic and symbolic representation and computation. In this line of work the core method has been suggested as a way of translating logic programs into a multilayer perceptron computing least models of the programs. In particular, a variant of the core method for three valued Łukasiewicz logic has proven to be applicable to cognitive modelling among others in the context of Byrne's suppression task. Building on the underlying formal results and the corresponding computational framework, the present article provides a modified core method suitable for the supervised learning of Łukasiewicz logic (and of a closely-related variant thereof), implements and executes the corresponding supervised learning with the backpropagation algorithm and, finally, constructs a rule extraction method in order to close the neural-symbolic cycle. The resulting system is then evaluated in several empirical test cases, and recommendations for future developments are derived. © 2017 Elsevier B.V.",Cognitive Systems Research,10.1016/j.cogsys.2017.07.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044158917&doi=10.1016%2fj.cogsys.2017.07.004&partnerID=40&md5=7eddcddf7db6d6df3f12c65d94e10e9f,2018,7/20/21 15:48,7/20/21 15:48,4
NPTPCDHQ,journalArticle,2018,"Tran, S.N.; D'Avila Garcez, A.S.",Deep Logic Networks: Inserting and Extracting Knowledge from Deep Belief Networks,1,,UNK,"Developments in deep learning have seen the use of layerwise unsupervised learning combined with supervised learning for fine-tuning. With this layerwise approach, a deep network can be seen as a more modular system that lends itself well to learning representations. In this paper, we investigate whether such modularity can be useful to the insertion of background knowledge into deep networks, whether it can improve learning performance when it is available, and to the extraction of knowledge from trained deep networks, and whether it can offer a better understanding of the representations learned by such networks. To this end, we use a simple symbolic language - a set of logical rules that we call confidence rules - and show that it is suitable for the representation of quantitative reasoning in deep networks. We show by knowledge extraction that confidence rules can offer a low-cost representation for layerwise networks (or restricted Boltzmann machines). We also show that layerwise extraction can produce an improvement in the accuracy of deep belief networks. Furthermore, the proposed symbolic characterization of deep networks provides a novel method for the insertion of prior knowledge and training of deep networks. With the use of this method, a deep neural-symbolic system is proposed and evaluated, with the experimental results indicating that modularity through the use of confidence rules and knowledge insertion can be beneficial to network performance. © 2012 IEEE.",IEEE Transactions on Neural Networks and Learning Systems,10.1109/TNNLS.2016.2603784,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995403891&doi=10.1109%2fTNNLS.2016.2603784&partnerID=40&md5=d7e818ffd09540742abbfab902658516,2018,7/20/21 15:48,7/20/21 15:48,5
5FLUBV5A,journalArticle,2021,"Roychowdhury, S.; Diligenti, M.; Gori, M.",Regularizing deep networks with prior knowledge: A constraint-based approach[Formula presented],1,,img,"Deep Learning architectures can develop feature representations and classification models in an integrated way during training. This joint learning process requires large networks with many parameters, and it is successful when a large amount of training data is available. Instead of making the learner develop its entire understanding of the world from scratch from the input examples, the injection of prior knowledge into the learner seems to be a principled way to reduce the amount of require training data, as the learner does not need to induce the rules from the data. This paper presents a general framework to integrate arbitrary prior knowledge into learning. The domain knowledge is provided as a collection of first-order logic (FOL) clauses, where each task to be learned corresponds to a predicate in the knowledge base. The logic statements are translated into a set of differentiable constraints, which can be integrated into the learning process to distill the knowledge into the network, or used during inference to enforce the consistency of the predictions with the prior knowledge. The experimental results have been carried out on multiple image datasets and show that the integration of the prior knowledge boosts the accuracy of several state-of-the-art deep architectures on image classification tasks. © 2021 The Authors",Knowledge-Based Systems,10.1016/j.knosys.2021.106989,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104105457&doi=10.1016%2fj.knosys.2021.106989&partnerID=40&md5=80144cf33992912376acc23e9716d914,2021,7/20/21 15:48,7/20/21 15:48,8
QTYPBWY7,journalArticle,2014,"França, M.V.M.; Zaverucha, G.; D'Avila Garcez, A.S.",Fast relational learning using bottom clause propositionalization with artificial neural networks,1,,UNK,"Relational learning can be described as the task of learning first-order logic rules from examples. It has enabled a number of new machine learning applications, e.g. graph mining and link analysis. Inductive Logic Programming (ILP) performs relational learning either directly by manipulating first-order rules or through propositionalization, which translates the relational task into an attribute-value learning task by representing subsets of relations as features. In this paper, we introduce a fast method and system for relational learning based on a novel propositionalization called Bottom Clause Propositionalization (BCP). Bottom clauses are boundaries in the hypothesis search space used by ILP systems Progol and Aleph. Bottom clauses carry semantic meaning and can be mapped directly onto numerical vectors, simplifying the feature extraction process. We have integrated BCP with a well-known neural-symbolic system, C-IL2P, to perform learning from numerical vectors. C-IL2P uses background knowledge in the form of propositional logic programs to build a neural network. The integrated system, which we call CILP++, handles first-order logic knowledge and is available for download from Sourceforge. We have evaluated CILP++ on seven ILP datasets, comparing results with Aleph and a well-known propositionalization method, RSD. The results show that CILP++ can achieve accuracy comparable to Aleph, while being generally faster, BCP achieved statistically significant improvement in accuracy in comparison with RSD when running with a neural network, but BCP and RSD perform similarly when running with C4.5. We have also extended CILP++ to include a statistical feature selection method, mRMR, with preliminary results indicating that a reduction of more than 90 % of features can be achieved with a small loss of accuracy. © 2013 The Author(s).",Machine Learning,10.1007/s10994-013-5392-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891373440&doi=10.1007%2fs10994-013-5392-1&partnerID=40&md5=8731ad71554ee4a0916f866be773a0d9,2014,7/20/21 15:48,7/20/21 15:48,9
K8KF6UMX,journalArticle,2018,"Sreelekha, S.",NeuroSymbolic integration with uncertainty,1,,UNK,"Most of the tasks which require intelligent behavior have some degree of uncertainty associated with them. The occurrence of uncertainty might be because of several reasons such as the incomplete domain knowledge, unreliable or ambiguous data due to measurement errors, inconsistent data representation. Most of the knowledge-based systems require the incorporation of some form of uncertainty management, in order to handle this kind of indeterminacy present in the system. In this paper, we present one such method to handle the uncertainty in neurules, a neuro-symbolic integration concept. Neuro-Computing is used within the symbolic frame work for improving the performance of symbolic rules. The uncertainty, the personal belief degree that an uncertain event may occur is managed by computing the composite belief values of incomplete or conflicting data. With the implementation of uncertainty management in neurules, the accuracy of the inference mechanism and the generalization performance can be improved. © 2018, Springer Nature Switzerland AG.",Annals of Mathematics and Artificial Intelligence,10.1007/s10472-018-9605-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056089637&doi=10.1007%2fs10472-018-9605-y&partnerID=40&md5=7b536c76a9f545463667915525d71135,2018,7/20/21 15:48,7/20/21 15:48,12
FVUVUB3N,journalArticle,2019,"Alirezaie, M.; Längkvist, M.; Sioutis, M.; Loutfi, A.",Semantic referee: A neural-symbolic framework for enhancing geospatial semantic segmentation,1,,img,"Understanding why machine learning algorithms may fail is usually the task of the human expert that uses domain knowledge and contextual information to discover systematic shortcomings in either the data or the algorithm. In this paper, we propose a semantic referee, which is able to extract qualitative features of the errors emerging from deep machine learning frameworks and suggest corrections. The semantic referee relies on ontological reasoning about spatial knowledge in order to characterize errors in terms of their spatial relations with the environment. Using semantics, the reasoner interacts with the learning algorithm as a supervisor. In this paper, the proposed method of the interaction between a neural network classifier and a semantic referee shows how to improve the performance of semantic segmentation for satellite imagery data. © 2019 - IOS Press and the authors. All rights reserved.",Semantic Web,10.3233/SW-180362,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072400163&doi=10.3233%2fSW-180362&partnerID=40&md5=0c0a71f7e614556f6e265a952bc2be44,2019,7/20/21 15:48,7/20/21 15:48,13
B6HMY5VN,journalArticle,2020,"Hohenecker, P.; Lukasiewicz, T.",Ontology reasoning with deep neural networks,1,,UNK,"The ability to conduct logical reasoning is a fundamental aspect of intelligent human behavior, and thus an important problem along the way to human-level artificial intelligence. Traditionally, logic-based symbolic methods from the field of knowledge representation and reasoning have been used to equip agents with capabilities that resemble human logical reasoning qualities. More recently, however, there has been an increasing interest in using machine learning rather than logic-based symbolic formalisms to tackle these tasks. In this paper, we employ state-of-the-art methods for training deep neural networks to devise a novel model that is able to learn how to effectively perform logical reasoning in the form of basic ontology reasoning. This is an important and at the same time very natural logical reasoning task, which is why the presented approach is applicable to a plethora of important real-world problems. We present the outcomes of several experiments, which show that our model is able to learn to perform highly accurate ontology reasoning on very large, diverse, and challenging benchmarks. Furthermore, it turned out that the suggested approach suffers much less from different obstacles that prohibit logic-based symbolic reasoning, and, at the same time, is surprisingly plausible from a biological point of view. © 2020 AI Access Foundation. All rights reserved.",Journal of Artificial Intelligence Research,10.1613/JAIR.1.11661,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091394619&doi=10.1613%2fJAIR.1.11661&partnerID=40&md5=f2c4fe69dd532c4c3c1697020bd217c3,2020,7/20/21 15:48,7/20/21 15:48,18
HMMJSAAE,journalArticle,2017,"Besold, T.R.; Garcez, A.A.; Stenning, K.; van der Torre, L.; van Lambalgen, M.",Reasoning in Non-probabilistic Uncertainty: Logic Programming and Neural-Symbolic Computing as Examples,1,,UNK,"This article aims to achieve two goals: to show that probability is not the only way of dealing with uncertainty (and even more, that there are kinds of uncertainty which are for principled reasons not addressable with probabilistic means); and to provide evidence that logic-based methods can well support reasoning with uncertainty. For the latter claim, two paradigmatic examples are presented: logic programming with Kleene semantics for modelling reasoning from information in a discourse, to an interpretation of the state of affairs of the intended model, and a neural-symbolic implementation of input/output logic for dealing with uncertainty in dynamic normative contexts. © 2017, Springer Science+Business Media Dordrecht.",Minds and Machines,10.1007/s11023-017-9428-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014652011&doi=10.1007%2fs11023-017-9428-3&partnerID=40&md5=7fc0aac7a6a945f1f9ab9c4c5b9a43a1,2017,7/20/21 15:48,7/20/21 15:48,19
W25MFCK4,journalArticle,2020,"Cohen, W.W.; Yang, F.; Mazaitis, K.R.",TensorLog: A probabilistic database implemented using deep-learning infrastructure,1,,UNK,"We present an implementation of a probabilistic first-order logic called TensorLog, in which classes of logical queries are compiled into differentiable functions in a neural-network infrastructure such as Tensorflow or Theano. This leads to a close integration of probabilistic logical reasoning with deep-learning infrastructure: in particular, it enables high-performance deep learning frameworks to be used for tuning the parameters of a probabilistic logic. The integration with these frameworks enables use of GPU-based parallel processors for inference and learning, making TensorLog the first highly parallellizable probabilistic logic. Experimental results show that TensorLog scales to problems involving hundreds of thousands of knowledge-base triples and tens of thousands of examples. © 2020 AI Access Foundation. All rights reserved.",Journal of Artificial Intelligence Research,10.1613/JAIR.1.11944,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094400673&doi=10.1613%2fJAIR.1.11944&partnerID=40&md5=f90034ac321d4c9e6dbeef4b20363d5e,2020,7/20/21 15:48,7/20/21 15:48,26
JGU2SECC,journalArticle,2020,"Jiang, J.; Wang, H.; Xie, J.; Guo, X.; Guan, Y.; Yu, Q.",Medical knowledge embedding based on recursive neural network for multi-disease diagnosis,1,,HER,"The representation of knowledge based on first-order logic captures the richness of natural language and supports multiple probabilistic inference models. Although symbolic representation enables quantitative reasoning with statistical probability, it is difficult to utilize with machine learning models as they perform numerical operations. In contrast, knowledge embedding (i.e., high-dimensional and continuous vectors) is a feasible approach to complex reasoning that can not only retain the semantic information of knowledge, but also establish the quantifiable relationship among embeddings. In this paper, we propose a recursive neural knowledge network (RNKN), which combines medical knowledge based on first-order logic with a recursive neural network for multi-disease diagnosis. After the RNKN is efficiently trained using manually annotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented knowledge embeddings and weight matrixes are learned. The experimental results confirm that the diagnostic accuracy of the RNKN is superior to those of four machine learning models, four classical neural networks and Markov logic network. The results also demonstrate that the more explicit the evidence extracted from CEMRs, the better the performance. The RNKN gradually reveals the interpretation of knowledge embeddings as the number of training epochs increases. © 2019 Elsevier B.V.",Artificial Intelligence in Medicine,10.1016/j.artmed.2019.101772,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078077985&doi=10.1016%2fj.artmed.2019.101772&partnerID=40&md5=3483a63fb7430aa96a98811d66247886,2020,7/20/21 15:48,7/20/21 15:48,30
7MMJY5BM,journalArticle,2019,"Schon, C.; Siebert, S.; Stolzenburg, F.",The CoRg Project: Cognitive Reasoning,1,,UNK,"The term cognitive computing refers to new hardware and/or software that mimics the functioning of the human brain. In the context of question answering and commonsense reasoning this means that the reasoning process of humans shall be modeled by adequate technical means. However, since humans do not follow the rules of classical logic, a system designed to model these abilities must be very versatile. The aim of the CoRg project (Cognitive Reasoning) is to successfully complete a reasoning task with commonsense reasoning. We address different benchmarks with focus on the COPA benchmark set (Choice of Plausible Alternatives). Since humans naturally use background knowledge, we have to deal with large background knowledge bases and must be able to reason with multiple input formats and sources in the CoRg system, in order to draw explainable conclusions. For this, we have to find appropriate logics for cognitive reasoning. For a successful reasoning system, nowadays it seems to be important to combine automated reasoning with machine learning technology like recurrent neural networks. © 2019, Gesellschaft für Informatik e.V. and Springer-Verlag GmbH Germany, part of Springer Nature.",KI - Kunstliche Intelligenz,10.1007/s13218-019-00601-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077011935&doi=10.1007%2fs13218-019-00601-5&partnerID=40&md5=e6edfc5075a223b3bbc5a5cbd192fc8c,2019,7/20/21 15:48,7/20/21 15:48,32
XNAC7N7B,journalArticle,2015,"Prentzas, J.; Hatzilygeroudis, I.",Improving efficiency of merging symbolic rules into integrated rules: Splitting methods and mergability criteria,1,,UNK,"Neurules are a type of neuro-symbolic rules integrating neurocomputing and production rules. Each neurule is represented as an adaline unit. Neurules exhibit characteristics such as modularity, naturalness and ability to perform interactive and integrated inferences and provide explanations for reached conclusions. One way of producing a neurule base is through conversion of an existing symbolic rule base yielding an equivalent but more compact rule base. The conversion process merges symbolic rules having the same conclusion into one or more neurules. Because of the inability of the adaline unit to handle inseparability, more than one neurule for each conclusion may be produced by splitting the initial set of symbolic rules into subsets. This paper presents research work improving the conversion process in terms of runtime and number of produced neurules. First, we show how easier it is to construct a neurule base than a connectionist one. Second, we present alternative rule set splitting methods. Finally, we define criteria concerning the ability or inability to convert a rule set into a single, equivalent, but more compact rule. With application of such mergability criteria, the conversion process of symbolic rules into neurules becomes more time-efficient. All the aforementioned are supported by experimental results. © 2014 Wiley Publishing Ltd.",Expert Systems,10.1111/exsy.12085,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027944661&doi=10.1111%2fexsy.12085&partnerID=40&md5=10da2576c3e51fe14d9ac29863fd7f84,2015,7/20/21 15:48,7/20/21 15:48,33
676S4D2D,journalArticle,2015,"Furbach, U.; Schon, C.; Stolzenburg, F.; Weis, K.-H.; Wirth, C.-P.",The RatioLog Project: Rational Extensions of Logical Reasoning,1,,text,"Higher-level cognition includes logical reasoning and the ability of question answering with common sense. The RatioLog project addresses the problem of rational reasoning in deep question answering by methods from automated deduction and cognitive computing. In a first phase, we combine techniques from information retrieval and machine learning to find appropriate answer candidates from the huge amount of text in the German version of the free encyclopedia “Wikipedia”. In a second phase, an automated theorem prover tries to verify the answer candidates on the basis of their logical representations. In a third phase—because the knowledge may be incomplete and inconsistent—we consider extensions of logical reasoning to improve the results. In this context, we work toward the application of techniques from human reasoning: We employ defeasible reasoning to compare the answers w.r.t. specificity, deontic logic, normative reasoning, and model construction. Moreover, we use integrated case-based reasoning and machine learning techniques on the basis of the semantic structure of the questions and answer candidates to learn giving the right answers. © 2015, Springer-Verlag Berlin Heidelberg.",KI - Kunstliche Intelligenz,10.1007/s13218-015-0377-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072861875&doi=10.1007%2fs13218-015-0377-9&partnerID=40&md5=c5095ffbeeaf0de5e98788136f7cf0d4,2015,7/20/21 15:48,7/20/21 15:48,36
8Y85NX6C,journalArticle,2015,"Hatzilygeroudis, I.; Prentzas, J.",Symbolic-neural rule based reasoning and explanation,1,,UNK,"In this paper, we present neurule-based inference and explanation mechanisms. A neurule is a kind of integrated rule, which integrates a symbolic rule with neurocomputing: each neurule is considered as an adaline neural unit. Thus, a neurule base consists of a number of autonomous adaline units (neurules), expressed in a symbolic oriented syntax. There are two inference processes for neurules: the connectionism-oriented process, which gives pre-eminence to neurocomputing approach, and the symbolism-oriented process, which gives pre-eminence to a symbolic backwards chaining like approach. Symbolism-oriented process is proved to be more efficient than the connectionism-oriented one, in terms of the number of required computations (56.47-63.88% average reduction) and the mean runtime gain (59.95-64.89% in average), although both require almost the same average number of input values. The neurule-based explanation mechanism provides three types of explanations: 'how' a conclusion was derived, 'why' a value for a specific input variable was asked from the user and 'why-not' a variable has acquired a specific value. As shown by experiments, the neurule-based explanation mechanism is superior to that provided by known connectionist expert systems, another neuro-symbolic integration category. It provides less in number (64.38-69.28% average reduction) and more natural explanation rules, thus increasing efficiency (mean runtime gain of 56.65-56.73% in average) and comprehensibility of explanations. © 2015 Elsevier Ltd. All rights reserved.",Expert Systems with Applications,10.1016/j.eswa.2015.01.068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923385886&doi=10.1016%2fj.eswa.2015.01.068&partnerID=40&md5=9ceb876cdd0c89753752e164b442c9a4,2015,7/20/21 15:48,7/20/21 15:48,37
NB39QA35,journalArticle,2018,"Yao, Y.; Xu, J.; Shi, J.; Xu, B.",Learning to activate logic rules for textual reasoning,1,,text,"Most current textual reasoning models cannotlearn human-like reasoning process, and thus lack interpretability and logical accuracy. To help address this issue, we propose a novel reasoning model which learns to activate logic rules explicitly via deep reinforcement learning. It takes the form of Memory Networks but features a special memory that stores relational tuples, mimicking the “Image Schema” in human cognitive activities. We redefine textual reasoning as a sequential decision-making process modifying or retrieving from the memory, where logic rules serve as state-transition functions. Activating logic rules for reasoning involves two problems: variable binding and relation activating, and this is a first step to solve them jointly. Our model achieves an average error rate of 0.7% on bAbI-20, a widely-used synthetic reasoning benchmark, using less than 1k training samples and no supporting facts. © 2018 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2018.06.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049856582&doi=10.1016%2fj.neunet.2018.06.012&partnerID=40&md5=47e0384962823cd19727841570859356,2018,7/20/21 15:48,7/20/21 15:48,42
8MT47N5Y,journalArticle,2021,"Mehri, R.; Haarslev, V.; Chinaei, H.",A machine learning approach for optimizing heuristic decision-making in Web Ontology Language reasoners,1,,UNK,"Description logics (DLs) are formalisms for representing knowledge bases of application domains. The Web Ontology Language (OWL) is a syntactic variant of a very expressive DL. OWL reasoners can infer implied information from OWL ontologies. The performance of OWL reasoners can be severely affected by situations that require decision-making over many alternatives. Such a nondeterministic behavior is often controlled by heuristics that are based on insufficient information. This article proposes a novel OWL reasoning approach that applies machine learning (ML) to implement pragmatic and optimal decision-making strategies in such situations. Disjunctions occurring in ontologies are one source of nondeterministic actions in reasoners. We propose two ML-based approaches to reduce the nondeterminism caused by dealing with disjunctions. The first approach is restricted to propositional DL while the second one can deal with standard DL. Both approaches speed up our ML-based reasoner by up to two orders of magnitude in comparison to the non-ML reasoner. Another source of nondeterministic actions is the order in which tableau rules should be applied. On average, our ML-based approach achieves a speedup of two orders of magnitude when compared to the most expensive rule ordering of the non-ML reasoner. © 2020 Wiley Periodicals LLC.",Computational Intelligence,10.1111/coin.12404,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092509786&doi=10.1111%2fcoin.12404&partnerID=40&md5=34ce5e4b928e3f69c439db0695d9c946,2021,7/20/21 15:48,7/20/21 15:48,44
2N43RWSY,journalArticle,2019,"Li, J.; Zhang, G.; Yu, L.; Meng, T.",Research and Design on Cognitive Computing Framework for Predicting Judicial Decisions,1,,UNK,"This paper aims to provide a cognitive computing framework to meet the challenges of semantic understanding, knowledge learning and judicial reasoning in the Chinese legal domain. In our framework, legal factors are first represented in a formal way; secondly, legal factors are extracted, and concepts and their relations are augmented with a combination of rule-based and deep learning methods; thirdly, a predication model is generated and trained to make judicial decisions. When a fact description is brought into the model, the probability of judicial decisions will be given automatically. Two elementary results are obtained: I. Our method can effectively predict the decisions for divorce cases with different expression styles, and offers better performance than traditional methods like Support Vector Machine (SVM); II. Our machine learning predicting results can be easily understood by general public as applied induction rules are given. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.",Journal of Signal Processing Systems,10.1007/s11265-018-1429-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058237823&doi=10.1007%2fs11265-018-1429-9&partnerID=40&md5=2fa5e5285532e9674e4183edf208ab06,2019,7/20/21 15:48,7/20/21 15:48,49
JN4IZETG,journalArticle,2021,"Škrlj, B.; Martinc, M.; Lavrač, N.; Pollak, S.",autoBOT: evolving neuro-symbolic representations for explainable low resource text classification,1,,text,"Learning from texts has been widely adopted throughout industry and science. While state-of-the-art neural language models have shown very promising results for text classification, they are expensive to (pre-)train, require large amounts of data and tuning of hundreds of millions or more parameters. This paper explores how automatically evolved text representations can serve as a basis for explainable, low-resource branch of models with competitive performance that are subject to automated hyperparameter tuning. We present autoBOT (automatic Bags-Of-Tokens), an autoML approach suitable for low resource learning scenarios, where both the hardware and the amount of data required for training are limited. The proposed approach consists of an evolutionary algorithm that jointly optimizes various sparse representations of a given text (including word, subword, POS tag, keyword-based, knowledge graph-based and relational features) and two types of document embeddings (non-sparse representations). The key idea of autoBOT is that, instead of evolving at the learner level, evolution is conducted at the representation level. The proposed method offers competitive classification performance on fourteen real-world classification tasks when compared against a competitive autoML approach that evolves ensemble models, as well as state-of-the-art neural language models such as BERT and RoBERTa. Moreover, the approach is explainable, as the importance of the parts of the input space is part of the final solution yielded by the proposed optimization procedure, offering potential for meta-transfer learning. © 2021, The Author(s).",Machine Learning,10.1007/s10994-021-05968-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104608374&doi=10.1007%2fs10994-021-05968-x&partnerID=40&md5=59b5fd0f7b23614c0337e650f6050d25,2021,7/20/21 15:48,7/20/21 15:48,54
94Q97J7C,journalArticle,2021,"Piantadosi, S.T.",The Computational Origin of Representation,1,,UNK,"Each of our theories of mental representation provides some insight into how the mind works. However, these insights often seem incompatible, as the debates between symbolic, dynamical, emergentist, sub-symbolic, and grounded approaches to cognition attest. Mental representations—whatever they are—must share many features with each of our theories of representation, and yet there are few hypotheses about how a synthesis could be possible. Here, I develop a theory of the underpinnings of symbolic cognition that shows how sub-symbolic dynamics may give rise to higher-level cognitive representations of structures, systems of knowledge, and algorithmic processes. This theory implements a version of conceptual role semantics by positing an internal universal representation language in which learners may create mental models to capture dynamics they observe in the world. The theory formalizes one account of how truly novel conceptual content may arise, allowing us to explain how even elementary logical and computational operations may be learned from a more primitive basis. I provide an implementation that learns to represent a variety of structures, including logic, number, kinship trees, regular languages, context-free languages, domains of theories like magnetism, dominance hierarchies, list structures, quantification, and computational primitives like repetition, reversal, and recursion. This account is based on simple discrete dynamical processes that could be implemented in a variety of different physical or biological systems. In particular, I describe how the required dynamics can be directly implemented in a connectionist framework. The resulting theory provides an “assembly language” for cognition, where high-level theories of symbolic computation can be implemented in simple dynamics that themselves could be encoded in biologically plausible systems. © 2020, Springer Nature B.V.",Minds and Machines,10.1007/s11023-020-09540-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094971194&doi=10.1007%2fs11023-020-09540-9&partnerID=40&md5=acf104d268f0f57433dcf2ae3a9ee58b,2021,7/20/21 15:48,7/20/21 15:48,64
6Z9JP7A2,journalArticle,2016,"Hao, W.; Yeung, D.-Y.",Towards Bayesian Deep Learning: A Framework and Some Existing Methods,1,,text,"While perception tasks such as visual object recognition and text understanding play an important role in human intelligence, subsequent tasks that involve inference, reasoning, and planning require an even higher level of intelligence. The past few years have seen major advances in many perception tasks using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. To achieve integrated intelligence that involves both perception and inference, it is naturally desirable to tightly integrate deep learning and Bayesian models within a principled probabilistic framework, which we call Bayesian deep learning. In this unified framework, the perception of text or images using deep learning can boost the performance of higher-level inference and in return, the feedback from the inference process is able to enhance the perception of text or images. This paper proposes a general framework for Bayesian deep learning and reviews its recent applications on recommender systems, topic models, and control. In this paper, we also discuss the relationship and differences between Bayesian deep learning and other related topics such as the Bayesian treatment of neural networks. © 1989-2012 IEEE.",IEEE Transactions on Knowledge and Data Engineering,10.1109/TKDE.2016.2606428,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027053369&doi=10.1109%2fTKDE.2016.2606428&partnerID=40&md5=2298795d82efbe8c50a7599aad18c609,2016,7/20/21 15:48,7/20/21 15:48,73
W9ZTSUJL,journalArticle,2021,"Racharak, T.",On Approximation of Concept Similarity Measure in Description Logic ELH with Pre-Trained Word Embedding,1,,text,"Data-driven and knowledge-driven methods are two mainstream techniques in the pursuit of developing artificial intelligence systems. While data-driven methods seek to develop a decision model from observations in the real world, they are difficult to provide an explanation for the results in human terms. On the other hand, knowledge-driven methods that employ symbolic reasoning based on formal semantics of a knowledge-base are thus more interpretable and explainable, while lacking an ability to deal with incomplete modeling of the structured knowledge-bases. This work aims to tackle these issues on ontology similarity by proposing a general framework that combines the strengths of both approaches for measuring semantic similarity of concepts in a description logic (DL) ontology. More specifically, a neuro-symbolic integrated framework is defined to exploit the pre-trained word embeddings with semantic definitions in an ontology to yield an explainable degree of concept similarity. To demonstrate its applicability, we develop a concrete similarity measure sf sim_ϵ conforming to the proposed framework and also introduce an efficient algorithm that can extract an explanation for why such a degree is indicated. The correctness is shown by analyzing theoretical properties that it guarantees to preserve and also by performing an empirical evaluation with a medical ontology SNOMED CT and a medical pre-trained embedding BioWordVec. The results show that our proposed method remains both interpretability and explainability while achieving comparable performance, relative to the state-of-the-art approaches in the data and knowledge-driven methods. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2021.3073730,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104631138&doi=10.1109%2fACCESS.2021.3073730&partnerID=40&md5=529c9a386b7a809ea18740d154d07878,2021,7/20/21 15:48,7/20/21 15:48,76
5EEQ5ZAD,journalArticle,2011,"Chapin, N.; Szymanski, B.; Bringsjord, S.; Schimanski, B.",A bottom-up complement to the logic-based top-down approach to the story arrangement test,1,,UNK,"Psychometric AI is a type of AI distinguished by the pursuit of intelligent systems able to excel on psychometrically validated human-level tests of cognitive abilities. We seek to build a system that solves a specific sub-test within Psychometric AI: the story arrangment test. Items in this test confront the test-taker with a set of jumbed snapshots (whether diagrammatic or otherwise) which must be ordered to tell a coherent story. We propose a dual-process system that combines bottom-up non- or sub-symbolic processing (e.g. neural network-based modelling) with top-down symbolic processing (e.g. deductive reasoning over declarative information represented as formulae in a logical system) for solving these tests of cognitive ability. The top-down process provides the benefits of a traceable proof, but requires a large amount of pre-existing knowledge. The bottom-up technique sacrifices provability and certainty on some problems for speed, but always yields some level of an answer to a given problem. This demonstrates a natural marriage between the two: the bottom-up approach seems especially powerful when used as a form of pre-processing in conjunction with a logic-based approach, because the latter approach would only need to consider a small number of possible orderings of snapshots. © 2011 Taylor & Francis.",Journal of Experimental and Theoretical Artificial Intelligence,10.1080/0952813X.2010.502313,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960791745&doi=10.1080%2f0952813X.2010.502313&partnerID=40&md5=db04f10d1680508d046bf49ce7ee636b,2011,7/20/21 15:48,7/20/21 15:48,77
B47SSE6P,journalArticle,2019,"Chaturvedi, I.; Satapathy, R.; Cavallari, S.; Cambria, E.",Fuzzy commonsense reasoning for multimodal sentiment analysis,1,,multi modal,"The majority of user-generated content posted online is in the form of text, images and videos but also physiological signals in games. AffectiveSpace is a vector space of affective commonsense available for English text but not for other languages nor other modalities such as electrocardiogram signals. We overcome this limitation by using deep learning to extract features from each modality and then projecting them to a common AffectiveSpace that has been clustered into different emotions. Because, in the real world, individuals tend to have partial or mixed sentiments about an opinion target, we use a fuzzy logic classifier to predict the degree of a particular emotion in AffectiveSpace. The combined model of deep convolutional neural networks and fuzzy logic is termed Convolutional Fuzzy Sentiment Classifier. Lastly, because the computational complexity of a fuzzy classifier is exponential with respect to the number of features, we project features to a four dimensional emotion space in order to speed up the classification performance. © 2019",Pattern Recognition Letters,10.1016/j.patrec.2019.04.024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065463296&doi=10.1016%2fj.patrec.2019.04.024&partnerID=40&md5=e809ca1e1a16b6df5b2a4aa1287fff8d,2019,7/20/21 15:48,7/20/21 15:48,78
FQ78YXTY,journalArticle,2020,"Kelly, M.A.; Arora, N.; West, R.L.; Reitter, D.",Holographic Declarative Memory: Distributional Semantics as the Architecture of Memory,1,,UNK,"We demonstrate that the key components of cognitive architectures (declarative and procedural memory) and their key capabilities (learning, memory retrieval, probability judgment, and utility estimation) can be implemented as algebraic operations on vectors and tensors in a high-dimensional space using a distributional semantics model. High-dimensional vector spaces underlie the success of modern machine learning techniques based on deep learning. However, while neural networks have an impressive ability to process data to find patterns, they do not typically model high-level cognition, and it is often unclear how they work. Symbolic cognitive architectures can capture the complexities of high-level cognition and provide human-readable, explainable models, but scale poorly to naturalistic, non-symbolic, or big data. Vector-symbolic architectures, where symbols are represented as vectors, bridge the gap between the two approaches. We posit that cognitive architectures, if implemented in a vector-space model, represent a useful, explanatory model of the internal representations of otherwise opaque neural architectures. Our proposed model, Holographic Declarative Memory (HDM), is a vector-space model based on distributional semantics. HDM accounts for primacy and recency effects in free recall, the fan effect in recognition, probability judgments, and human performance on an iterated decision task. HDM provides a flexible, scalable alternative to symbolic cognitive architectures at a level of description that bridges symbolic, quantum, and neural models of cognition. © 2020 Cognitive Science Society, Inc",Cognitive Science,10.1111/cogs.12904,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095401513&doi=10.1111%2fcogs.12904&partnerID=40&md5=fc6197e721487682e27359e97464b85e,2020,7/20/21 15:48,7/20/21 15:48,83
UHPX4UN3,journalArticle,2021,"Krishnamurthy, P.; Sarmadi, A.; Khorrami, F.",Explainable classification by learning human-readable sentences in feature subsets,1,,text,"We propose a new methodology (Sentences in Feature Subsets, i.e., SiFS) to mine human-readable decision rules from empirical data sets. Unlike opaque classifiers obtained using deep learning, the proposed methodology derives decision rules that are compact and comprised of Boolean logic sentences involving subsets of features in the input data. For this purpose, we develop a new classifier model defined in terms of sets of inequalities among selected features in the input data. To empirically derive suitable inequalities from training data, our approach combines a differentiable representation of sets of Boolean logic sentences, gradient-based optimization of coefficients in the inequalities, a genetic-based algorithm for selection of the subsets of features, and a “goodness” model of sentences to prune and down-select sentences. We present results on synthetic and real-world benchmark datasets to demonstrate efficacy of SiFS in deriving human-readable decision rules. It is seen that SiFS achieves comparable accuracies to the best among various other classification algorithms (accuracies of 95% to 100% on several datasets, F1 scores between 0.95 and 1.0), reasonable computation times (training times of a few seconds for considered datasets), and compact human-readable decision rules (between 1 to 10 sentences of 3 words or less for considered datasets). © 2021 Elsevier Inc.",Information Sciences,10.1016/j.ins.2021.02.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102427389&doi=10.1016%2fj.ins.2021.02.031&partnerID=40&md5=6cf9b1b59d37a1d0b5e7c3100f11a2df,2021,7/20/21 15:48,7/20/21 15:48,91
Z9LQSC4L,journalArticle,2011,"Leandro, C.; Pita, H.; Monteiro, L.",Symbolic knowledge extraction from trained neural networks governed by Łukasiewicz logics,1,,,"This work describes a methodology to extract symbolic rules from trained neural networks. In our approach, patterns on the network are codified using formulas on a Łukasiewicz logic. For this we take advantage of the fact that every connective in this multi-valued logic can be evaluated by a neuron in an artificial network having, by activation function the identity truncated to zero and one. This fact simplifies symbolic rule extraction and allows the easy injection of formulas into a network architecture. We trained this type of neural network using a back-propagation algorithm based on Levenderg-Marquardt algorithm, where in each learning iteration, we restricted the knowledge dissemination in the network structure. This makes the descriptive power of produced neural networks similar to the descriptive power of Łukasiewicz logic language, minimizing the information loss on the translation between connectionist and symbolic structures. To avoid redundance on the generated network, the method simplifies them in a pruning phase, using the ""Optimal Brain Surgeon"" algorithm. We tested this method on the task of finding the formula used on the generation of a given truth table. For real data tests, we selected the Mushrooms data set, available on the UCI Machine Learning Repository. © 2011 Springer-Verlag Berlin Heidelberg.",Studies in Computational Intelligence,10.1007/978-3-642-20206-3_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79954551066&doi=10.1007%2f978-3-642-20206-3_3&partnerID=40&md5=22f44da1c9521a754c2671153708e250,2011,7/20/21 15:48,7/20/21 15:48,93
BYLHAZZD,journalArticle,2018,"El Hatri, C.; Boumhidi, J.",Fuzzy deep learning based urban traffic incident detection,1,,traffic,"Traffic incident detection (TID) is an important part of any modern traffic control because it offers an opportunity to maximise road system performance. For the complexity and the nonlinear characteristics of traffic incidents, this paper proposes a novel fuzzy deep learning based TID method which considers the spatial and temporal correlations of traffic flow inherently. Parameters of the deep network are initialized using a Stacked Auto-Encoder (SAE) model following a layer by layer pre-training procedure. To conduct the fine tuning step, the back-propagation algorithm is used to precisely adjust the parameters in the deep network. Fuzzy logic is employed to control the learning parameters where the objective is to reduce the possibility of overshooting during the learning process, increase the convergence speed and minimize the error. To find the best architecture of the deep network, we used a separate validation set to evaluate different architectures generated randomly based on the Mean Squared Error (MSE). Simulation results show that the proposed incident detection method has many advantages such as higher detection rate and lower false alarm rate. © 2017",Cognitive Systems Research,10.1016/j.cogsys.2017.12.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038826829&doi=10.1016%2fj.cogsys.2017.12.002&partnerID=40&md5=a21ff71b4c8c6848764a73f5b17cdbe3,2018,7/20/21 15:48,7/20/21 15:48,94
P53Y4CWV,journalArticle,2021,"Dash, T.; Srinivasan, A.; Vig, L.",Incorporating symbolic domain knowledge into graph neural networks,1,,,"Our interest is in scientific problems with the following characteristics: (1) Data are naturally represented as graphs; (2) The amount of data available is typically small; and (3) There is significant domain-knowledge, usually expressed in some symbolic form (rules, taxonomies, constraints and the like). These kinds of problems have been addressed effectively in the past by symbolic machine learning methods like Inductive Logic Programming (ILP), by virtue of 2 important characteristics: (a) The use of a representation language that easily captures the relation encoded in graph-structured data, and (b) The inclusion of prior information encoded as domain-specific relations, that can alleviate problems of data scarcity, and construct new relations. Recent advances have seen the emergence of deep neural networks specifically developed for graph-structured data (Graph-based Neural Networks, or GNNs). While GNNs have been shown to be able to handle graph-structured data, less has been done to investigate the inclusion of domain-knowledge. Here we investigate this aspect of GNNs empirically by employing an operation we term vertex-enrichment and denote the corresponding GNNs as VEGNNs. Using over 70 real-world datasets and substantial amounts of symbolic domain-knowledge, we examine the result of vertex-enrichment across 5 different variants of GNNs. Our results provide support for the following: (a) Inclusion of domain-knowledge by vertex-enrichment can significantly improve the performance of a GNN. That is, the performance of VEGNNs is significantly better than GNNs across all GNN variants; (b) The inclusion of domain-specific relations constructed using ILP improves the performance of VEGNNs, across all GNN variants. Taken together, the results provide evidence that it is possible to incorporate symbolic domain knowledge into a GNN, and that ILP can play an important role in providing high-level relationships that are not easily discovered by a GNN. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.",Machine Learning,10.1007/s10994-021-05966-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107808586&doi=10.1007%2fs10994-021-05966-z&partnerID=40&md5=40a0ff763e0663db0dd1e1fcb59206ae,2021,7/20/21 15:48,7/20/21 15:48,97
8INQPZF7,journalArticle,2019,"Liu, J.; Zhang, X.; Li, Y.; Wang, J.; Kim, H.-J.",Deep learning-based reasoning with multi-ontology for IoT applications,1,,,"In the era of mobile big data, data driven intelligent Internet of Things (IoT) applications are becoming widespread, and knowledge-based reasoning is one of the essential tasks of these applications. While most knowledge-based reasoning work is conducted with knowledge graph, ontology-based reasoning method can inherently achieve higher level intelligence by leveraging both explicit and tacit knowledge in specific domains, and its performance is determined by precise refinement of the inference rules. However, most ontology-based reasoning work concentrates on semantic reasoning in a single ontology, and fail to utilize association of multiple ontologies in various domains to extend reasoning capacity. This is even the case for the IoT applications where knowledge from multiple domains needs to be utilized. To overcome this issue, we propose a deep learning-based method to associate multiple ontology rule bases, thereby discover new inference rules. In our method, we first use a regression tree model to determine the threshold value for parameters in inference rules that constitute the ontology rule base, avoiding the influence of uncertainty factors on knowledge reasoning results. Then, a two-way GRU (Gated Recurrent Unit) neural network with attention mechanism is used to discover semantic relations among the rule bases of ontologies. Therefore, the association of multiple ontology rule bases is realized, and the rule base of knowledge reasoning is expanded by acquiring some unspecified rules. To the best our knowledge, this work is the first one to leverage deep learning in reasoning with multiple ontologies. In order to verify the effectiveness of our method, we apply it in a real traffic safety monitoring application by relating rule bases of a vehicle ontology and a traffic management ontology, and achieve effective knowledge reasoning. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2019.2937353,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077961533&doi=10.1109%2fACCESS.2019.2937353&partnerID=40&md5=d7c3e6b475f82b548ca443a53ccda160,2019,7/20/21 15:48,7/20/21 15:48,111
7SGVPUQ2,journalArticle,2014,"Hu, H.; Pang, L.; Tian, D.; Shi, Z.",Perception granular computing in visual haze-free task,1,,,"In the past decade, granular computing (GrC) has been an active topic of research in machine learning and computer vision. However, the granularity division is itself an open and complex problem. Deep learning, at the same time, has been proposed by Geoffrey Hinton, which simulates the hierarchical structure of human brain, processes data from lower level to higher level and gradually composes more and more semantic concepts. The information similarity, proximity and functionality constitute the key points in the original insight of granular computing proposed by Zadeh. Many GrC researches are based on the equivalence relation or the more general tolerance relation, either of which can be described by some distance functions. The information similarity and proximity depended on the samples distribution can be easily described by the fuzzy logic. From this point of view, GrC can be considered as a set of fuzzy logical formulas, which is geometrically defined as a layered framework in a multi-scale granular system. The necessity of such kind multi-scale layered granular system can be supported by the columnar organization of the neocortex. So the granular system proposed in this paper can be viewed as a new explanation of deep learning that simulates the hierarchical structure of human brain. In view of this, a novel learning approach, which combines fuzzy logical designing with machine learning, is proposed in this paper to construct a GrC system to explore a novel direction for deep learning. Unlike those previous works on the theoretical framework of GrC, our granular system is abstracted from brain science and information science, so it can be used to guide the research of image processing and pattern recognition. Finally, we take the task of haze-free as an example to demonstrate that our multi-scale GrC has high ability to increase the texture information entropy and improve the effect of haze-removing. © 2013 Published by Elsevier Ltd. All rights reserved.",Expert Systems with Applications,10.1016/j.eswa.2013.11.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890486569&doi=10.1016%2fj.eswa.2013.11.006&partnerID=40&md5=e3854fae3c4745ee147d0e0b37d3c80d,2014,7/20/21 15:48,7/20/21 15:48,114
M3WPKU55,journalArticle,2021,"Kawamoto, Y.",An epistemic approach to the formal specification of statistical machine learning,1,,,"We propose an epistemic approach to formalizing statistical properties of machine learning. Specifically, we introduce a formal model for supervised learning based on a Kripke model where each possible world corresponds to a possible dataset and modal operators are interpreted as transformation and testing on datasets. Then, we formalize various notions of the classification performance, robustness, and fairness of statistical classifiers by using our extension of statistical epistemic logic. In this formalization, we show relationships among properties of classifiers, and relevance between classification performance and robustness. As far as we know, this is the first work that uses epistemic models and logical formulas to express statistical properties of machine learning, and would be a starting point to develop theories of formal specification of machine learning. © 2020, The Author(s).",Software and Systems Modeling,10.1007/s10270-020-00825-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091169688&doi=10.1007%2fs10270-020-00825-2&partnerID=40&md5=fa16e2583e0096f1d86113915526b1b2,2021,7/20/21 15:48,7/20/21 15:48,118
YBUAUWEY,journalArticle,2019,"Muggleton, S.H.; Hocquette, C.",Machine Discovery of Comprehensible Strategies for Simple Games Using Meta-interpretive Learning,1,,,"Recently, world-class human players have been outperformed in a number of complex two-person games (Go, Chess, Checkers) by Deep Reinforcement Learning systems. However, the data efficiency of the learning systems is unclear given that they appear to require far more training games to achieve such performance than any human player might experience in a lifetime. In addition, the resulting learned strategies are not in a form which can be communicated to human players. This contrasts to earlier research in Behavioural Cloning in which single-agent skills were machine learned in a symbolic language, facilitating their being taught to human beings. In this paper, we consider Machine Discovery of human-comprehensible strategies for simple two-person games (Noughts-and-Crosses and Hexapawn). One advantage of considering simple games is that there is a tractable approach to calculating minimax regret. We use these games to compare Cumulative Minimax Regret for variants of both standard and deep reinforcement learning against two variants of a new Meta-interpretive Learning system called MIGO. In our experiments, tested variants of both normal and deep reinforcement learning have consistently worse performance (higher cumulative minimax regret) than both variants of MIGO on Noughts-and-Crosses and Hexapawn. In addition, MIGO’s learned rules are relatively easy to comprehend, and are demonstrated to achieve significant transfer learning in both directions between Noughts-and-Crosses and Hexapawn. © 2019, The Author(s).",New Generation Computing,10.1007/s00354-019-00054-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065030104&doi=10.1007%2fs00354-019-00054-2&partnerID=40&md5=d40c517598f829ac81d0bf29d641f7f0,2019,7/20/21 15:48,7/20/21 15:48,121
M3TG8SKF,journalArticle,2018,"Lima, R.; Espinasse, B.; Freitas, F.",OntoILPER: an ontology- and inductive logic programming-based system to extract entities and relations from text,1,,,"Named entity recognition (NER) and relation extraction (RE) are two important subtasks in information extraction (IE). Most of the current learning methods for NER and RE rely on supervised machine learning techniques with more accurate results for NER than RE. This paper presents OntoILPER a system for extracting entity and relation instances from unstructured texts using ontology and inductive logic programming, a symbolic machine learning technique. OntoILPER uses the domain ontology and takes advantage of a higher expressive relational hypothesis space for representing examples whose structure is relevant to IE. It induces extraction rules that subsume examples of entities and relation instances from a specific graph-based model of sentence representation. Furthermore, OntoILPER enables the exploitation of the domain ontology and further background knowledge in the form of relational features. To evaluate OntoILPER, several experiments over the TREC corpus for both NER and RE tasks were conducted and the yielded results demonstrate its effectiveness in both tasks. This paper also provides a comparative assessment among OntoILPER and other NER and RE systems, showing that OntoILPER is very competitive on NER and outperforms the selected systems on RE. © 2017, Springer-Verlag London Ltd.",Knowledge and Information Systems,10.1007/s10115-017-1108-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030849258&doi=10.1007%2fs10115-017-1108-3&partnerID=40&md5=547a569fba2b1e4253593f5230953d91,2018,7/20/21 15:48,7/20/21 15:48,128
MLIW5XJN,journalArticle,2017,"Angelopoulos, N.; Cussens, J.",Distributional logic programming for Bayesian knowledge representation,1,,,"We present a formalism for combining logic programming and its flavour of nondeterminism with probabilistic reasoning. In particular, we focus on representing prior knowledge for Bayesian inference. Distributional logic programming (Dlp), is considered in the context of a class of generative probabilistic languages. A characterisation based on probabilistic paths which can play a central role in clausal probabilistic reasoning is presented. We illustrate how the characterisation can be utilised to clarify derived distributions with regards to mixing the logical and probabilistic constituents of generative languages. We use this operational characterisation to define a class of programs that exhibit probabilistic determinism. We show how Dlp can be used to define generative priors over statistical model spaces. For example, a single program can generate all possible Bayesian networks having N nodes while at the same time it defines a prior that penalises networks with large families. Two classes of statistical models are considered: Bayesian networks and classification and regression trees. Finally we discuss: (1) a Metropolis–Hastings algorithm that can take advantage of the defined priors and the probabilistic choice points in the prior programs and (2) its application to real-world machine learning tasks. © 2016 Elsevier Inc.",International Journal of Approximate Reasoning,10.1016/j.ijar.2016.08.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983546588&doi=10.1016%2fj.ijar.2016.08.004&partnerID=40&md5=268fb1b72b44236f9edb479d8e5aa4b7,2017,7/20/21 15:48,7/20/21 15:48,130
KDZ6AWYV,journalArticle,2020,"Gehrmann, S.; Strobelt, H.; Kruger, R.; Pfister, H.; Rush, A.M.",Visual Interaction with Deep Learning Models through Collaborative Semantic Inference,1,,,"Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system. © 1995-2012 IEEE.",IEEE Transactions on Visualization and Computer Graphics,10.1109/TVCG.2019.2934595,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075638456&doi=10.1109%2fTVCG.2019.2934595&partnerID=40&md5=9cd3c347b36186d413c6a55ad41613c3,2020,7/20/21 15:48,7/20/21 15:48,131
I9IHFH6N,journalArticle,2020,"Thibodeau, P.H.; Blonder, A.; Flusberg, S.J.",A connectionist account of the relational shift and context sensitivity in the development of generalisation,1,,,"Similarity-based generalisation is fundamental to human cognition, and the ability to draw analogies based on relational similarities between superficially different domains is crucial for reasoning and inference. Learning to base generalisation on shared relations rather than (or in the face of) shared perceptual features has been identified as an important developmental milestone. However, recent research has highlighted the context-sensitivity of generalisation: children and adults use perceptual similarity to make inferences in some cases and relational similarity in others, a finding that suggests people track the predictive validity of different types of inferences. Here we demonstrate that this pattern of behaviour naturally emerges over the course of development in a domain-general statistical learning model that employs distributed, sub-symbolic representations. We suggest that this model offers a parsimonious account of the development of context-sensitive, similarity-based generalisation and may provide several advantages over other popular structured or symbolic approaches to modelling relational inference. © 2020 Informa UK Limited, trading as Taylor & Francis Group.",Connection Science,10.1080/09540091.2020.1728519,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079377998&doi=10.1080%2f09540091.2020.1728519&partnerID=40&md5=bb948bdd2c4714b316a668cae6e72f95,2020,7/20/21 15:48,7/20/21 15:48,135
CGLBI7VX,journalArticle,2019,"Nápoles, G.; Vanhoenshoven, F.; Vanhoof, K.","Short-term cognitive networks, flexible reasoning and nonsynaptic learning",1,,,"While the machine learning literature dedicated to fully automated reasoning algorithms is abundant, the number of methods enabling the inference process on the basis of previously defined knowledge structures is scanter. Fuzzy Cognitive Maps (FCMs) are recurrent neural networks that can be exploited towards this goal because of their flexibility to handle external knowledge. However, FCMs suffer from a number of issues that range from the limited prediction horizon to the absence of theoretically sound learning algorithms able to produce accurate predictions. In this paper we propose a neural system named Short-term Cognitive Networks that tackle some of these limitations. In our model, used for regression and pattern completion, weights are not constricted and may have a causal nature or not. As a second contribution, we present a nonsynaptic learning algorithm to improve the network performance without modifying the previously defined weight matrix. Besides, we derive a stop condition to prevent the algorithm from iterating without significantly decreasing the global simulation error. © 2019 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2019.03.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063943662&doi=10.1016%2fj.neunet.2019.03.012&partnerID=40&md5=e2fc39c366bb6790ab00aabc75ce215b,2019,7/20/21 15:48,7/20/21 15:48,140
Q7RZGZ48,journalArticle,2018,"López-Sánchez, D.; Herrero, J.R.; Arrieta, A.G.; Corchado, J.M.",Hybridizing metric learning and case-based reasoning for adaptable clickbait detection,1,,,"The term clickbait is usually used to name web contents which are specifically designed to maximize advertisement monetization, often at the expense of quality and exactitude. The rapid proliferation of this type of content has motivated researchers to develop automatic detection methods, to effectively block clickbaits in different application domains. In this paper, we introduce a novel clickbait detection method. Our approach leverages state-of-the-art techniques from the fields of deep learning and metric learning, integrating them into the Case-Based Reasoning methodology. This provides the model with the ability to learn-over-time, adapting to different users’ criteria. Our experimental results also evidence that the proposed approach outperforms previous clickbait detection methods by a large margin. © 2017, Springer Science+Business Media, LLC, part of Springer Nature.",Applied Intelligence,10.1007/s10489-017-1109-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040791890&doi=10.1007%2fs10489-017-1109-7&partnerID=40&md5=183e854d657d892f20d9053e0a4d6dd5,2018,7/20/21 15:48,7/20/21 15:48,142
EGI547RA,journalArticle,2019,"Honda, H.; Hagiwara, M.",Question Answering Systems with Deep Learning-Based Symbolic Processing,1,,,"The authors propose methods to learn symbolic processing with deep learning and to build question answering systems by means of learned models. Symbolic processing, performed by the Prolog processing systems which execute unification, resolution, and list operations, is learned by a combination of deep learning models, Neural Machine Translation (NMT) and Word2Vec training. To our knowledge, the implementation of a Prolog-like processing system using deep learning is a new experiment that has not been conducted in the past. The results of their experiments revealed that the proposed methods are superior to the conventional methods because symbolic processing (1) has rich representations, (2) can interpret inputs even if they include unknown symbols, and (3) can be learned with a small amount of training data. In particular (2), handling of unknown data, which is a major task in artificial intelligence research, is solved using Word2Vec. Furthermore, question answering systems can be built from knowledge bases written in Prolog with learned symbolic processing, which, with conventional methods, is extremely difficult to accomplish. Their proposed systems can not only answer questions through powerful inferences by utilizing facts that harbor unknown data but also have the potential to build knowledge bases from a large amount of data, including unknown data, on the Web. The proposed systems are a completely new trial, there is no state-of-the-art methods in the sense of 'newest'. Therefore, to evaluate their efficiency, they are compared with the most traditional and robust system i.e., the Prolog system. This is new research that encompasses the subjects of conventional artificial intelligence and neural network, and their systems have higher potential to build applications such as FAQ chatbots, decision support systems and energy-efficient estimation using a large amount of information on the Web. Mining hidden information through these applications will provide great value. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2019.2948081,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078352116&doi=10.1109%2fACCESS.2019.2948081&partnerID=40&md5=dd4f6f6b24f6bb01178c87f12ce8cb5e,2019,7/20/21 15:48,7/20/21 15:48,143
ZW6KGA63,journalArticle,2018,"Priore, P.; Ponte, B.; Puente, J.; Gómez, A.",Learning-based scheduling of flexible manufacturing systems using ensemble methods,1,,ensemble methods,"Dispatching rules are commonly applied to schedule jobs in Flexible Manufacturing Systems (FMSs). However, the suitability of these rules relies heavily on the state of the system; hence, there is no single rule that always outperforms the others. In this scenario, machine learning techniques, such as support vector machines (SVMs), inductive learning-based decision trees (DTs), backpropagation neural networks (BPNs), and case based-reasoning (CBR), offer a powerful approach for dynamic scheduling, as they help managers identify the most appropriate rule in each moment. Nonetheless, different machine learning algorithms may provide different recommendations. In this research, we take the analysis one step further by employing ensemble methods, which are designed to select the most reliable recommendations over time. Specifically, we compare the behaviour of the bagging, boosting, and stacking methods. Building on the aforementioned machine learning algorithms, our results reveal that ensemble methods enhance the dynamic performance of the FMS. Through a simulation study, we show that this new approach results in an improvement of key performance metrics (namely, mean tardiness and mean flow time) over existing dispatching rules and the individual use of each machine learning algorithm. © 2018 Elsevier Ltd",Computers and Industrial Engineering,10.1016/j.cie.2018.09.034,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054163976&doi=10.1016%2fj.cie.2018.09.034&partnerID=40&md5=f91bd0e079bbfe2179eb5d3c91ae1782,2018,7/20/21 15:48,7/20/21 15:48,149
7Q5JRVK2,journalArticle,2017,"Diligenti, M.; Gori, M.; Saccà, C.",Semantic-based regularization for learning and inference,1,,SRL,"This paper proposes a unified approach to learning from constraints, which integrates the ability of classical machine learning techniques to learn from continuous feature-based representations with the ability of reasoning using higher-level semantic knowledge typical of Statistical Relational Learning. Learning tasks are modeled in the general framework of multi-objective optimization, where a set of constraints must be satisfied in addition to the traditional smoothness regularization term. The constraints translate First Order Logic formulas, which can express learning-from-example supervisions and general prior knowledge about the environment by using fuzzy logic. By enforcing the constraints also on the test set, this paper presents a natural extension of the framework to perform collective classification. Interestingly, the theory holds for both the case of data represented by feature vectors and the case of data simply expressed by pattern identifiers, thus extending classic kernel machines and graph regularization, respectively. This paper also proposes a probabilistic interpretation of the proposed learning scheme, and highlights intriguing connections with probabilistic approaches like Markov Logic Networks. Experimental results on classic benchmarks provide clear evidence of the remarkable improvements that are obtained with respect to related approaches. © 2015 Elsevier B.V.",Artificial Intelligence,10.1016/j.artint.2015.08.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940937276&doi=10.1016%2fj.artint.2015.08.011&partnerID=40&md5=3333e89077342ba6c46a593809d11eb2,2017,7/20/21 15:48,7/20/21 15:48,153
9AMIEFEX,journalArticle,2013,"Rybinski, H.; Ryzko, D.; Wiech, P.W.",Learning of defaults by agents in a distributed multi-agent system environment,1,,multiagent system,"The paper introduces a novel approach to machine learning in a multi-agents system. A distributed version of Inductive Logic Programming is used, which allows agents to construct new rules based on knowledge and examples, which are available to different memebrs of the system. The learning process is performed in two phases - first locally by each agent and then on the global level while reasoning. © Springer-Verlag Berlin Heidelberg 2013.","Smart Innovation, Systems and Technologies",10.1007/978-3-642-28699-5_8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879304696&doi=10.1007%2f978-3-642-28699-5_8&partnerID=40&md5=f18c9d8863cef0425ebef00b3ba5529e,2013,7/20/21 15:48,7/20/21 15:48,156
5DGXDZ77,journalArticle,2020,"Fan, F.; Wang, G.",Fuzzy logic interpretation of quadratic networks,1,,fuzzy logic,"Over past several years, deep learning has achieved huge successes in various applications. However, such a data-driven approach is often criticized for lack of interpretability. Recently, we proposed artificial quadratic neural networks consisting of quadratic neurons in potentially many layers. In cellular level, a quadratic function is used to replace the inner product in a traditional neuron, and then undergoes a nonlinear activation. With a single quadratic neuron, any fuzzy logic operation, such as XOR, can be implemented. In this sense, any deep network constructed with quadratic neurons can be interpreted as a deep fuzzy logic system. Since traditional neural networks and quadratic counterparts can represent each other and fuzzy logic operations are naturally implemented in quadratic neural networks, it is plausible to explain how a deep neural network works with a quadratic network as the system model. In this paper, we generalize and categorize fuzzy logic operations implementable with individual quadratic neurons, and then perform statistical/information-theoretic analyses of exemplary quadratic neural networks. © 2019 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2019.09.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073032808&doi=10.1016%2fj.neucom.2019.09.001&partnerID=40&md5=eca123700491bf1a0dcb8c6ecb61d608,2020,7/20/21 15:48,7/20/21 15:48,157
AZXPAGR7,journalArticle,2012,"Emele, C.D.; Norman, T.J.; Şensoy, M.; Parsons, S.",Learning strategies for task delegation in norm-governed environments,1,,multiagent system,"How do I choose whom to delegate a task to? This is an important question for an autonomous agent collaborating with others to solve a problem. Were similar proposals accepted from similar agents in similar circumstances? What arguments were most convincing? What are the costs incurred in putting certain arguments forward? Can I exploit domain knowledge to improve the outcome of delegation decisions? In this paper, we present an agent decision-making mechanism where models of other agents are refined through evidence from past dialogues and domain knowledge, and where these models are used to guide future delegation decisions. Our approach combines ontological reasoning, argumentation and machine learning in a novel way, which exploits decision theory for guiding argumentation strategies. Using our approach, intelligent agents can autonomously reason about the restrictions (e. g., policies/norms) that others are operating with, and make informed decisions about whom to delegate a task to. In a set of experiments, we demonstrate the utility of this novel combination of techniques. Our empirical evaluation shows that decision-theory, machine learning and ontology reasoning techniques can significantly improve dialogical outcomes. © 2012 The Author(s).",Autonomous Agents and Multi-Agent Systems,10.1007/s10458-012-9194-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861481400&doi=10.1007%2fs10458-012-9194-9&partnerID=40&md5=abbf3d67bf6eb4b8bba5503533109cc8,2012,7/20/21 15:48,7/20/21 15:48,161
E55R8LH9,journalArticle,2020,"González Rodríguez, G.; Gonzalez-Cava, J.M.; Méndez Pérez, J.A.",An intelligent decision support system for production planning based on machine learning,1,,fuzzy logic,"This paper presents a new methodology to solve a Closed-Loop Supply Chain (CLSC) management problem through a decision-making system based on fuzzy logic built on machine learning. The system will provide decisions to operate a production plant integrated in a CLSC to meet the production goals with the presence of uncertainties. One of the main contributions of the proposal is the ability to reject the effects that the imbalances in the rest of the chain have on the inventories of raw materials and finished products. For this, an intelligent algorithm will be in charge of the supervision of the plant operation and task-reprogramming to ensure the achievement of the process goals. Fuzzy logic and machine learning techniques are combined to design the tool. The method was tested on an industrial hospital laundry with satisfactory results, thus highlighting the potential of this proposal for its incorporation into the Industry 4.0 framework. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",Journal of Intelligent Manufacturing,10.1007/s10845-019-01510-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074834155&doi=10.1007%2fs10845-019-01510-y&partnerID=40&md5=19aa04e07ce67066094fda3a9f42639e,2020,7/20/21 15:48,7/20/21 15:48,166
B7D2DTG3,journalArticle,2019,"Al-Asaly, M.S.; Hassan, M.M.; Alsanad, A.",A cognitive/intelligent resource provisioning for cloud computing services: opportunities and challenges,1,,,"In cloud computing, resources could be provisioned in a dynamic way on demand for cloud services. Cloud providers seek to realize effective SLA execution mechanisms for avoiding SLA violations by provisioning the resources or applications and timely interacting to environmental changes and failures. Sufficient resource provisioning to cloud’s services relies on the requirements of the workloads to achieve a high performance for quality of service. Therefore, deciding the suitable amount of cloud’s resources for these services to achieve is one of the main works in cloud computing. During the runtime of services, the amount of cloud’s resources can be specified and provisioned based on the actual workloads changes. Determining the correct amount of cloud’s resources needed for running the services on clouds is not easy task, and it depends on the existing workloads of services. Consequently, it is required to predict the future workloads for dynamic provisioning of resources in order to meet the changes in workloads and demands of services in cloud computing environments. In this paper, we study the possibility of using a cognitive/intelligent approach for cloud resource provisioning which is a combination of the autonomic computing concept, deep learning technique and fuzzy logic control. Deep learning technique is a state-of-the-art in the machine learning field. It achieved promising results in many other fields like image classification and speech recognition. For these reasons, deep learning is proposed in this work to tackle the workload prediction in cloud computing. Additionally, we also propose to use a fuzzy logic-based method in order to make a decision in the case of uncertainty of the workload prediction. We study various exiting works on autonomic cloud resource provisioning and show that there is still an opportunity to improve the current methods. We also present the challenges that may exist on this domain. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Soft Computing,10.1007/s00500-019-04061-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066029238&doi=10.1007%2fs00500-019-04061-9&partnerID=40&md5=049e49d578b6908b22ccb743d2f30e66,2019,7/20/21 15:48,7/20/21 15:48,168
FEXZ3FTL,journalArticle,2021,"Ramoa, A.; Condeço, J.; Fdez-Riverola, F.; Lourenço, A.","HaemoKBS: A knowledge-based system for real-time, continuous categorisation of adverse reactions in blood recipients",1,,,"This work introduces HaemoKBS, a novel Haemovigilance decision support system for adverse reactions in blood recipients. Machine learning inference and rule-based reasoning were applied to build the underlying decision support models, namely to automatically extract evidence from different types of data included in hospital notifications and incorporate a priori expert knowledge. The ultimate aim is to dynamically learn and improve the reasoning abilities of the system and thus, be able to provide educated recommendations to hospital notifiers along with understandable explanations on the acquired knowledge. Experiments over the records of the Portuguese National Haemovigilance System from the last 10 years demonstrate the practical usefulness of HaemoKBS, which will contribute to a better depiction of the adverse reactions and to flag any incomplete notification enforcing data quality. © 2020 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2020.04.101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086458649&doi=10.1016%2fj.neucom.2020.04.101&partnerID=40&md5=8df9265de7b5d3bedd95d4af6dc0f6dd,2021,7/20/21 15:48,7/20/21 15:48,170
ZZAHFFRU,journalArticle,2019,"Hu, R.; Zhao, H.-M.; Xu, H.",A big data intelligence analysis expression method based on machine learning,1,,,"A dynamic intelligence expression method is presented in this paper, which uses big data analysis to represent the intelligence to be taken from Web. In this method, reasoning methods are used to create new ideas which can be added to field intelligence systems in favor of big data analysis. This is used for the generalization of the well-known analysis to implement rule based generalization. The method plans to produce a learning model which best take offs the class members of a marked rule base. The object categories are given by an interface which is represented by the standards of a mathematical method. The category is defined by the formula. In our big data method, the learned artificial intelligence model is represented by models and it is consisted of a best condition of expressions of a given category. We show that this feature gives scholar choices to get ideas into the application field. Furthermore, the expression according to models adds additional value to the function and enables to answer questions, which big data function method cannot. The big data expression of the models can be explained by scholar. The reasoning logic can be added to the existing artificial intelligence expression method. Additionally, the reasoning logic obtaining method can be used repeatedly. In each procedure, new ideas from the search step can be added to the reasoning rule sets to enhance the comprehensive characteristics of the presented reasoning methods. © 2017, Springer Science+Business Media, LLC, part of Springer Nature.",Cluster Computing,10.1007/s10586-017-1578-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039710022&doi=10.1007%2fs10586-017-1578-9&partnerID=40&md5=88c40148aad42105435361f150362159,2019,7/20/21 15:48,7/20/21 15:48,180
57NJKR3Q,journalArticle,2018,"Houeland, T.G.; Aamodt, A.",A learning system based on lazy metareasoning,1,,,"Metareasoning has been widely studied in the literature, with a wide variety of algorithms and partially overlapping methodological approaches. However, these methods are typically either not targeted toward practical machine learning systems or alternatively are focused on achieving the best possible performance for a particular domain, with extensive human tuning and research, and vast computing resources. In this paper, our goal is to create systems that perform sustained autonomous learning, with automatically determined domain-specific optimizations for any given domain, and without requiring human assistance. We present Alma, a metareasoning architecture that creates and selects reasoning methods based on empirically observed performance. This is achieved by using lazy learning at the metalevel, and automatically training and combining reasoning methods at run-time. In experiments across diverse data sets, we demonstrate the ability of Alma to successfully reason about learner performance in different domains and achieve a better overall result than any of the individual reasoning methods, even with limited computing time available. © 2017, Springer-Verlag GmbH Germany.",Progress in Artificial Intelligence,10.1007/s13748-017-0138-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056120994&doi=10.1007%2fs13748-017-0138-0&partnerID=40&md5=75b79eac1b12b3320289c48f183eb2c3,2018,7/20/21 15:48,7/20/21 15:48,199
LXVVU9IG,journalArticle,2019,"Makni, B.; Hendler, J.",Deep learning for noise-tolerant RDFS reasoning,1,,,"Since the 2001 envisioning of the Semantic Web (SW) (Scientific American 284(5) (2001) 34-43), the main research focus in SW reasoning has been on the soundness and completeness of reasoners. While these reasoners assume the veracity of input data, the reality is that the Web of data is inherently noisy. Although there has been recent work on noise-tolerant reasoning, it has focused on type inference rather than full RDFS reasoning. Even though RDFS closure generation can be seen as a Knowledge Graph (KG) completion problem, the problem setting is different - making KG embedding techniques that were designed for link prediction not suitable for RDFS reasoning. This paper documents a novel approach that extends noise-tolerance in the SW to full RDFS reasoning. Our embedding technique - that is tailored for RDFS reasoning - consists of layering RDF graphs and encoding them in the form of 3D adjacency matrices where each layer layout forms a graph word. Each input graph and its entailments are then represented as sequences of graph words, and RDFS inference can be formulated as translation of these graph words sequences, achieved through neural machine translation. Our evaluation on LUBM1 synthetic dataset shows 97 % validation accuracy and 87.76 % on a subset of DBpedia while demonstrating a noise-tolerance unavailable with rule-based reasoners. © 2019 - IOS Press and the authors. All rights reserved.",Semantic Web,10.3233/SW-180363,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072370517&doi=10.3233%2fSW-180363&partnerID=40&md5=b3a71ad3e5347c72d3ad65d01bb1e67a,2019,7/20/21 15:48,7/20/21 15:48,203
Y5DEU66R,journalArticle,2019,"Dai, X.; Zhao, X.; Jin, P.; Cai, X.; Zhang, H.; Yang, C.; Li, B.",Opera-oriented character relations extraction for role interaction and behaviour Understanding: a deep learning approach,1,,,"There are a great number of complex relations among different characters in an opera. Retrieving such relations is crucial for performers and audience to accurately understand the features and behaviour of roles. Aiming to automatically extract relations among characters in an opera, in this paper we propose an effective method that can extract character relations from opera scripts. Firstly, we construct a uniform reasoning framework for opera scripts. Based on this model, we propose a deep syntax-parsing method to detect character relations from opera scripts. After that, we propose a new deep learning approach called SL-Bi-LSTM-CRF to extract the objects involved in character relations. The proposed SL-Bi-LSTM-CRF algorithm is a sentence-level relation extraction algorithm based on the Bi-directional LSTM with a CRF layer. With this mechanism, we are able to get a detailed description for character relations. We conduct experiments on a real dataset of opera scripts. The experimental results in terms of precision, recall, and F-score suggest the effectiveness of our proposal. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.",Behaviour and Information Technology,10.1080/0144929X.2019.1584246,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061991420&doi=10.1080%2f0144929X.2019.1584246&partnerID=40&md5=11bbf1c511988eb74e99678a9026bcfb,2019,7/20/21 15:48,7/20/21 15:48,207
IMUWQCJG,journalArticle,2019,"Amaral, R.P.F.; Ribeiro, M.V.; de Aguiar, E.P.",Type-1 and singleton fuzzy logic system trained by a fast scaled conjugate gradient methods for dealing with binary classification problems,1,,fuzzy logic,"This work introduces the type-1 and singleton fuzzy logic system trained by scaled conjugate gradient method and its usage for binary classification problems. Aiming to improve the performance of the training procedure, we propose the multiplication of the Hessian matrix by the directional vector using the so-called differential operator R·, which results in another proposal for training the aforementioned fuzzy logic system. In order to evaluate the proposals, performance analyses based on well-known data sets provided by UCI Machine Learning Repository and Knowledge Extraction based on Evolutionary Learning Repository together with well-established metrics are detailed. The numerical results show that the proposals achieve improvements in comparison with others gradient based training methods applied to the type-1 fuzzy logic system present in the literature. These improvements regard to the fast convergence speed under the constraint over the number of epochs during the training phase. © 2019",Neurocomputing,10.1016/j.neucom.2019.05.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065533996&doi=10.1016%2fj.neucom.2019.05.002&partnerID=40&md5=6e7c1a10dcfe9bc03b88e9bee58054bd,2019,7/20/21 15:48,7/20/21 15:48,208
HIJL2VU6,journalArticle,2019,"Cropper, A.; Muggleton, S.H.",Learning efficient logic programs,1,,,"When machine learning programs from data, we ideally want to learn efficient rather than inefficient programs. However, existing inductive logic programming (ILP) techniques cannot distinguish between the efficiencies of programs, such as permutation sort (n!) and merge sort O(nlogn). To address this limitation, we introduce Metaopt, an ILP system which iteratively learns lower cost logic programs, each time further restricting the hypothesis space. We prove that given sufficiently large numbers of examples, Metaopt converges on minimal cost programs, and our experiments show that in practice only small numbers of examples are needed. To learn minimal time-complexity programs, including non-deterministic programs, we introduce a cost function called tree cost which measures the size of the SLD-tree searched when a program is given a goal. Our experiments on programming puzzles, robot strategies, and real-world string transformation problems show that Metaopt learns minimal cost programs. To our knowledge, Metaopt is the first machine learning approach that, given sufficient numbers of training examples, is guaranteed to learn minimal cost logic programs, including minimal time-complexity programs. © 2018, The Author(s).",Machine Learning,10.1007/s10994-018-5712-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045856425&doi=10.1007%2fs10994-018-5712-6&partnerID=40&md5=a476b40df794375ab07b5999e70bdade,2019,7/20/21 15:48,7/20/21 15:48,209
8I89SD4K,journalArticle,2020,"Ul Islam, R.; Hossain, M.S.; Andersson, K.",A deep learning inspired belief rule-based expert system,1,,,"Recent technological advancements in the area of the Internet of Things (IoT) and cloud services, enable the generation of large amounts of raw data. However, the accurate prediction by using this data is considered as challenging for machine learning methods. Deep Learning (DL) methods are widely used to process large amounts of data because they need less preprocessing than traditional machine learning methods. Various types of uncertainty associated with large amounts of raw data hinder the prediction accuracy. Belief Rule-Based Expert Systems (BRBES) are widely used to handle uncertain data. However, due to their incapability of integrating associative memory within the inference procedures, they demonstrate poor accuracy of prediction when large amounts of data is considered. Therefore, we propose the integration of an associative memory based DL method within the BRBES inference procedures, allowing to discover accurate data patterns and hence, the improvement of prediction under uncertainty. To demonstrate the applicability of the proposed method, which is named BRB-DL, it has been fine tuned against two datasets, one in the area of air pollution and the other in the area of power generation. The reliability of the proposed BRB-DL method, has also been compared with other DL methods such as Long-Short Term Memory and Deep Neural Network, and BRBES by taking into account of the air quality dataset from Beijing city and the power generation dataset of a combined cycle power plant. BRB-DL outperforms the above-mentioned methods in terms of prediction accuracy. For example, the Mean Square Error value of BRB-DL is 4.12 whereas for Long-Short Term Memory, Deep Neural Network, Fuzzy Deep Neural Network, Adaptive Neuro Fuzzy Inference System and BRBES it is 18.66, 28.49, 17.05, 16.37 and 38.15 for combined cycle power plant respectively, which are significantly higher. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",IEEE Access,10.1109/ACCESS.2020.3031438,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102834557&doi=10.1109%2fACCESS.2020.3031438&partnerID=40&md5=ef7afa89137816308f10eb1bbecfbfbe,2020,7/20/21 15:48,7/20/21 15:48,212
7MGKKE7Q,journalArticle,2019,"Lima, R.; Espinasse, B.; Freitas, F.",A logic-based relational learning approach to relation extraction: The OntoILPER system,1,,,"Relation Extraction (RE), the task of detecting and characterizing semantic relations between entities in text, has gained much importance in the last two decades, mainly in the biomedical domain. Many papers have been published on Relation Extraction using supervised machine learning techniques. Most of these techniques rely on statistical methods, such as feature-based and tree-kernels-based methods. Such statistical learning techniques are usually based on a propositional hypothesis space for representing examples, i.e., they employ an attribute–value representation of features. This kind of representation has some drawbacks, particularly in the extraction of complex relations which demand more contextual information about the involving instances, i.e., it is not able to effectively capture structural information from parse trees without loss of information. In this work, we present OntoILPER, a logic-based relational learning approach to Relation Extraction that uses Inductive Logic Programming for generating extraction models in the form of symbolic extraction rules. OntoILPER takes profit of a rich relational representation of examples, which can alleviate the aforementioned drawbacks. The proposed relational approach seems to be more suitable for Relation Extraction than statistical ones for several reasons that we argue. Moreover, OntoILPER uses a domain ontology that guides the background knowledge generation process and is used for storing the extracted relation instances. The induced extraction rules were evaluated on three protein–protein interaction datasets from the biomedical domain. The performance of OntoILPER extraction models was compared with other state-of-the-art RE systems. The encouraging results seem to demonstrate the effectiveness of the proposed solution. © 2018 Elsevier Ltd",Engineering Applications of Artificial Intelligence,10.1016/j.engappai.2018.11.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057496358&doi=10.1016%2fj.engappai.2018.11.001&partnerID=40&md5=46ddd00d613ed9d46426d943543fafd9,2019,7/20/21 15:48,7/20/21 15:48,218
Y7XQEZMH,journalArticle,2021,"Bu, L.; Liang, Y.; Xie, Z.; Qian, H.; Hu, Y.-Q.; Yu, Y.; Chen, X.; Li, X.",Machine learning steered symbolic execution framework for complex software code,1,,,"During program traversing, symbolic execution collects pathconditions and feeds them to a constraint solver to obtain feasiblesolutions. However, complex path conditions, like nonlinearconstraints, which widely appear in programs, are hard to be handledefficiently by the existing solvers. In this paper, we adapt theclassical symbolic execution framework with a machine learningapproach for constraint satisfaction. The approach samples andlearns from different solutions to identify potentially feasiblearea. This sampling-learning style solving can be applied indifferent class of complex problems easily. Therefore, incorporatingthis approach, our framework, MLBSE, supports the symbolicexecution of not only simple linear path conditions, but alsononlinear arithmetic operations, and even black-box function callsof library methods. Meanwhile, thanks to the theoretical foundationof the machine learning based approach, when the solver fails tosolve a path condition, we can have an estimation of the confidencein the satisfiability (ECS) of the problem to give users insightsabout how the problem is analyzed and whether they could ultimatelyfind a solution. We implement MLBSE on the basis of SymbolicPath Finder (SPF) into a fully automatic Java symbolic executionengine. Users can feed their code to MLBSE directly, which isvery convenient to use. To evaluate its performance, 22 real caseprograms are used as the benchmarks for MLBSE to generate testcases, which involve a total number of 1042 methods that are full ofnonlinear operations, floating-point arithmetic as well as nativemethod calls. Experiment results show that the coverage achieved byMLBSE is much higher than the state-of-the-art tools. © 2021, British Computer Society.",Formal Aspects of Computing,10.1007/s00165-021-00538-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106508716&doi=10.1007%2fs00165-021-00538-3&partnerID=40&md5=f27f87a74e093a0563b6a02a05cfc129,2021,7/20/21 15:48,7/20/21 15:48,221
LS69UH8F,journalArticle,2017,"Otaibi, J.A.; Safi, Z.; Hassaine, A.; Islam, F.; Jaoua, A.",Machine Learning and Conceptual Reasoning for Inconsistency Detection,1,,text,"This paper focuses on detecting inconsistencies within text corpora. It is a very interesting area with many applications. Most existing methods deal with this problem using complicated textual analysis, which is known for not being accurate enough. We propose a new methodology that consists of two steps, the first one being a machine learning step that performs multilevel text categorization. The second one applies conceptual reasoning on the predicted categories in order to detect inconsistencies. This paper has been validated on a set of Islamic advisory opinions (also known as fatwas). This domain is gaining a large interest with users continuously checking the authenticity and relevance of such content. The results show that our method is very accurate and can complement existing methods using the linguistic analysis. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2016.2642402,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018484520&doi=10.1109%2fACCESS.2016.2642402&partnerID=40&md5=01f5cae922b149b00e8bf26d723b8cef,2017,7/20/21 15:48,7/20/21 15:48,222
V6GFPJBU,journalArticle,2021,"Cheng, S.-T.; Hsu, C.-W.; Horng, G.-J.; Jiang, C.-R.",Video reasoning for conflict events through feature extraction,1,,video,"The rapid growth of multimedia data and the improvement of deep learning technology has allowed high-accuracy models to be trained for various fields. Video tools such as video classification, temporal action detection, and video summary are now available for the understanding of videos. In daily life, many social events start with a small conflict event. If conflicts and the subsequent dangers can be learned about from a video, we can prevent social incidents from occurring early on. This research presents a video and audio reasoning network that infers possible conflict events through video and audio features. To make the respective model more generalizable to other tasks, we have also added a predictive network to predict the risk of conflict events. We use multitasking to render the characteristics of movies and voices more generalizable to other similar tasks. We also propose several methods to integrate video features and audio features, improving the reasoning performance of the model. There’s a model we proposed is called the video and audio reasoning Network (VARN) which is more accurate than other models. Compared with RandomNet, it achieves a 2.9 times greater accuracy. © 2021, Springer Science+Business Media, LLC, part of Springer Nature.",Journal of Supercomputing,10.1007/s11227-020-03514-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098696134&doi=10.1007%2fs11227-020-03514-5&partnerID=40&md5=ea56b5c1fbcc2a235b610c46cbc67af6,2021,7/20/21 15:48,7/20/21 15:48,227
NWKGBV36,journalArticle,2018,"Sykes, E.R.",Reasoning about ideal interruptible moments: A soft computing implementation of an interruption classifier in free-form task environments,1,,HCI,"Current trends in society and technology make the concept of interruption a central human computer interaction problem. In this work, a novel soft computing implementation for an Interruption Classifier was designed, developed and evaluated that draws from a user model and real-time observations of the user's actions as s/he works on computer-based tasks to determine ideal times to interact with the user. This research is timely as the number of interruptions people experience daily has grown considerably over the last decade. Thus, systems are needed to manage interruptions by reasoning about ideal timings of interactions. This research shows: (1) the classifier incorporates a user model in its’ reasoning process. Most of the research in this area has focused on task-based contextual information when designing systems that reason about interruptions; (2) the classifier performed at 96% accuracy in experimental test scenarios and significantly outperformed other comparable systems; (3) the classifier is implemented using an advanced machine learning technology—an Adaptive Neural-Fuzzy Inference System—this is unique since all other systems use Bayesian Networks or other machine learning tools; (4) the classifier does not require any direct user involvement—in other systems, users must provide interruption annotations while reviewing video sessions so the system can learn; and (5) a promising direction for reasoning about interruptions for free-form tasks–this is largely an unsolved problem. © 2018",International Journal of Human Computer Studies,10.1016/j.ijhcs.2018.06.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051663528&doi=10.1016%2fj.ijhcs.2018.06.005&partnerID=40&md5=ada9734099cc2ff3e7e3ed337e9c05da,2018,7/20/21 15:48,7/20/21 15:48,229
ETE3ZTWR,journalArticle,2020,"Wang, Q.; Hao, Y.",ALSTM: An attention-based long short-term memory framework for knowledge base reasoning,1,,,"Knowledge Graphs (KGs) have been applied to various application scenarios including Web searching, Q&A, recommendation system, natural language processing and so on. However, the vast majority of Knowledge Bases (KBs) are incomplete, necessitating a demand for KB completion (KBC). Methods of KBC used in the mainstream current knowledge base include the latent factor model, the random walk model and recent popular methods based on reinforcement learning, which performs well in their respective areas of expertise. Recurrent neural network (RNN) and its variants model temporal data by remembering information for long periods, however, whether they also have the ability to use the information they have already remembered to achieve complex reasoning in the knowledge graph. In this paper, we produce a novel framework (ALSTM) based on the Attention mechanism and Long Short-Term Memory (LSTM), which associates structure learning with parameter learning of first-order logical rules in an end-to-end differentiable neural networks model. In this framework, we designed a memory system and employed a multi-head dot product attention (MHDPA) to interact and update the memories embedded in the memory system for reasoning purposes. This is also consistent with the process of human cognition and reasoning, looking for enlightenment for the future in historical memory. In addition, we explored the use of inductive bias in deep learning to facilitate learning of entities, relations, and rules. Experiments establish the efficiency and effectiveness of our model and show that our method achieves better performance in tasks which include fact prediction and link prediction than baseline models on several benchmark datasets such as WN18RR, FB15K-237 and NELL-995. © 2020 Elsevier Ltd",Neurocomputing,10.1016/j.neucom.2020.02.065,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081931785&doi=10.1016%2fj.neucom.2020.02.065&partnerID=40&md5=1cbeb4e9a1aa7b61a3f9f20e5f3cd26e,2020,7/20/21 15:48,7/20/21 15:48,239
UMI9HNEY,journalArticle,2019,"Motepe, S.; Hasan, A.N.; Stopforth, R.",Improving Load Forecasting Process for a Power Distribution Network Using Hybrid AI and Deep Learning Algorithms,1,,fuzzy logic,"Load forecasting is useful for various applications, including maintenance planning. The study of load forecasting using recent state-of-the-art hybrid artificial intelligence (AI) and deep learning (DL) techniques is limited in South Africa (SA) and South African power distribution networks. This paper proposes a novel hybrid AI and DL South African distribution network load forecasting system. The system comprises of modules that handle the collection of the loading data from the field, analysis of data integrity using fuzzy logic, data preprocessing, consolidation of the loading and the temperature data, and load forecasting. The load forecasting results are then used to inform maintenance planning. The load forecasting is conducted using a hybrid AI/DL load forecasting module. A novel comparative study of recent state-of-the-art AI techniques is also presented to determine the best technique to deploy in this module when forecasting South African power redistributing customers' loads. The impact of the inclusion of weather parameters and loading data clean up on the load forecasting performance of a hybrid AI technique, optimally pruned extreme learning machines (OP-ELM), and a deep learning technique, long short-term memory (LSTM), is also investigated. These techniques are compared with each other and also with a commonly used powerful hybrid AI technique, adaptive neuro-fuzzy inference system (ANFIS). LSTM was found to achieve higher load forecasting accuracies than ANFIS and OP-ELM in forecasting the two distribution customers' loads in this paper. Only the LSTM models' performance improved with the inclusion of temperature in their development. © 2019 IEEE.",IEEE Access,10.1109/ACCESS.2019.2923796,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068640058&doi=10.1109%2fACCESS.2019.2923796&partnerID=40&md5=9bbdc546bc5233dd0dd139eac2c2a5a5,2019,7/20/21 15:48,7/20/21 15:48,246
8UBLGFBX,journalArticle,2019,"Al-Hmouz, R.; Pedrycz, W.; Balamash, A.; Morfeq, A.",Logic-driven autoencoders,1,,fuzzy logic,"Autoencoders are computing architectures encountered in various schemes of deep learning and realizing an efficient way of representing data in a compact way by forming a set of features. In this study, a concept, architecture, and algorithmic developments of logic-driven autoencoders are presented. In such structures, encoding and the decoding processes realized at the consecutive layers of the autoencoder are completed with the aid of some fuzzy logic operators (namely, OR, AND, NOT operations) and the ensuing encoding and decoding processing is carried out with the aid of fuzzy logic processing. The optimization of the autoencoder is completed through a gradient-based learning. The transparent knowledge representation delivered by autoencoders is facilitated by the involvement of logic processing, which implies that the encoding mechanism comes with the generalization abilities delivered by OR neurons while the specialization mechanism is achieved by the AND-like neurons forming the decoding layer. A series of illustrative examples is also presented. © 2019 Elsevier B.V.",Knowledge-Based Systems,10.1016/j.knosys.2019.104874,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070212527&doi=10.1016%2fj.knosys.2019.104874&partnerID=40&md5=d23a07c789b979b939e4c2b1b880b18a,2019,7/20/21 15:48,7/20/21 15:48,250
B2ZYRVRM,journalArticle,2020,"Zhang, L.; He, W.; Morkved, O.; Zhao, V.; Littman, M.L.; Lu, S.; Ur, B.",Trace2TAP: Synthesizing Trigger-Action Programs from Traces of Behavior,1,,iot,"Two common approaches for automating IoT smart spaces are having users write rules using trigger-action programming (TAP) or training machine learning models based on observed actions. In this paper, we unite these approaches. We introduce and evaluate Trace2TAP, a novel method for automatically synthesizing TAP rules from traces (time-stamped logs of sensor readings and manual actuations of devices). We present a novel algorithm that uses symbolic reasoning and SAT-solving to synthesize TAP rules from traces. Compared to prior approaches, our algorithm synthesizes generalizable rules more comprehensively and fully handles nuances like out-of-order events. Trace2TAP also iteratively proposes modified TAP rules when users manually revert automations. We implemented our approach on Samsung SmartThings. Through formative deployments in ten offices, we developed a clustering/ranking system and visualization interface to intelligibly present the synthesized rules to users. We evaluated Trace2TAP through a field study in seven additional offices. Participants frequently selected rules ranked highly by our clustering/ranking system. Participants varied in their automation priorities, and they sometimes chose rules that would seem less desirable by traditional metrics like precision and recall. Trace2TAP supports these differing priorities by comprehensively synthesizing TAP rules and bringing humans into the loop during automation. © 2020 Owner/Author.","Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies",10.1145/3411838,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092435676&doi=10.1145%2f3411838&partnerID=40&md5=b95c8d5171bb8976d4bf2b1aa946503d,2020,7/20/21 15:48,7/20/21 15:48,254
JQIKCMV2,journalArticle,2021,"Abeyrathna, K.D.; Granmo, O.-C.; Goodwin, M.",Extending the Tsetlin Machine with Integer-Weighted Clauses for Increased Interpretability,1,,,"Building models that are both interpretable and accurate is an unresolved challenge for many pattern recognition problems. In general, rule-based and linear models lack accuracy, while deep learning interpretability is based on rough approximations of the underlying inference. However, recently, the rule-based Tsetlin Machines (TMs) have obtained competitive performance in terms of accuracy, memory footprint, and inference speed on diverse benchmarks (image classification, regression, natural language understanding, and game-playing). TMs construct rules using human-interpretable conjunctive clauses in propositional logic. These, in turn, are combined linearly to solve complex pattern recognition tasks. This paper addresses the accuracy-interpretability challenge in machine learning by introducing a TM with integer weighted clauses - the Integer Weighted TM (IWTM). The intent is to increase TM interpretability by reducing the number of clauses required for competitive performance. The IWTM achieves this by weighting the clauses so that a single clause can replace multiple duplicates. Since each TM clause is formed adaptively by a Tsetlin Automata (TA) team, identifying effective weights becomes a challenging online learning problem. We solve this problem by extending each team of TA with another kind of automaton: the stochastic searching on the line (SSL) automaton. We evaluate the performance of the new scheme empirically using five datasets, along with a study of interpretability. On average, IWTM uses 6.5 times fewer literals than the vanilla TM and 120 times fewer literals than a TM with real-valued weights. Furthermore, in terms of average memory usage and F1-Score, IWTM outperforms simple Multi-Layered Artificial Neural Networks, Decision Trees, Support Vector Machines, K-Nearest Neighbor, Random Forest, Gradient Boosted Trees (XGBoost), Explainable Boosting Machines (EBMs), as well as the standard and real-value weighted TMs. IWTM finally outperforms Neural Additive Models on Fraud Detection and StructureBoost on CA-58 in terms of Area Under Curve, while performing competitively on COMPAS. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2021.3049569,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099201234&doi=10.1109%2fACCESS.2021.3049569&partnerID=40&md5=5322e5ba8ef699b8165123d956114d20,2021,7/20/21 15:48,7/20/21 15:48,264
QJ4AF8EJ,journalArticle,2020,"Martinez-Gil, J.; Chaves-Gonzalez, J.M.",A novel method based on symbolic regression for interpretable semantic similarity measurement,1,,text,"The problem of automatically measuring the degree of semantic similarity between textual expressions is a challenge that consists of calculating the degree of likeness between two text fragments that have none or few features in common according to human judgment. In recent times, several machine learning methods have been able to establish a new state-of-the-art regarding the accuracy, but none or little attention has been paid to their interpretability, i.e. the extent to which an end-user could be able to understand the cause of the output from these approaches. Although such solutions based on symbolic regression already exist in the field of clustering, we propose here a new approach which is being able to reach high levels of interpretability without sacrificing accuracy in the context of semantic textual similarity. After a complete empirical evaluation using several benchmark datasets, it is shown that our approach yields promising results in a wide range of scenarios. © 2020 Elsevier Ltd",Expert Systems with Applications,10.1016/j.eswa.2020.113663,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087275641&doi=10.1016%2fj.eswa.2020.113663&partnerID=40&md5=6471ee0af40219ec2cf132803f6e8d8d,2020,7/20/21 15:48,7/20/21 15:48,268
ARN3RXUK,journalArticle,2018,"Fan, F.; Cong, W.; Wang, G.",Generalized backpropagation algorithm for training second-order neural networks,1,,fuzzy logic,"The artificial neural network is a popular framework in machine learning. To empower individual neurons, we recently suggested that the current type of neurons could be upgraded to second-order counterparts, in which the linear operation between inputs to a neuron and the associated weights is replaced with a nonlinear quadratic operation. A single second-order neurons already have a strong nonlinear modeling ability, such as implementing basic fuzzy logic operations. In this paper, we develop a general backpropagation algorithm to train the network consisting of second-order neurons. The numerical studies are performed to verify the generalized backpropagation algorithm. Copyright © 2017 John Wiley & Sons, Ltd.",International Journal for Numerical Methods in Biomedical Engineering,10.1002/cnm.2956,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041571468&doi=10.1002%2fcnm.2956&partnerID=40&md5=654bce765c4ba30b89eda93c57d80848,2018,7/20/21 15:48,7/20/21 15:48,286
JBRJXR8E,journalArticle,2015,"Katzouris, N.; Artikis, A.; Paliouras, G.",Incremental learning of event definitions with Inductive Logic Programming,1,,,"Event recognition systems rely on knowledge bases of event definitions to infer occurrences of events in time. Using a logical framework for representing and reasoning about events offers direct connections to machine learning, via Inductive Logic Programming (ILP), thus allowing to avoid the tedious and error-prone task of manual knowledge construction. However, learning temporal logical formalisms, which are typically utilized by logic-based event recognition systems is a challenging task, which most ILP systems cannot fully undertake. In addition, event-based data is usually massive and collected at different times and under various circumstances. Ideally, systems that learn from temporal data should be able to operate in an incremental mode, that is, revise prior constructed knowledge in the face of new evidence. In this work we present an incremental method for learning and revising event-based knowledge, in the form of Event Calculus programs. The proposed algorithm relies on abductive–inductive learning and comprises a scalable clause refinement methodology, based on a compressive summarization of clause coverage in a stream of examples. We present an empirical evaluation of our approach on real and synthetic data from activity recognition and city transport applications. © 2015, The Author(s).",Machine Learning,10.1007/s10994-015-5512-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939256422&doi=10.1007%2fs10994-015-5512-1&partnerID=40&md5=96d57db2958366f218a8606b5529b595,2015,7/20/21 15:48,7/20/21 15:48,287
W2Q4E8E4,journalArticle,2021,"Saritha, M.; Milton, R.S.",A probabilistic logic approach to outcome prediction in team games using historical data and domain knowledge,1,,,"Relational data is structured and, in the real world, ambiguous. Logic can handle relations and probability can handle uncertainty. A probabilistic logic approach to learning can handle both relational structure and uncertainty in the data. Probabilistic logic approach works well with relational data. Incorporating domain knowledge in probabilistic logic approach further enhances learning, improving accuracy. A number of statistical techniques carry out predictive analytics based on historical data alone. Soccer, however, is a team game and the outcome of a soccer game depends on how well the team together and the players play against the opponent team. Thus, data about soccer games are better represented in relational form. In the present work, we propose to learn from soccer match data to predict their outcomes. We learn a model for the prediction of soccer game outcomes, taking into account the history of the matches played by the teams. We frame the background knowledge as rules in the logic program to enhance the prediction. Compared to the traditional machine learning approaches to soccer game outcome prediction, probabilistic logic approach is found to result in significant improvement in prediction accuracy. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.",Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-01989-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085142665&doi=10.1007%2fs12652-020-01989-x&partnerID=40&md5=8322df4f0b40c8f13df2205fe15c936d,2021,7/20/21 15:48,7/20/21 15:48,289
ADEGV37A,journalArticle,2021,"Nguembang Fadja, A.; Riguzzi, F.; Lamma, E.",Learning hierarchical probabilistic logic programs,1,,,"Probabilistic logic programming (PLP) combines logic programs and probabilities. Due to its expressiveness and simplicity, it has been considered as a powerful tool for learning and reasoning in relational domains characterized by uncertainty. Still, learning the parameter and the structure of general PLP is computationally expensive due to the inference cost. We have recently proposed a restriction of the general PLP language called hierarchical PLP (HPLP) in which clauses and predicates are hierarchically organized. HPLPs can be converted into arithmetic circuits or deep neural networks and inference is much cheaper than for general PLP. In this paper we present algorithms for learning both the parameters and the structure of HPLPs from data. We first present an algorithm, called parameter learning for hierarchical probabilistic logic programs (PHIL) which performs parameter estimation of HPLPs using gradient descent and expectation maximization. We also propose structure learning of hierarchical probabilistic logic programming (SLEAHP), that learns both the structure and the parameters of HPLPs from data. Experiments were performed comparing PHIL and SLEAHP with PLP and Markov Logic Networks state-of-the art systems for parameter and structure learning respectively. PHIL was compared with EMBLEM, ProbLog2 and Tuffy and SLEAHP with SLIPCOVER, PROBFOIL+, MLB-BC, MLN-BT and RDN-B. The experiments on five well known datasets show that our algorithms achieve similar and often better accuracies but in a shorter time. © 2021, The Author(s).",Machine Learning,10.1007/s10994-021-06016-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107994928&doi=10.1007%2fs10994-021-06016-4&partnerID=40&md5=d465478b9c9a9759332ccb7a4929acf2,2021,7/20/21 15:48,7/20/21 15:48,290
H5Z76FA7,journalArticle,2013,"Bellodi, E.; Riguzzi, F.",Expectation maximization over binary decision diagrams for probabilistic logic programs,1,,,"Recently much work in Machine Learning has concentrated on using expressive representation languages that combine aspects of logic and probability. A whole field has emerged, called Statistical Relational Learning, rich of successful applications in a variety of domains. In this paper we present a Machine Learning technique targeted to Probabilistic Logic Programs, a family of formalisms where uncertainty is represented using Logic Programming tools. Among various proposals for Probabilistic Logic Programming, the one based on the distribution semantics is gaining popularity and is the basis for languages such as ICL, PRISM, ProbLog and Logic Programs with Annotated Disjunctions. This paper proposes a technique for learning parameters of these languages. Since their equivalent Bayesian networks contain hidden variables, an Expectation Maximization (EM) algorithm is adopted. In order to speed the computation up, expectations are computed directly on the Binary Decision Diagrams that are built for inference. The resulting system, called EMBLEM for ""EM over Bdds for probabilistic Logic programs Efficient Mining"", has been applied to a number of datasets and showed good performances both in terms of speed and memory usage. In particular its speed allows the execution of a high number of restarts, resulting in good quality of the solutions. © 2013 - IOS Press and the authors. All rights reserved.",Intelligent Data Analysis,10.3233/IDA-130582,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878938613&doi=10.3233%2fIDA-130582&partnerID=40&md5=c7dc621ea3604c31c595156a82129d64,2013,7/20/21 15:48,7/20/21 15:48,291
CEVZ9A8R,journalArticle,2018,"Díaz-Pernil, D.; Gutiérrez-Naranjo, M.A.",Semantics of deductive databases with spiking neural P systems,1,,,"The integration of symbolic reasoning systems based on logic and connectionist systems based on the functioning of living neurons is a vivid research area in computer science. In the literature, one can find many efforts where different reasoning systems based on different logics are linked to classic artificial neural networks. In this paper, we study the relation between the semantics of reasoning systems based on propositional logic and the connectionist model in the framework of membrane computing, namely, spiking neural P systems. We prove that the fixed point semantics of deductive databases without negation can be implemented in the spiking neural P systems model and such a model can also deal with negation if it is endowed with anti-spikes and annihilation rules. © 2017 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2017.07.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023773675&doi=10.1016%2fj.neucom.2017.07.007&partnerID=40&md5=5d15452a4d460cfa464e8c8a3814bdd0,2018,7/20/21 15:48,7/20/21 15:48,303
QYLXBZ8F,journalArticle,2020,"Wang, Q.; Hao, Y.; Cao, J.",ADRL: An attention-based deep reinforcement learning framework for knowledge graph reasoning,1,,,"Knowledge graph reasoning is one of the key technologies for knowledge graph construction, which plays an important part in application scenarios such as vertical search and intelligent question answering. It is intended to infer the desired entity from the entities and relations that already exist in the knowledge graph. Most current methods for reasoning, such as embedding-based methods, globally embed all entities and relations, and then use the similarity of vectors to infer relations between entities or whether given triples are true. However, in real application scenarios, we require a clear and interpretable target entity as the output answer. In this paper, we propose a novel attention-based deep reinforcement learning framework (ADRL) for learning multi-hop relational paths, which improves the efficiency, generalization capacity, and interpretability of conventional approaches through the structured perception of deep learning and relational reasoning of reinforcement learning. We define the entire process of reasoning as a Markov decision process. First, we employ CNN to map the knowledge graph to a low-dimensional space, and a message-passing mechanism to sense neighbor entities at each level, and then employ LSTM to memorize and generate a sequence of historical trajectories to form a policy and value functions. We design a relational module that includes a self-attention mechanism that can infer and share the weights of neighborhood entity vectors and relation vectors. Finally, we employ the actor–critic algorithm to optimize the entire framework. Experiments confirm the effectiveness and efficiency of our method on several benchmark data sets. © 2020 Elsevier B.V.",Knowledge-Based Systems,10.1016/j.knosys.2020.105910,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083306400&doi=10.1016%2fj.knosys.2020.105910&partnerID=40&md5=de8d6ab87c63ac28eca6420214134478,2020,7/20/21 15:48,7/20/21 15:48,309
3K5G87V9,journalArticle,2019,"Aksjonov, A.; Nedoma, P.; Vodovozov, V.; Petlenkov, E.; Herrmann, M.",Detection and Evaluation of Driver Distraction Using Machine Learning and Fuzzy Logic,1,,fuzzy logic;traffic,"In addition to vehicle control, drivers often perform secondary tasks that impede driving. Reduction of driver distraction is an important challenge for the safety of intelligent transportation systems. In this paper, a methodology for the detection and evaluation of driver distraction while performing secondary tasks is described and an appropriate hardware and a software environment is offered and studied. The system includes a model of normal driving, a subsystem for measuring the errors from the secondary tasks, and a module for total distraction evaluation. A new machine learning algorithm defines driver performance in lane keeping and speed maintenance on a specific road segment. To recognize the errors, a method is proposed, which compares normal driving parameters with ones obtained while conducting a secondary task. To evaluate distraction, an effective fuzzy logic algorithm is used. To verify the proposed approach, a case study with driver-in-the-loop experiments was carried out, in which participants performed the secondary task, namely chatting on a cell phone. The results presented in this research confirm its capability to detect and to precisely measure a level of abnormal driver performance. © 2000-2011 IEEE.",IEEE Transactions on Intelligent Transportation Systems,10.1109/TITS.2018.2857222,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052713176&doi=10.1109%2fTITS.2018.2857222&partnerID=40&md5=c5630d202c132675d2f290df4bf9f68d,2019,7/20/21 15:48,7/20/21 15:48,310
2AVPZCMD,journalArticle,2021,"Lavanya, P.G.; Kouser, K.; Suresha, M.",Effective feature representation using symbolic approach for classification and clustering of big data,1,,ensemble methods,"The tremendous growth in the technology has led to the accumulation of enormous Big Data. Techniques that efficiently analyse this Big Data are in great demand. Tweets from Social media and Sensor data are some of the most common forms of Big Data. Machine learning algorithms pave way for researchers to analyze Big Data. Most Machine learning algorithms depend on efficient feature extraction and feature selection for its success. Here, we explore feature selection methods like entropy and Rough set on the sensor data. Also a symbolic approach of feature extraction is proposed which represents both sensor and twitter data efficiently for further data analysis. Some popular classifiers like Naïve Bayes, K Nearest Neighbour, Support Vector Machine and Decision Tree are used for validating the efficacy of the features selected. An ensemble classifier technique is also proposed which is compared with various state of the art ensemble classifiers. Symbolic features perform better than both entropy and Rough set features for sensor data and improves the clustering efficiency of twitter data. The proposed ensemble weighted average classifier on Symbolic features outperform all the other ensemble classifiers and independent classifiers. The results obtained from these methods have the potential to aid the public health surveillance. © 2021 Elsevier Ltd",Expert Systems with Applications,10.1016/j.eswa.2021.114658,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101876907&doi=10.1016%2fj.eswa.2021.114658&partnerID=40&md5=943364f5d7bd95abf15c4aee8f20c833,2021,7/20/21 15:48,7/20/21 15:48,322
3SUBVMMD,journalArticle,2020,"Xu, X.; Zhao, Z.; Xu, X.; Yang, J.; Chang, L.; Yan, X.; Wang, G.",Machine learning-based wear fault diagnosis for marine diesel engine by fusing multiple data-driven models,1,,ensemble methods,"Wear fault is one of the dominant causes for marine diesel engine damage which significantly influences ship safety. By taking full advantage of the data generated in engine operation, machine learning-based wear fault diagnostic model can help engineers to determine fault modes correctly and take quick action to avoid severe accidents. To identify wear faults more accurately, a multi-model fusion system based on evidential reasoning (ER) rule is proposed in this paper. The outputs of three data-driven models including an artificial neural network (ANN) model, a belief rule-based inference (BRB) model, and an ER rule model are used as pieces of evidence to be fused in decision level. In this paper, the fusion system defines reliability and importance weight of every single model respectively. A novel method is presented to determine the reliability of evidence by considering the accuracy and stability of every single model. The importance weight is optimized by genetic algorithm to improve the performance of the fusion system. The proposed machine learning-based diagnostic system is validated by a set of real samples acquired from marine diesel engines in operation. The test results show that the system is more accurate and robust, and the fault tolerant ability is improved remarkably compared with every single data-driven diagnostic model. © 2019 Elsevier B.V.",Knowledge-Based Systems,10.1016/j.knosys.2019.105324,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076531207&doi=10.1016%2fj.knosys.2019.105324&partnerID=40&md5=d49791bc6050625c3f226fad9430dbe9,2020,7/20/21 15:48,7/20/21 15:48,323
J5WFD34E,journalArticle,2021,"Sharma, A.; Kumar, H.; Mittal, K.; Kauhsal, S.; Kaushal, M.; Gupta, D.; Narula, A.",IoT and deep learning-inspired multi-model framework for monitoring Active Fire Locations in Agricultural Activities,1,,fuzzy logic,"This paper proposes an Internet of Things (IoT) and deep learning-inspired multi-model system for detection, dissemination, and monitoring of Active Fire Locations(AFL) in agricultural activities. The IoT module of the proposed system works on the fusion of IoT sensors-based detectors and deep learning-based detectors. Fuzzy logic is used for the fusion of various sensors and providing real-time detection and location of AFL. The deep learning detector implements IP camera-based MobilenetV2 architecture for accurate and long-distance detections trained on a novel self-created dataset. The proposed framework also provides a software module for monitoring and tracking of various AFL. The software comes with several features like automatic extraction of fire locations from remote sensing sites, assigning active fire locations to multiple stakeholders, extracting farmers' names indulged in burning, automatic sending a notification to government agencies, and provisions for citizens centric participation. The results of the proposed framework are quite encouraging. © 2021 Elsevier Ltd",Computers and Electrical Engineering,10.1016/j.compeleceng.2021.107216,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107976046&doi=10.1016%2fj.compeleceng.2021.107216&partnerID=40&md5=33486322da8964ad0eeae9023fed6fc1,2021,7/20/21 15:48,7/20/21 15:48,327
TZXBCWPB,journalArticle,2019,"Liu, J.; Patwary, M.J.A.; Sun, X.Y.; Tao, K.",An experimental study on symbolic extreme learning machine,1,,,"With the advent of big data era, the volume and complexity of data have increased exponentially and the type of data has also been increased largely. Among all different types of data, symbolic data plays an important role in the study on machine learning model. It has been proved that feed-forward neural network (FNN) has a good ability to deal with numeric data but relatively clumsy with symbolic data. In this paper, a special type of FNN called Extreme Learning Machine (ELM) is discussed for handling symbolic data. Experimental results demonstrate that, unlike traditional back propagation based FNN, ELM has a better performance in comparison with C4.5 which is generally acknowledged as one of the best algorithms in handling symbolic data classification problems. In this performance comparison, some key evaluation criteria such as generalization ability, time complexity, the effect of training sample size and noise-resistance ability are taken into account. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.",International Journal of Machine Learning and Cybernetics,10.1007/s13042-018-0872-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063261700&doi=10.1007%2fs13042-018-0872-z&partnerID=40&md5=2082789c78f434157582551c55a503c0,2019,7/20/21 15:48,7/20/21 15:48,331
75XE98GS,journalArticle,2016,"He, H.; Li, Z.; Yao, C.; Zhang, W.",Sentiment classification technology based on Markov logic networks,1,,text,"With diverse online media emerging, there is a growing concern of sentiment classification problem. At present, text sentiment classification mainly utilizes supervised machine learning methods, which feature certain domain dependency. On the basis of Markov logic networks (MLNs), this study proposed a cross-domain multi-task text sentiment classification method rooted in transfer learning. Through many-to-one knowledge transfer, labeled text sentiment classification, knowledge was successfully transferred into other domains, and the precision of the sentiment classification analysis in the text tendency domain was improved. The experimental results revealed the following: (1) the model based on a MLN demonstrated higher precision than the single individual learning plan model. (2) Multi-task transfer learning based on Markov logical networks could acquire more knowledge than self-domain learning. The cross-domain text sentiment classification model could significantly improve the precision and efficiency of text sentiment classification. © 2016 Informa UK Limited, trading as Taylor & Francis Group.",New Review of Hypermedia and Multimedia,10.1080/13614568.2016.1152317,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962439030&doi=10.1080%2f13614568.2016.1152317&partnerID=40&md5=fb7daee053c2a45eb0c723674641c8d7,2016,7/20/21 15:48,7/20/21 15:48,336
DCSICCZN,journalArticle,2021,"Krishnamurthy, P.; Khorrami, F.; Schmidt, S.; Wright, K.",Machine Learning for NetFlow Anomaly Detection with Human-Readable Annotations,1,,,"We propose a framework for anomaly detection in communication network logs along with automated extraction of human-readable annotations that explain the decision logic underlying each anomaly detection. For this purpose, we develop a machine learning methodology formulated in terms of a model comprised of an OR-combination of multiple Boolean logic based sentences. Each sentence is an empirically learned set of inequality conditions involving subsets of features. The feature set, which comprises the &#x201C;alphabet&#x201D; for human-readable annotations, is constructed using dynamic graph based spatio-temporal aggregation to extract human-understandable aggregates of network activity. These aggregates are constructed both in terms of computers (nodes in dynamic graph) and communications between computers (edges in dynamic graph). From the alphabet, the learned model identifies subsets of features that relate to each anomaly type and the combinations of conditions in terms of the feature subsets for detection of the specific anomaly type. Given a data point that the learned model detects as anomalous, the model identifies the specific features and their combinations related to the anomaly detection. These human-readable annotations provide a cyber-security analyst a transparent view into the decision logic underlying an anomaly detection. IEEE",IEEE Transactions on Network and Service Management,10.1109/TNSM.2021.3075656,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105104085&doi=10.1109%2fTNSM.2021.3075656&partnerID=40&md5=df79de107d445daf352fe15ed0f51a9b,2021,7/20/21 15:48,7/20/21 15:48,342
QGS93Z7F,journalArticle,2017,"Teso, S.; Sebastiani, R.; Passerini, A.",Structured learning modulo theories,1,,,"Modeling problems containing a mixture of Boolean and numerical variables is a long-standing interest of Artificial Intelligence. However, performing inference and learning in hybrid domains is a particularly daunting task. The ability to model these kinds of domains is crucial in “learning to design” tasks, that is, learning applications where the goal is to learn from examples how to perform automatic de novo design of novel objects. In this paper we present Structured Learning Modulo Theories, a max-margin approach for learning in hybrid domains based on Satisfiability Modulo Theories, which allows to combine Boolean reasoning and optimization over continuous linear arithmetical constraints. The main idea is to leverage a state-of-the-art generalized Satisfiability Modulo Theory solver for implementing the inference and separation oracles of Structured Output SVMs. We validate our method on artificial and real world scenarios. © 2015 Elsevier B.V.",Artificial Intelligence,10.1016/j.artint.2015.04.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931088104&doi=10.1016%2fj.artint.2015.04.002&partnerID=40&md5=0270b4c5e5e5fc46bb81a574166dbe24,2017,7/20/21 15:48,7/20/21 15:48,343
VYX2CHG3,journalArticle,2021,"Yao, S.; Yang, J.-B.; Xu, D.-L.",A probabilistic modeling approach for interpretable data inference and classification,1,,,"In this paper, we propose a new probabilistic modeling approach for interpretable inference and classification using the maximum likelihood evidential reasoning (MAKER) framework. This approach integrates statistical analysis, hybrid evidence combination and belief rule-based (BRB) inference, and machine learning. Statistical analysis is used to acquire evidence from data. The BRB inference is applied to analyze the relationship between system inputs and outputs. An interdependence index is used to quantify the interdependence between input variables. An adapted genetic algorithm is applied to train the models. The model established by the approach features a unique strong interpretability, which is reflected in three aspects: (1) interpretable evidence acquisition, (2) interpretable inference mechanism, and (3) interpretable parameters determination. The MAKER-based model is shown to be a competitive classifier for the Banana, Haberman's survival, and Iris data set, and generally performs better than other interpretable classifiers, e.g., complex tree, logistic regression, and naive Bayes. © 2021-IOS Press. All rights reserved.",Journal of Intelligent and Fuzzy Systems,10.3233/JIFS-201833,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102410623&doi=10.3233%2fJIFS-201833&partnerID=40&md5=e9545048288ae262c38b031cf4128e19,2021,7/20/21 15:48,7/20/21 15:48,351
3YFVRRKE,journalArticle,2020,"Gong, J.; Ma, H.; Teng, Z.; Teng, Q.; Zhang, H.; Du, L.; Chen, S.; Bhuiyan, M.Z.A.; Li, J.; Liu, M.",Hierarchical Graph Transformer-Based Deep Learning Model for Large-Scale Multi-Label Text Classification,1,,text,"Traditional methods of multi-label text classification, particularly deep learning, have achieved remarkable results. However, most of these methods use word2vec technology to represent sequential text information, while ignoring the logic and internal hierarchy of the text itself. Although these approaches can learn the hypothetical hierarchy and logic of the text, it is unexplained. In addition, the traditional approach treats labels as independent individuals and ignores the relationships between them, which not only does not reflect reality but also causes significant loss of semantic information. In this paper, we propose a novel Hierarchical Graph Transformer based deep learning model for large-scale multi-label text classification. We first model the text into a graph structure that can embody the different semantics of the text and the connections between them. We then use a multi-layer transformer structure with a multi-head attention mechanism at the word, sentence, and graph levels to fully capture the features of the text and observe the importance of the separate parts. Finally, we use the hierarchical relationship of the labels to generate the representation of the labels, and design a weighted loss function based on the semantic distances of the labels. Extensive experiments conducted on three benchmark datasets demonstrated that the proposed model can realistically capture the hierarchy and logic of text and improve performance compared with the state-of-the-art methods. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2020.2972751,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081058031&doi=10.1109%2fACCESS.2020.2972751&partnerID=40&md5=1376cf7721ed6ff3f046f7ca9e9b4415,2020,7/20/21 15:48,7/20/21 15:48,363
PXG38ZQ6,journalArticle,2018,"Krykunov, M.; Woo, T.K.",Bond Type Restricted Property Weighted Radial Distribution Functions for Accurate Machine Learning Prediction of Atomization Energies,1,,,"Understanding the performance of machine learning algorithms is essential for designing more accurate and efficient statistical models. It is not always possible to unravel the reasoning of neural networks. Here, we propose a method for calculating machine learning kernels in closed and analytic form by combining atomic property weighted radial distribution function (AP-RDF) descriptor with a Gaussian kernel. This allowed us to analyze and improve the performance of the Bag-of-Bonds descriptor when the bond type restriction is included in AP-RDF. The improvement is achieved for the prediction of molecular atomization energies (MAE = 1.7 kcal/mol for QM7 data set) and is due to the incorporation of a tensor product into the kernel, which captures the multidimensional representation of the AP-RDF. On the other hand, the numerical version of the AP-RDF is a constant size descriptor, making it more computationally efficient than Bag-of-Bonds. We have also discussed a connection between molecular quantum similarity and machine learning kernels with first-principles kinds of descriptors. © 2018 American Chemical Society.",Journal of Chemical Theory and Computation,10.1021/acs.jctc.8b00788,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053564109&doi=10.1021%2facs.jctc.8b00788&partnerID=40&md5=2cbd09df3dbfdc3a397b3d1f48f9ce0c,2018,7/20/21 15:48,7/20/21 15:48,365
6FRUK6MX,journalArticle,2019,"Nilashi, M.; Yadegaridehkordi, E.; Ibrahim, O.; Samad, S.; Ahani, A.; Sanzogni, L.",Analysis of Travellers’ Online Reviews in Social Networking Sites Using Fuzzy Logic Approach,1,,text,"Social media and digital technology have had significant contributions and impacts on the hospitality and accommodation businesses. Online traveller reviews have been rich sources of information for the traveller’s decision-making process in social media websites. TripAdvisor, a popular travel review site and social media platform, is mainly developed as a free business consultation service to help the travellers to make right decisions in their trips. The aim of this research is to use the multi-criteria ratings provided by the travellers in social media networking sites for developing a new recommender system for hotel recommendations in e-tourism platforms. We extend the crisp-based multi-criteria algorithms to fuzzy-based multi-criteria algorithms for finding the similarities between the travellers based on their provided ratings. To develop the recommendation method, we use clustering and prediction machine learning techniques. We evaluate the recommendation system on TripAdvisor data. Our experiments confirm that the use of clustering and prediction machine learning with the aid of fuzzy-based recommendation algorithms can significantly improve the quality of recommendations in tourism domain. © 2019, Taiwan Fuzzy Systems Association.",International Journal of Fuzzy Systems,10.1007/s40815-019-00630-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068769615&doi=10.1007%2fs40815-019-00630-0&partnerID=40&md5=62412649e9ffa2b4f2168abd40a0cda3,2019,7/20/21 15:48,7/20/21 15:48,372
RVGS5W42,journalArticle,2018,"Abdolrazzaghi, M.; Hashemy, S.; Abdolali, A.","Fast-forward solver for inhomogeneous media using machine learning methods: artificial neural network, support vector machine and fuzzy logic",1,,fuzzy logic,"Encountering with a nonlinear second-order differential equation including ϵr and μr spatial distributions, while computing the fields inside inhomogeneous media, persuaded us to find their known distributions that give exact solutions. Similarities between random distributions of electric properties and known functions lead us to estimate them using three mathematical tools of artificial neural networks (ANNs), support vector machines (SVMs) and Fuzzy Logic (FL). Assigning known functions after fitting with minimum error to arbitrary inputs using results of machine learning networks leads to achieve an approximate solution for the field inside materials considering boundary conditions. A comparative study between the methods according to the complexity of the structures as well as the accuracy and the calculation time for testing of unforeseen inputs, including classification, prediction and regression is presented. We examined the extracted pairs of ϵr and μr with ANN, SVM networks and FL and got satisfactory outputs with detailed results. The application of the presented method in zero reflection subjects is exemplified. © 2016, The Natural Computing Applications Forum.",Neural Computing and Applications,10.1007/s00521-016-2694-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995466550&doi=10.1007%2fs00521-016-2694-9&partnerID=40&md5=6ada5d9b33055614f29963c8e89df48e,2018,7/20/21 15:48,7/20/21 15:48,377
TXRTAFYY,journalArticle,2020,"Le, D.V.-K.; Chen, Z.; Wong, Y.W.; Isa, D.",A complete online-SVM pipeline for case-based reasoning system: a study on pipe defect detection system,1,,cbr,"Recent developments in case-based reasoning system (CBR) have led to an interest in favoring machine learning (ML) approaches as a replacement for traditional weighted distance methods. However, valuable information obtained through a training process was relinquished as transferring to other phases. This paper proposed a complete pipeline integration of CBR using kernel method designated with support vector machine (SVM) as the main engine. Since the system requires learning SVM model to be invoked in every phase, the online learning mechanism is nominated to effectively update the model when a new case adjoins. The proposed full SVM-CBR integration has been successfully built into a pipe defect detection. The achieved result indicates a substantial improvement by transferring learning information accurately. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.",Soft Computing,10.1007/s00500-020-04985-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084590066&doi=10.1007%2fs00500-020-04985-7&partnerID=40&md5=b08e9b16d8c025deb517179f68c582ae,2020,7/20/21 15:48,7/20/21 15:48,380
WET9CYNX,journalArticle,2021,"Chan, A.; Ma, L.; Juefei-Xu, F.; Ong, Y.; Xie, X.; Xue, M.; Liu, Y.",Breaking Neural Reasoning Architectures With Metamorphic Relation-Based Adversarial Examples,1,,text,"The ability to read, reason, and infer lies at the heart of neural reasoning architectures. After all, the ability to perform logical reasoning over language remains a coveted goal of Artificial Intelligence. To this end, models such as the Turing-complete differentiable neural computer (DNC) boast of real logical reasoning capabilities, along with the ability to reason beyond simple surface-level matching. In this brief, we propose the first probe into DNC's logical reasoning capabilities with a focus on text-based question answering (QA). More concretely, we propose a conceptually simple but effective adversarial attack based on metamorphic relations. Our proposed adversarial attack reduces DNCs' state-of-the-art accuracy from 100&#x0025; to 1.5&#x0025; in the worst case, exposing weaknesses and susceptibilities in modern neural reasoning architectures. We further empirically explore possibilities to defend against such attacks and demonstrate the utility of our adversarial framework as a simple scalable method to improve model adversarial robustness. IEEE",IEEE Transactions on Neural Networks and Learning Systems,10.1109/TNNLS.2021.3072166,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104646646&doi=10.1109%2fTNNLS.2021.3072166&partnerID=40&md5=952b39e75bd116821832ef81f66fa36c,2021,7/20/21 15:48,7/20/21 15:48,381
EYV3YM7J,journalArticle,2020,"Finotti Amaral, R.P.; Menezes, I.F.M.; Ribeiro, M.V.",An extension of the type-1 and singleton fuzzy logic system trained by scaled conjugate gradient methods for multiclass classification problems,1,,,"This paper proposes an extension of the type-1 and singleton fuzzy logic system for dealing with multiclass classification problems. The proposed extension enables a fuzzy classifier to generate more than one output, thereby avoiding the use of binary decomposition strategies when multiclass classification problems are considered. Additionally, with the goal of improving classifier performance, the scaled conjugate gradient training method was applied, as well as its modified version using the differential operator R·. The effectiveness of the proposed extension was evaluated using data from the UCI Machine Learning Repository based on well-established classification metrics. The numerical results reveal a significant reduction in computational complexity when using the proposed extension compared to the traditional decomposition strategy, as well as improved convergence speed when using the scaled conjugate gradient training method. © 2020 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2020.05.052,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087275063&doi=10.1016%2fj.neucom.2020.05.052&partnerID=40&md5=a0330cf3f07a51d22ea56f195abfd81e,2020,7/20/21 15:48,7/20/21 15:48,382
V3J6IF6I,journalArticle,2018,"Troiano, L.; Villa, E.M.; Loia, V.",Replicating a Trading Strategy by Means of LSTM for Financial Industry Applications,1,,,"This paper investigates the possibility of learning a trading rule looking at the relationship between market indicators and decisions undertaken regarding entering or quitting a position. As means to achieve this objective, we employ a long short-term memory machine, due its capability to relate past and recent events. Our solution is a first step in the direction of building a model-free robot, based on deep learning, able to identify the logic that links the market mood given by technical indicators to the undertaken investment decisions. Although preliminary, experimental results show that the proposed solution is viable and promising. © 2005-2012 IEEE.",IEEE Transactions on Industrial Informatics,10.1109/TII.2018.2811377,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042883444&doi=10.1109%2fTII.2018.2811377&partnerID=40&md5=fb0f6a260e8cba87f6e016c58dd7b546,2018,7/20/21 15:48,7/20/21 15:48,388
RKWLKKSY,journalArticle,2020,"Al-Hmouz, R.; Pedrycz, W.; Balamash, A.; Morfeq, A.",Logic -oriented autoencoders and granular logic autoencoders: Developing interpretable data representation,1,,,"The plethora of ways of data representation and their applications to system modeling is inherently associated with dimensionality reduction. In a nutshell, the result of dimensionality reduction should support efficient ways of constructing ensuing models (classifiers, predictors) as well as an interpretation of the data themselves. Furthermore, there should be a suitable measure quantifying the quality of data positioned in the reduced space. We advocate that what makes the reduced data interpretable, goes hand in hand with revealing a logic fabric of the data, suppressing redundancy, and finally arriving at a logic description of data. The anticipation is that the reduced data can be described in the form of logic expressions formed over the original highly dimensional data. Evidently, having these above stated points in mind, the aim of this study is two-fold: (i) to develop a logic-oriented data representation, and (ii) to quantify the quality of results of dimensionality reduction by incorporating a facet of information granularity. In other words, we argue that the result of dimensionality reduction gives rise to information granules whose level of granularity associates with the quality of processing completed by the autoencoder. In light of the recent surge of architectures of deep learning, the study is focused on the construction and analysis of logic-oriented autoencoders. We propose a two-level architecture composed of the logic-oriented processing units (and processing carried out at the first layer of the autoencoder) followed by the or processing completed at the second layer. As data representation provided by the autoencoder is not ideal, we augment the original architecture by granular parameters which give rise to granular logic-oriented autoencoders. A suite of experiments is also reported. IEEE",IEEE Transactions on Fuzzy Systems,10.1109/TFUZZ.2020.3043659,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097924201&doi=10.1109%2fTFUZZ.2020.3043659&partnerID=40&md5=28d358ebb5c92eb30cfccf9bf4a9c2d4,2020,7/20/21 15:48,7/20/21 15:48,395
GW9R9ULR,journalArticle,2014,"Augello, A.; Gentile, M.; Pilato, G.; Vassallo, G.",A geometric algebra based distributional model to encode sentences semantics,1,,text,"Word space models are used to encode the semantics of natural language elements by means of high dimensional vectors [23]. Latent Semantic Analysis (LSA) methodology [15] is well known and widely used for its generalization properties. Despite of its good performance in several applications, the model induced by LSA ignores dynamic changes in sentences meaning that depend on the order of the words, because it is based on a bag of words analysis. In this chapter we present a technique that exploits LSA-based semantic spaces and geometric algebra in order to obtain a sub-symbolic encoding of sentences taking into account the words sequence in the sentence. © 2014 Springer-Verlag Berlin Heidelberg.",Studies in Computational Intelligence,10.1007/978-3-642-40621-8_6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958552873&doi=10.1007%2f978-3-642-40621-8_6&partnerID=40&md5=7d9827fbd99a335fb2f3cc34a59a36e4,2014,7/20/21 15:48,7/20/21 15:48,398
KF7JL3EM,journalArticle,2013,"Campos, J.; Lopez-Sanchez, M.; Salamó, M.; Avila, P.; Rodríguez-Aguilar, J.A.",Robust regulation adaptation in multi-agent systems,1,,multiagent system,"Adaptive organisation-centred multi-agent systems can dynamically modify their organisational components to better accomplish their goals. Our research line proposes an abstract distributed architecture (2- LAMA) to endow an organisation with adaptation capabilities. This article focuses on regulation-adaptation based on a machine learning approach, in which adaptation is learned by applying a tailored case-based reasoning method. We evaluate the robustness of the system when it is populated by non compliant agents. The evaluation is performed in a peer-to-peer sharing network scenario. Results show that our proposal significantly improves system performance and can cope with regulation violators without incorporating any specific regulation-compliance enforcement mechanisms. © 2013 ACM.",ACM Transactions on Autonomous and Adaptive Systems,10.1145/2517328,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885593556&doi=10.1145%2f2517328&partnerID=40&md5=ff7606af03fee32dd5be00fae8476b92,2013,7/20/21 15:48,7/20/21 15:48,403
UUMM6HWA,journalArticle,2020,"Wei, X.; Du, J.; Xue, Z.; Liang, M.; Geng, Y.; Xu, X.; Lee, J.",A very deep two-stream network for crowd type recognition,1,,,"Crowd type identification is a crucial task in the emergency alert. In this paper, to solve accurate identification of crowd type, the crowd type description triad C-BMO < Behavior, Mood, Organized > and a novel crowd type recognition network (CTRN): very deep two-stream network architecture are proposed, respectively. The very deep two-stream network architecture is based on the static map and motion map in the video. To early warn the emergency, the reasoning rules of the emergency alert are proposed based on joining the crowd type and the crowd characteristics. To verify the proposed method, the crowd type dataset is collected, and we experiment with the proposed plan on the crowd type dataset. The experimental results demonstrate that the proposed model is competitive compared with the state-of-the-art techniques. © 2019",Neurocomputing,10.1016/j.neucom.2018.10.106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085867931&doi=10.1016%2fj.neucom.2018.10.106&partnerID=40&md5=8dbc5ed9f579a11128d4512cd211e922,2020,7/20/21 15:48,7/20/21 15:48,407
9CU6G7II,journalArticle,2018,"Green, N.L.",Towards mining scientific discourse using argumentation schemes,1,,text,"The dominant approach to argument mining has been to treat it as a machine learning problem based upon superficial text features, and to treat the relationships between arguments as either support or attack. However, accurately summarizing argumentation in scientific research articles requires a deeper understanding of the text and a richer model of relationships between arguments. First, this paper presents an argumentation scheme-based approach to mining a class of biomedical research articles. Argumentation schemes implemented as logic programs are formulated in terms of semantic predicates that could be obtained from a text by use of biomedical/biological natural language processing tools. The logic programs can be used to extract the underlying scheme name, premises, and implicit or explicit conclusion of an argument. Then this paper explores how arguments in a research article occur within a narrative of scientific discovery, how they are related to each other, and some implications. © 2018-IOS Press and the authors.",Argument and Computation,10.3233/AAC-180038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050853497&doi=10.3233%2fAAC-180038&partnerID=40&md5=d4c468c9dff9ce956cf3fe69aa0f609a,2018,7/20/21 15:48,7/20/21 15:48,410
N5RLUPDA,journalArticle,2020,"Yeganejou, M.; Dick, S.; Miller, J.",Interpretable Deep Convolutional Fuzzy Classifier,1,,,"While deep learning has proven to be a powerful new tool for modeling and predicting a wide variety of complex phenomena, those models remain incomprehensible black boxes. This is a critical impediment to the widespread deployment of deep learning technology, as decades of research have found that users simply will not trust (i.e., make decisions based on) a model whose solutions cannot be explained. Fuzzy systems, on the other hand, are by design much more easily understood. In this article, we propose to create more comprehensible deep networks by hybridizing them with fuzzy logic. Our proposed architecture first employs a convolutional neural network as an automated feature extractor and then performs a fuzzy clustering in the derived feature space. After hardening the clusters, we employ Rocchio's algorithm to classify the data points. Experiments on three datasets show that the automated feature extraction substantially improves the accuracy of the fuzzy classifier, and while the substitution of a fuzzy classifier slightly decreases the network's performance, we are able to introduce an effective interpretation mechanism. © 1993-2012 IEEE.",IEEE Transactions on Fuzzy Systems,10.1109/TFUZZ.2019.2946520,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087900786&doi=10.1109%2fTFUZZ.2019.2946520&partnerID=40&md5=9a0582ffbeac8d5e8a50ca29447b04f3,2020,7/20/21 15:48,7/20/21 15:48,429
LF34PFXG,journalArticle,2021,"Maldonado, S.; López, J.; Vairetti, C.",Time-weighted Fuzzy Support Vector Machines for classification in changing environments,1,,fuzzy logic,"The predictive performance of classification methods relies heavily on the nature of the environment, as in the joint distribution of inputs and outputs may evolve over time. This issue is known as dataset shift. Given that most statistical and machine learning techniques assume that the training sample is drawn from the same distribution as the test data used for evaluation, an appreciable amount of researchers and practitioners tend to ignore this issue at the model construction stage. In this paper, we propose a novel Fuzzy Support Vector Machine strategy, in which the traditional hinge loss function is redefined to account for dataset shift. Additionally, we propose a general version of this loss function applying aggregation operators in order to improve performance by dealing with dataset shift via fuzzy logic. Originally developed as linear approaches, our proposals are extended to kernel-based classification for non-linear machine learning. Our methods are able to perform best compared to traditional classifiers in terms of out-of-time prediction using simulated and real-world dataset for credit scoring, confirming the theoretical virtues of our approach. © 2021 Elsevier Inc.",Information Sciences,10.1016/j.ins.2021.01.070,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100733859&doi=10.1016%2fj.ins.2021.01.070&partnerID=40&md5=7a3f3f3f7f119b0e944d7d5934354b4e,2021,7/20/21 15:48,7/20/21 15:48,454
C95BG4IA,journalArticle,2019,"Zhu, W.; Wu, H.; Deng, M.",LTL model checking based on binary classification of machine learning,1,,,"Linear Temporal Logic (LTL) Model Checking (MC) has been applied to many fields. However, the state explosion problem and the exponentially computational complexity restrict the further applications of LTL model checking. A lot of approaches have been presented to address these problems. And they work well. However, the essential issue has not been resolved due to the limitation of inherent complexity of the problem. As a result, the running time of LTL model checking algorithms will be inacceptable if a LTL formula is too long. To this end, this study tries to seek an acceptable approximate solution for LTL model checking by introducing the Machine Learning (ML) technique. And a method for predicting LTL model checking results is proposed, using the several ML algorithms including Boosted Tree (BT), Random Forest (RF), Decision tree (DT) or Logistic Regression (LR), respectively. First, for a number of Kripke structures and LTL formulas, a data set A containing model checking results is obtained, using one of the existing LTL model checking algorithm. Second, the LTL model checking problem can be induced to a binary classification problem of machine learning. In other words, some records in A form a training set for the given machine learning algorithm, where formulas and kripke structures are the two features, and model checking results are the one label. On the basis of it, a ML model M is obtained to predict the results of LTL model checking. As a result, an approximate LTL model checking technique occurs. The experiments show that the new method has the similar max accuracy with the state of the art algorithm in the classical LTL model checking technique, while the average efficiency of the former method is at most 6.3 million times higher than that of the latter algorithms, if the length of each of LTL formulas equals to 500. These results indicate that the new method can quickly and accurately determine LTL model checking result for a given Kripke structure and a given long LTL formula, since the new method avoids the famous state explosion problem. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2019.2942762,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078271653&doi=10.1109%2fACCESS.2019.2942762&partnerID=40&md5=9d3bdda496ff3961f2f02bebbebef7d3,2019,7/20/21 15:48,7/20/21 15:48,466
93IZB3KL,journalArticle,2015,"Ontañón, S.; Meseguer, P.",Speeding up operations on feature terms using constraint programming and variable symmetry,1,,text,"Feature terms are a generalization of first-order terms which have recently received increased attention for their usefulness in structured machine learning, natural language processing and other artificial intelligence applications. One of the main obstacles for their wide usage is that, when set-valued features are allowed, their basic operations (subsumption, unification, and antiunification) have a very high computational cost. We present a Constraint Programming formulation of these operations, which in some cases provides orders of magnitude speed-ups with respect to the standard approaches. In addition, exploiting several symmetries - that often appear in feature terms databases - causes substantial additional savings. We provide experimental results of the benefits of this approach. © 2014 Elsevier B.V. All rights reserved.",Artificial Intelligence,10.1016/j.artint.2014.11.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920721203&doi=10.1016%2fj.artint.2014.11.010&partnerID=40&md5=c9f780913feed4eb3679397f94a0bae7,2015,7/20/21 15:48,7/20/21 15:48,475
VRF6UTTU,journalArticle,2016,"Gennari, R.; Vittorini, P.",Qualitative Temporal Reasoning Can Improve on Temporal Annotation Quality: How and Why,1,,text,"The analysis of time helps in extracting knowledge from web contents. In order to analyze massive amounts of data, current natural language processing systems rely mainly on supervised approaches: machine learning algorithms that learn how to classify data based on corpora, annotated with the TimeML mark-up language or one of its derivatives. The quality of annotation data, thus, affects the performances of such systems. Quality can be improved by reasoning on temporal annotations. This article takes such a view. After a review of the strictly necessary background, it focuses on and discusses open issues in the area of quality of temporal annotations: inconsistency and incompleteness of annotations. Then it proposes a semantic reasoning approach as solution for improving on their quality, viz., the SOA-based Qualitative Temporal Reasoner for reasoning about temporal annotations, which leverages on existing theories and tools for qualitative reasoning. The article presents the design of the reasoner and its two main reasoning services: consistency checking for tackling inconsistency, and deduction for addressing incompleteness on demand. Afterward, the paper presents an experimental evaluation of the reasoner, sustaining why the chosen semantic reasoning approach can help improve on quality of annotations. The experiment assesses the reasoner’s performances on two different corpora and from several perspectives, e.g., the effectiveness of consistency checking in terms of the number of inconsistent documents found, and of deduction in terms of the number of annotations added. It concludes with discussion of the results of the evaluation and possible routes for future work. © 2016 Taylor & Francis.",Applied Artificial Intelligence,10.1080/08839514.2016.1214360,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994029426&doi=10.1080%2f08839514.2016.1214360&partnerID=40&md5=d9fabb57bad43a4a046804cb6abfba37,2016,7/20/21 15:48,7/20/21 15:48,504
E79J9D2F,journalArticle,2019,"Alshammari, M.; Nasraoui, O.; Sanders, S.",Mining Semantic Knowledge Graphs to Add Explainability to Black Box Recommender Systems,1,,SW,"Recommender systems are being increasingly used to predict the preferences of users on online platforms and recommend relevant options that help them cope with information overload. In particular, modern model-based collaborative filtering algorithms, such as latent factor models, are considered state-of-the-art in recommendation systems. Unfortunately, these black box systems lack transparency, as they provide little information about the reasoning behind their predictions. White box systems, in contrast, can, by nature, easily generate explanations. However, their predictions are less accurate than sophisticated black box models. Recent research has demonstrated that explanations are an essential component in bringing the powerful predictions of big data and machine learning methods to a mass audience without compromising trust. Explanations can take a variety of formats, depending on the recommendation domain and the machine learning model used to make predictions. The objective of this work is to build a recommender system that can generate both accurate predictions and semantically rich explanations that justify the predictions. We propose a novel approach to build an explanation generation mechanism into a latent factor-based black box recommendation model. The designed model is trained to learn to make predictions that are accompanied by explanations that are automatically mined from the semantic web. Our evaluation experiments, which carefully study the trade-offs between the quality of predictions and explanations, show that our proposed approach succeeds in producing explainable predictions without a significant sacrifice in prediction accuracy. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2019.2934633,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079639757&doi=10.1109%2fACCESS.2019.2934633&partnerID=40&md5=11d0c29f3d6a70fe8a95c79b12006977,2019,7/20/21 15:49,7/20/21 15:49,527
343UXVIM,journalArticle,2017,"Lan, A.S.; Waters, A.E.; Studer, C.; Baraniuk, R.G.",BLAh: Boolean Logic Analysis for Graded Student Response Data,1,,text,"Machine learning (ML) models and algorithms can enable a personalized learning experience for students in an inexpensive and scalable manner. At the heart of ML-driven personalized learning is the automated analysis of student responses to assessment items. Existing statistical models for this task enable the estimation of student knowledge and question difficulty solely from graded response data with only minimal effort from instructors. However, most existing student-response models are generalized linear models, meaning that they characterize the probability that a student answers a question correctly through a linear combination of their knowledge and the question's difficulty with respect to each concept that is being assessed. Such models cannot characterize complicated, nonlinear student-response associations and, hence, lack human interpretability in practice. In this paper, we propose a nonlinear student-response model called Boolean logic analysis (BLAh) that models a student's binary-valued graded response to a question as the output of a Boolean logic function. We develop a Markov chain Monte Carlo inference algorithm that learns the Boolean logic functions for each question solely from graded response data. A refined BLAh model improves the identifiability, tractability, and interpretability by considering a restricted set of ordered Boolean logic functions. Experimental results on a variety of real-world educational datasets demonstrate that BLAh not only achieves best-in-class prediction performance on unobserved student responses on some datasets but also provides easily interpretable parameters when questions are tagged with metadata by domain experts, which can provide useful feedback to instructors and content designers to improve the quality of assessment items. © 2007-2012 IEEE.",IEEE Journal on Selected Topics in Signal Processing,10.1109/JSTSP.2017.2722419,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023194336&doi=10.1109%2fJSTSP.2017.2722419&partnerID=40&md5=e8c8997edcf476dfccae0ffdd5e8e727,2017,7/20/21 15:49,7/20/21 15:49,531
Y7Z4S598,journalArticle,2021,"Tiwari, P.; Zhu, H.; Pandey, H.M.",DAPath: Distance-aware knowledge graph reasoning based on deep reinforcement learning,1,,KG,"Knowledge graph reasoning aims to find reasoning paths for relations over incomplete knowledge graphs (KG). Prior works may not take into account that the rewards for each position (vertex in the graph) may be different. We propose the distance-aware reward in the reinforcement learning framework to assign different rewards for different positions. We observe that KG embeddings are learned from independent triples and therefore cannot fully cover the information described in the local neighborhood. To this effect, we integrate a graph self-attention (GSA) mechanism to capture more comprehensive entity information from the neighboring entities and relations. To let the model remember the path, we incorporate the GSA mechanism with GRU to consider the memory of relations in the path. Our approach can train the agent in one-pass, thus eliminating the pre-training or fine-tuning process, which significantly reduces the problem complexity. Experimental results demonstrate the effectiveness of our method. We found that our model can mine more balanced paths for each relation. © 2020 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2020.11.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097578405&doi=10.1016%2fj.neunet.2020.11.012&partnerID=40&md5=a2caa01cae010212d970d69a2c391266,2021,7/20/21 15:49,7/20/21 15:49,534
NPTZVV3I,journalArticle,2021,"Yan, R.; Yu, Y.; Qiu, D.",Emotion-enhanced classification based on fuzzy reasoning,1,,text,"Texts and emoticons expressing sentiment can be used to analyse emotion. In an Internet environment, emoticons are frequently used, which have explicated information for emotion analysis. Considering the characteristics of short texts including sparseness, non-standardization and ambiguities in a subject, two models based on word embedding, emotion-dictionary and fuzzy reasoning are proposed: the low-dimensional hybrid feature model and the emotion-enhanced inference model. The low-dimensional hybrid feature model includes the number of emoticons, the emotion-word number and the negative-word number in a text. The emotion-enhanced reference model includes some fuzzy reasoning rules and a variety of the combinations of emotion-words, negative-words, and question marks and exclamation points. The validity of the model has been verified based on Douyin reviews and the data of the 2nd CCF Conference on Natural Language Processing and Chinese Computing (NLPCC 2013), where the average accuracy rate on Douyin reviews achieved is 89.16 %. Through the comparative experiment, the results show that the models are more effective in ultra-short emotion text classification than the comparison models. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",International Journal of Machine Learning and Cybernetics,10.1007/s13042-021-01356-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108818937&doi=10.1007%2fs13042-021-01356-y&partnerID=40&md5=93fc1af8542cadcb177bf5887c64c4ff,2021,7/20/21 15:49,7/20/21 15:49,535
4AYRBJ85,journalArticle,2020,"Yirui, Z.; Jian, S.",Analysis of vibration high-frequency dynamic characteristics of wheelless rail vehicle system based on fuzzy logic control,1,,fuzzy logic;traffic,"Track irregularity is the main source of vibration excitation of vehicle-track weighing system, which has an important impact on the safety, stability and comfort of train operation, and it is also the main factor limiting the speed of train operation. Higher requirements are put forward for track smoothness with the rapid development of China's railways. Therefore, it has a great theoretical and practical significance to study the relationship between track irregularity and random vibration of vehicle-track cooker-in system and the evaluation method of track smoothness. In this paper, a model construction method is proposed based on machine learning fuzzy logic control and neural network algorithm to analyze the high frequency dynamic characteristics of ballastless track wheel-rail vehicle system. Firstly, a numerical analysis model of high frequency dynamic characteristics of ballastless track wheel-rail vehicle system is established by using linear discrete elastic-yellow damper element connection model; Secondly, the Rough Set Block Neural Network is introduced to optimize the dynamic characteristic analysis model, and the intelligent model of model optimization analysis is established. Finally, the validity of the proposed algorithm is verified by simulation experiments of practical examples. © 2020 - IOS Press and the authors. All rights reserved.",Journal of Intelligent and Fuzzy Systems,10.3233/JIFS-179920,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091075865&doi=10.3233%2fJIFS-179920&partnerID=40&md5=689c3c3b2818b751eebc9bed96725a53,2020,7/20/21 15:49,7/20/21 15:49,538
5A7944LD,journalArticle,2014,"Muggleton, S.",Alan turing and the development of artificial intelligence,1,,survey,"During the centennial year of his birth Alan Turing (1912-1954) has been widely celebrated as having laid the foundations for Computer Science, Automated Decryption, Systems Biology and the Turing Test. In this paper we investigate Turing's motivations and expectations for the development of Machine Intelligence, as expressed in his 1950 article in Mind. We show that many of the trends and developments within AI over the last 50 years were foreseen in this foundational paper. In particular, Turing not only describes the use of Computational Logic but also the necessity for the development of Machine Learning in order to achieve human-level AI within a 50 year time-frame. His description of the Child Machine (a machine which learns like an infant) dominates the closing section of the paper, in which he provides suggestions for how AI might be achieved. Turing discusses three alternative suggestions which can be characterised as: (1) AI by programming, (2) AI by ab initio machine learning and (3) AI using logic, probabilities, learning and background knowledge. He argues that there are inevitable limitations in the first two approaches and recommends the third as the most promising. We compare Turing's three alternatives to developments within AI, and conclude with a discussion of some of the unresolved challenges he posed within the paper. © 2014 - IOS Press and the authors.",AI Communications,10.3233/AIC-130579,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889667265&doi=10.3233%2fAIC-130579&partnerID=40&md5=8f35b384c0c2190c011f3749a71f29c8,2014,7/20/21 15:49,7/20/21 15:49,539
WDWYXV4W,journalArticle,2020,"Chakraborty, M.; Biswas, S.K.; Purkayastha, B.",Rule extraction from neural network trained using deep belief network and back propagation,1,,rule-extraction,"Representing the knowledge learned by neural networks in the form of interpretable rules is a prudent technique to justify the decisions made by neural networks. Heretofore many algorithms exist to extract symbolic rules from neural networks, but among them, a few extract rules from deep neural networks trained using deep learning techniques. So, this paper proposes an algorithm to extract rules from a multi-hidden layer neural network, pre-trained using deep belief network and fine-tuned using back propagation. The algorithm analyzes each node of a layer and extracts knowledge from each layer separately. The process of knowledge extraction from the first hidden layer is different from the other layers. Consecutively, the algorithm combines all the knowledge extracted and refines them to construct a final ruleset consisting of symbolic rules. The algorithm further subdivides the subspace of a rule in the ruleset if it satisfies certain conditions. Results show that the algorithm extracted rules with higher accuracy compared to some existing rule extraction algorithms. Other than accuracy, the efficacy of the extracted rules is also validated with fidelity and various other performance measures. © 2020, Springer-Verlag London Ltd., part of Springer Nature.",Knowledge and Information Systems,10.1007/s10115-020-01473-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085080273&doi=10.1007%2fs10115-020-01473-0&partnerID=40&md5=5fe2c035d5d7c117d36315294ca03069,2020,7/20/21 15:49,7/20/21 15:49,545
F82SSRUW,journalArticle,2016,"Panda, M.; Abraham, A.; Tripathy, B.K.",Soft granular computing based classification using hybrid fuzzy-KNN-SVM,1,,granular,"This paper aims at providing the concept of information granulation in Granular computing based pattern classification that is used to deal with incomplete, unreliable, uncertain knowledge from the view of a dataset. Data Discretization provides us the granules which further can be used to classify the instances. We use Equal width and Equal frequency Discretization as unsupervised ones; Fayyad-Irani's Minimum description length and Kononenko's supervised discretization approaches along with Fuzzy logic, neural network, Support vector machine and their hybrids to develop an efficient granular information processing paradigm. The experimental results show the effectiveness of our approach. We use benchmark datasets in UCI Machine Learning Repository in order to verify the performance of granular computing based approach in comparison with other existing approaches. Finally, we perform statistical significance test for confirming validity of the results obtained. © 2016 IOS Press and the authors. All rights reserved.",Intelligent Decision Technologies,10.3233/IDT-150243,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960844134&doi=10.3233%2fIDT-150243&partnerID=40&md5=144a1af2b7b1fa9981aecf8a29c273b8,2016,7/20/21 15:49,7/20/21 15:49,546
XWFGXQVI,journalArticle,2016,"Chang, J.W.; Lee, M.C.; Wang, T.I.",Integrating a semantic-based retrieval agent into case-based reasoning systems: A case study of an online bookstore,1,,text,"Natural language search engines should be developed to provide a friendly environment for business-to-consumer e-commerce that reduce the fatigue customers experience and help them decide what to buy. To support product information retrieval and reuse, this paper presents a novel framework for a case-based reasoning system that includes a collaborative filtering mechanism and a semantic-based case retrieval agent. Furthermore, the case retrieval agent integrates short-text semantic similarity (STSS) and recognizing textual entailment (RTE). The proposed approach was evaluated using competitive methods in the performance of STSS and RTE, and according to the results, the proposed approach outperforms most previously described approaches. Finally, the effectiveness of the proposed approach was investigated using a case study of an online bookstore, and according to the results of case study, the proposed approach outperforms a compared system using string similarity and an existing e-commerce system, Amazon. © 2015 Elsevier B.V. All rights reserved.",Computers in Industry,10.1016/j.compind.2015.10.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949948395&doi=10.1016%2fj.compind.2015.10.007&partnerID=40&md5=5d50ebbcb2986b1ddeb5d29317d902b8,2016,7/20/21 15:49,7/20/21 15:49,549
6D9FGR2F,journalArticle,2018,"Zhao, J.; Hei, X.; Shi, Z.; Dong, L.; Liu, Y.; Yan, R.; Li, X.",Regression learning based on incomplete relationships between attributes,1,,UNK,"In recent years, machine learning researchers have focused on methods to construct flexible and interpretable regression models. However, the method of obtaining complete knowledge from incomplete and fuzzy prior knowledge and the trade-off between the generalization performance and the interpretability of the model are very important factors to consider. In this paper, we propose a new regression learning method. Complete relationships are obtained from the incomplete fuzzy relationships between attributes by using Markov logic networks [29]. The complete relationships are then applied to constrain the shape of the regression model in the optimization procedure to solve the trade-off problem. Finally, the benefits of our approach are illustrated on benchmark data sets and in real-world experiments. © 2017 Elsevier Inc.",Information Sciences,10.1016/j.ins.2017.09.023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029445554&doi=10.1016%2fj.ins.2017.09.023&partnerID=40&md5=68bc8ba9680a10683af2b1ca642f64e4,2018,7/20/21 15:49,7/20/21 15:49,551
2KKWBRNS,journalArticle,2020,"Mežnar, S.; Lavrač, N.; Škrlj, B.",SNoRe: Scalable Unsupervised Learning of Symbolic Node Representations,1,,UNK,"Learning from complex real-life networks is a lively research area, with recent advances in learning information-rich, low-dimensional network node representations. However, state-of-the-art methods are not necessarily interpretable and are therefore not fully applicable to sensitive settings in biomedical or user profiling tasks, where explicit bias detection is highly relevant. The proposed SNoRe (Symbolic Node Representations) algorithm is capable of learning symbolic, human-understandable representations of individual network nodes, based on the similarity of neighborhood hashes which serve as features. SNoRe's interpretable features are suitable for direct explanation of individual predictions, which we demonstrate by coupling it with the widely used instance explanation tool SHAP to obtain nomograms representing the relevance of individual features for a given classification. To our knowledge, this is one of the first such attempts in a structural node embedding setting. In the experimental evaluation on eleven real-life datasets, SNoRe proved to be competitive to strong baselines, such as variational graph autoencoders, node2vec and LINE. The vectorized implementation of SNoRe scales to large networks, making it suitable for contemporary network learning and analysis tasks. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2020.3039541,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096825835&doi=10.1109%2fACCESS.2020.3039541&partnerID=40&md5=e8441cda5e249a2b1df7ec5142d27062,2020,7/20/21 15:49,7/20/21 15:49,568
TZB3DZY9,journalArticle,2019,"Westphal, P.; Bühmann, L.; Bin, S.; Jabeen, H.; Lehmann, J.",SML-Bench - A benchmarking framework for structured machine learning,1,,SW,"The availability of structured data has increased significantly over the past decade and several approaches to learn from structured data have been proposed. These logic-based, inductive learning methods are often conceptually similar, which would allow a comparison among them even if they stem from different research communities. However, so far no efforts were made to define an environment for running learning tasks on a variety of tools, covering multiple knowledge representation languages. With SML-Bench, we propose a benchmarking framework to run inductive learning tools from the ILP and semantic web communities on a selection of learning problems. In this paper, we present the foundations of SML-Bench, discuss the systematic selection of benchmarking datasets and learning problems, and showcase an actual benchmark run on the currently supported tools. © 2019 - IOS Press and the authors. All rights reserved.",Semantic Web,10.3233/SW-180308,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060949735&doi=10.3233%2fSW-180308&partnerID=40&md5=24363c13d83ab892a4fbe831c04e5afa,2019,7/20/21 15:49,7/20/21 15:49,574
K75C7DPI,journalArticle,2014,"Won, S.Y.; Lee, H.; Kim, T.",Ontology mediation approach using formal concept analysis,1,,SW,"Ontology mediation enables the interoperability of heterogeneous semantic data sources. Ontology mediation includes operations such as, mapping, alignment, matching, merging and integration. Formal Concept Analysis (FCA) is a machine learning technique which represents some association between the merged concepts. This paper proposes ontology mediation approach using FCA techniques. FCA has the capability of deriving a concept hierarchy or formal ontology from a collection of objects and properties. Thus, FCA can discover and position new concepts in the merged ontology. Ontology mediation includes ontology mapping, ontology alignment and ontology merging. The proposed model is implemented using an example ontology case. © 2014 ICIC International.","ICIC Express Letters, Part B: Applications",,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893194882&partnerID=40&md5=acce44322158fce6db4126076bd4625b,2014,7/20/21 15:49,7/20/21 15:49,575
H3QCZ6XR,journalArticle,2018,"Cocarascu, O.; Toni, F.",Combining deep learning and argumentative reasoning for the analysis of social media textual content using small data sets,1,,text,"The use of social media has become a regular habit for many and has changed the way people interact with each other. In this article, we focus on analyzing whether news headlines support tweets and whether reviews are deceptive by analyzing the interaction or the influence that these texts have on the others, thus exploiting contextual information. Concretely, we define a deep learning method for relation–based argument mining to extract argumentative relations of attack and support. We then use this method for determining whether news articles support tweets, a useful task in fact-checking settings, where determining agreement toward a statement is a useful step toward determining its truthfulness. Furthermore, we use our method for extracting bipolar argumentation frameworks from reviews to help detect whether they are deceptive. We show experimentally that our method performs well in both settings. In particular, in the case of deception detection, our method contributes a novel argumentative feature that, when used in combination with other features in standard supervised classifiers, outperforms the latter even on small data sets. © 2018, 2018 Association for Computational Linguistics Published under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license.",Computational Linguistics,10.1162/coli_a_00338,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059282814&doi=10.1162%2fcoli_a_00338&partnerID=40&md5=84a4ba12b55e9580be7c28297868b1ff,2018,7/20/21 15:49,7/20/21 15:49,582
3NLTZ2RZ,journalArticle,2016,"Jiménez, P.; Corchuelo, R.",Roller: a novel approach to Web information extraction,1,,text,"The research regarding Web information extraction focuses on learning rules to extract some selected information from Web documents. Many proposals are ad hoc and cannot benefit from the advances in machine learning; furthermore, they are likely to fade away as the Web evolves, and their intrinsic assumptions are not satisfied. Some authors have explored transforming Web documents into relational data and then using techniques that got inspiration from inductive logic programming. In theory, such proposals should be easier to adapt as the Web evolves because they build on catalogues of features that can be adapted without changing the proposals themselves. Unfortunately, they are difficult to scale as the number of documents or features increases. In the general field of machine learning, there are propositio-relational proposals that attempt to provide effective and efficient means to learn from relational data using propositional techniques, but they have seldom been explored regarding Web information extraction. In this article, we present a new proposal called Roller: it relies on a search procedure that uses a dynamic flattening technique to explore the context of the nodes that provide the information to be extracted; it is configured with an open catalogue of features, so that it can adapt to the evolution of the Web; it also requires a base learner and a rule scorer, which helps it benefit from the continuous advances in machine learning. Our experiments confirm that it outperforms other state-of-the-art proposals in terms of effectiveness and that it is very competitive in terms of efficiency; we have also confirmed that our conclusions are solid from a statistical point of view. © 2016, Springer-Verlag London.",Knowledge and Information Systems,10.1007/s10115-016-0921-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960355231&doi=10.1007%2fs10115-016-0921-4&partnerID=40&md5=0d194e0db3f1298e95a16b53f1f94b22,2016,7/20/21 15:49,7/20/21 15:49,585
SESHVYVF,journalArticle,2021,"Sedova, N.; Sedov, V.; Bazhenov, R.; Bogatenkov, S.",Neural network classifier for automatic course-keeping based on fuzzy logic,1,,UNK,"The authors continued their research on the development of an intelligent automatic ships pilot containing a controller based on fuzzy logic. Its features are determined by the optimizer based on a genetic algorithm. It also contains a modular unit of neural network models of ship navigation paths, as well as a neural network classifier. This paper is devoted to the description of a neural network classifier designed to classify the movement patterns of marine vessels to identify the peculiarities of the ship depending on its type and sailing conditions. The introduction of such classifier to an autopilot allows for more precise consideration of multivariate and difficult to formalize factors affecting the vessel while operating, such as varying weather conditions, irregular waves, hydrodynamic characteristics of the vessel, draft, water under the keel, rate of the vessel sailing, etc. The article outlines the technique concerning the development of a neural network classifier and the results of its computer modelling on the example of a refrigerated transport vessel type. The authors used such methods for obtaining and processing findings as spectral estimation, machine learning methods, in particular, neural network technology and computer or simulation modelling. © 2021-IOS Press. All rights reserved.",Journal of Intelligent and Fuzzy Systems,10.3233/JIFS-201495,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102408954&doi=10.3233%2fJIFS-201495&partnerID=40&md5=2ae36a1ac81c539ca483017d180403b4,2021,7/20/21 15:49,7/20/21 15:49,587
3P9VZIGK,journalArticle,2017,"Pounder, G.A.J.; Ellis, R.L.A.; Fernandez-Lopez, G.",Cognitive function synthesis: preliminary results,1,,AGI,"Purpose: This paper aims to introduce the cognitive function synthesis (CFS) conceptual framework to artificial general intelligence. CFS posits that at the “core” of intelligence in hybrid architectures, “interdependent” cognitive functions are synthesised through the interaction of various associative memory (AM)-based systems. This synthesis could form an interface layer between deliberative/symbolic and reactive/sub-symbolic layers in hybrid cognitive architectures. Design/methodology/approach: A CFS conceptual framework, specifying an arrangement of AMs, was presented. The framework was executed using sparse distributed memory. Experiments were performed to investigate CFS autonomous extraction, consciousness and imagination. Findings: Autonomous extraction was achieved using data from a Wi-Fi camera with the CFS auto-associative AM handling “Sensor Data”. However, noise reduction degraded the extracted image. An environment, simulated in V-REP 3.3.1, was used to investigate consciousness and imagination. CFS displayed consciousness by successfully tracking/anticipating the object position with over 90 per cent congruence. CFS imagination was seen by its predicting two time steps into the future. Originality/value: Preliminary results demonstrate the plausibility of CFS claims for autonomous extraction, consciousness and imagination. © 2017, © Emerald Publishing Limited.",Kybernetes,10.1108/K-01-2015-0038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012169813&doi=10.1108%2fK-01-2015-0038&partnerID=40&md5=c749b82d8b767d423fb5fcdbc431cd69,2017,7/20/21 15:49,7/20/21 15:49,594
TUWJMS6C,journalArticle,2019,"Riveret, R.; Gao, Y.; Governatori, G.; Rotolo, A.; Pitt, J.; Sartor, G.",A probabilistic argumentation framework for reinforcement learning agents: Towards a mentalistic approach to agent profiles,1,,UNK,"A bounded-reasoning agent may face two dimensions of uncertainty: firstly, the uncertainty arising from partial information and conflicting reasons, and secondly, the uncertainty arising from the stochastic nature of its actions and the environment. This paper attempts to address both dimensions within a single unified framework, by bringing together probabilistic argumentation and reinforcement learning. We show how a probabilistic rule-based argumentation framework can capture Markov decision processes and reinforcement learning agents; and how the framework allows us to characterise agents and their argument-based motivations from both a logic-based perspective and a probabilistic perspective. We advocate and illustrate the use of our approach to capture models of agency and norms, and argue that, in addition to providing a novel method for investigating agent types, the unified framework offers a sound basis for taking a mentalistic approach to agent profiles. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",Autonomous Agents and Multi-Agent Systems,10.1007/s10458-019-09404-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062791180&doi=10.1007%2fs10458-019-09404-2&partnerID=40&md5=1e799daa0c28499dc9a6cd1a23bd5ea9,2019,7/20/21 15:49,7/20/21 15:49,595
F4EY43IL,journalArticle,2019,"Chen, L.; Chen, D.; Wang, H.",Fuzzy Kernel Alignment with Application to Attribute Reduction of Heterogeneous Data,1,,fuzzy logic,"Fuzzy similarity relation is a function to measure the similarity between two samples. It is widely used to learn knowledge under the framework of fuzzy machine learning. The selection of a suitable fuzzy similarity relation is important for the learning task. It has been pointed out that fuzzy similarity relations can be brought into the framework of kernel functions in machine learning. This fact motivates us to study fuzzy similarity relation selection for fuzzy machine learning utilizing kernel selection methods in machine learning. Kernel alignment is a kernel selection method that is effective and has low computational complexity. In this paper, we present novel methods for fuzzy similarity relation selection based on the kernel alignment, and their use in attribution reduction for heterogeneous data. First, we define an ideal kernel for classification problems, based on which a novel fuzzy kernel alignment model is proposed. Second, we present a method for the fuzzy similarity relation selection based on the minimization of the fuzzy alignment between the defined ideal kernel and a kernel for the learning problem at hand. In order to show the correctness of this selection method, we prove that the lower bound of the classification accuracy of a support vector machine will increase with the decrease of the fuzzy alignment value. Furthermore, we apply the proposed fuzzy similarity relation selection to attribute reduction for heterogeneous data. Finally, we present experimental results to show that the proposed method of fuzzy similarity relation selection based on the fuzzy kernel alignment is effective. © 1993-2012 IEEE.",IEEE Transactions on Fuzzy Systems,10.1109/TFUZZ.2018.2880933,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056310660&doi=10.1109%2fTFUZZ.2018.2880933&partnerID=40&md5=34f86de79af997e69544d7ffda2755f6,2019,7/20/21 15:49,7/20/21 15:49,598
P5Y77D3H,journalArticle,2021,"Ong, D.C.; Soh, H.; Zaki, J.; Goodman, N.D.",Applying Probabilistic Programming to Affective Computing,1,,UNK,"Affective Computing is a rapidly growing field spurred by advancements in artificial intelligence, but often, held back by the inability to translate psychological theories of emotion into tractable computational models. To address this, we propose a probabilistic programming approach to affective computing, which models psychological-grounded theories as generative models of emotion, and implements them as stochastic, executable computer programs. We first review probabilistic approaches that integrate reasoning about emotions with reasoning about other latent mental states (e.g., beliefs, desires) in context. Recently-developed probabilistic programming languages offer several key desidarata over previous approaches, such as: (i) flexibility in representing emotions and emotional processes; (ii) modularity and compositionality; (iii) integration with deep learning libraries that facilitate efficient inference and learning from large, naturalistic data; and (iv) ease of adoption. Furthermore, using a probabilistic programming framework allows a standardized platform for theory-building and experimentation: Competing theories (e.g., of appraisal or other emotional processes) can be easily compared via modular substitution of code followed by model comparison. To jumpstart adoption, we illustrate our points with executable code that researchers can easily modify for their own models. We end with a discussion of applications and future directions of the probabilistic programming approach © 2010-2012 IEEE.",IEEE Transactions on Affective Computing,10.1109/TAFFC.2019.2905211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107145487&doi=10.1109%2fTAFFC.2019.2905211&partnerID=40&md5=7b8d90ccfd4d31da4a968fee43883202,2021,7/20/21 15:49,7/20/21 15:49,603
YX2SCA8W,journalArticle,2018,"Veloso de Melo, V.; Banzhaf, W.",Automatic feature engineering for regression models with machine learning: An evolutionary computation and statistics hybrid,1,,evolutionary computation,"Symbolic Regression (SR) is a well-studied task in Evolutionary Computation (EC), where adequate free-form mathematical models must be automatically discovered from observed data. Statisticians, engineers, and general data scientists still prefer traditional regression methods over EC methods because of the solid mathematical foundations, the interpretability of the models, and the lack of randomness, even though such deterministic methods tend to provide lower quality prediction than stochastic EC methods. On the other hand, while EC solutions can be big and uninterpretable, they can be created with less bias, finding high-quality solutions that would be avoided by human researchers. Another interesting possibility is using EC methods to perform automatic feature engineering for a deterministic regression method instead of evolving a single model; this may lead to smaller solutions that can be easy to understand. In this contribution, we evaluate an approach called Kaizen Programming (KP) to develop a hybrid method employing EC and Statistics. While the EC method builds the features, the statistical method efficiently builds the models, which are also used to provide the importance of the features; thus, features are improved over the iterations resulting in better models. Here we examine a large set of benchmark SR problems known from the EC literature. Our experiments show that KP outperforms traditional Genetic Programming - a popular EC method for SR - and also shows improvements over other methods, including other hybrids and well-known statistical and Machine Learning (ML) ones. More in line with ML than EC approaches, KP is able to provide high-quality solutions while requiring only a small number of function evaluations. © 2017 Elsevier Inc.",Information Sciences,10.1016/j.ins.2017.11.041,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035783891&doi=10.1016%2fj.ins.2017.11.041&partnerID=40&md5=b187844100de50c4720976ff3ad26031,2018,7/20/21 15:49,7/20/21 15:49,606
IFRCPZ2Q,journalArticle,2019,"Guidotti, R.; Monreale, A.; Giannotti, F.; Pedreschi, D.; Ruggieri, S.; Turini, F.",Factual and Counterfactual Explanations for Black Box Decision Making,1,,XAI,"The rise of sophisticated machine learning models has brought accurate but obscure decision systems, which hide their logic, thus undermining transparency, trust, and the adoption of artificial intelligence (AI) in socially sensitive and safety-critical contexts. We introduce a local rule-based explanation method, providing faithful explanations of the decision made by a black box classifier on a specific instance. The proposed method first learns an interpretable, local classifier on a synthetic neighborhood of the instance under investigation, generated by a genetic algorithm. Then, it derives from the interpretable classifier an explanation consisting of a decision rule, explaining the factual reasons of the decision, and a set of counterfactuals, suggesting the changes in the instance features that would lead to a different outcome. Experimental results show that the proposed method outperforms existing approaches in terms of the quality of the explanations and of the accuracy in mimicking the black box. © 2001-2011 IEEE.",IEEE Intelligent Systems,10.1109/MIS.2019.2957223,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076272618&doi=10.1109%2fMIS.2019.2957223&partnerID=40&md5=e2b958485d1510a355f1cff6dbf0efa2,2019,7/20/21 15:49,7/20/21 15:49,634
74QZV8X9,journalArticle,2020,"Wang, Y.; Xia, C.; Si, C.; Yao, B.; Wang, T.",Robust reasoning over heterogeneous textual information for fact verification,1,,text,"Automatic fact verification (FV) based on artificial intelligence is considered as a promising approach which can be used to identify misinformation distributed on the web. Even though previous FV using deep learning have made great achievements in single dataset (e.g., FEVER), the trained systems are unlikely to be capable of extracting evidence from heterogeneous web-sources and validating claims in accordance with evidence found on the Internet. Nevertheless, the heterogeneity covers abundant semantic information, which will help FV system identify misinformation in a more accurate way. The current work is the first attempt to make the combination of knowledge graph (KG) and graph neural network (GNN) to enhance the robustness of FV systems for heterogeneous information. As a result, it can be generalized to multi-domain datasets after training on a sufficient single one. To make information update and aggregate well on the collaborative graph, the present study proposes a double graph attention network (DGAT) framework which recursively propagates the embeddings from a node's neighbors to refine the node's embedding as well as applies an attention mechanism to classify the importance of the neighbors. We train and evaluate our system on FEVER, a single and benchmark dataset for FV, and then re-evaluate our system on UKP Snopes Corpus, a new richly annotated corpus for FV tasks on the basis of heterogeneous web sources. According to experimental results, although DGAT has no excellent advantages in a single dataset, it shows outstanding performance in more realistic and multi-domain datasets. Moreover, the current study also provides a feasible method for deep learning to have the ability to infer heterogeneous information robustly. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2020.3019586,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091207880&doi=10.1109%2fACCESS.2020.3019586&partnerID=40&md5=0dcde93954508fe534c001ed1a88ae22,2020,7/20/21 15:49,7/20/21 15:49,642
NJFLVCKA,journalArticle,2015,"Petrova, A.; Ma, Y.; Tsatsaronis, G.; Kissa, M.; Distel, F.; Baader, F.; Schroeder, M.",Formalizing biomedical concepts from textual definitions,1,,text,"Background: Ontologies play a major role in life sciences, enabling a number of applications, from new data integration to knowledge verification. SNOMED CT is a large medical ontology that is formally defined so that it ensures global consistency and support of complex reasoning tasks. Most biomedical ontologies and taxonomies on the other hand define concepts only textually, without the use of logic. Here, we investigate how to automatically generate formal concept definitions from textual ones. We develop a method that uses machine learning in combination with several types of lexical and semantic features and outputs formal definitions that follow the structure of SNOMED CT concept definitions. Results: We evaluate our method on three benchmarks and test both the underlying relation extraction component as well as the overall quality of output concept definitions. In addition, we provide an analysis on the following aspects: (1) How do definitions mined from the Web and literature differ from the ones mined from manually created definitions, e.g., MeSH? (2) How do different feature representations, e.g., the restrictions of relations' domain and range, impact on the generated definition quality?, (3) How do different machine learning algorithms compare to each other for the task of formal definition generation?, and, (4) What is the influence of the learning data size to the task? We discuss all of these settings in detail and show that the suggested approach can achieve success rates of over 90%. In addition, the results show that the choice of corpora, lexical features, learning algorithm and data size do not impact the performance as strongly as semantic types do. Semantic types limit the domain and range of a predicted relation, and as long as relations' domain and range pairs do not overlap, this information is most valuable in formalizing textual definitions. Conclusions: The analysis presented in this manuscript implies that automated methods can provide a valuable contribution to the formalization of biomedical knowledge, thus paving the way for future applications that go beyond retrieval and into complex reasoning. The method is implemented and accessible to the public from: https://github.com/alifahsyamsiyah/learningDL. © 2015 Petrova et al.; licensee BioMed Central.",Journal of Biomedical Semantics,10.1186/s13326-015-0015-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938800329&doi=10.1186%2fs13326-015-0015-3&partnerID=40&md5=03a5419cd4b5acfec04a6cfd3481444b,2015,7/20/21 15:49,7/20/21 15:49,643
9URQK9SB,journalArticle,2019,"Marie, F.; Corbat, L.; Chaussy, Y.; Delavelle, T.; Henriet, J.; Lapayre, J.-C.",Segmentation of deformed kidneys and nephroblastoma using Case-Based Reasoning and Convolutional Neural Network,1,,img,"Most often, image segmentation is not fully automated and a user is required to lead the process in order to obtain correct results. In a medical context, segmentation can furnish much information to surgeons, but this task is rarely executed. Artificial Intelligence (AI) is a powerful approach for devising a viable solution to fully automated treatment. In this paper, we have focused on kidneys deformed by nephroblastoma. However, a frequent medical constraint is encountered which is a lack of sufficient data with which to train our system. In function of this constraint, two AI approaches were used to segment these structures. First, a Case Based Reasoning (CBR) approach was defined which can enhance the growth of regions for segmentation of deformed kidneys using an adaptation phase to modify coordinates of recovered seeds. This CBR approach was confronted with manual region growing and a Convolutional Neural Network (CNN). The CBR system succeeded in performing the best segmentation for the kidney with a mean Dice of 0.83. Deep Learning was then examined as a possible solution, using the latest performing networks for image segmentation. However, for relevant efficiency, this method requires a large data set. An option would be to manually segment only certain representative slices from a patient and then use them to train a Convolutional Neural Network (CNN) how to segment. In this article the authors propose an evaluation of a CNN for medical image segmentation following different training sets with a variable number of manual segmentations. To choose slices to train the CNN, an Overlearning Vector for Valid Sparse SegmentatIONs (OV2 ASSION) was used, with the notion of gap between two slices from the training set. This protocol made it possible to obtain reliable segmentations of per patient with a small data set and to determine that only 26% of initial segmented slices are required to obtain a complete segmentation of a patient with a mean Dice of 0.897. © 2019",Expert Systems with Applications,10.1016/j.eswa.2019.03.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062915757&doi=10.1016%2fj.eswa.2019.03.010&partnerID=40&md5=9e340be56439b06c3324d4d8aafe16ef,2019,7/20/21 15:49,7/20/21 15:49,646
452MQ7P7,journalArticle,2016,"Xu, S.; Liu, Z.; Zhang, Y.",Least squares support vector regression and interval type-2 fuzzy density weight for scene denoising,1,,img,"Support vector machines are the popular machine learning techniques. Its variant least squares support vector regression (LS-SVR) is effective for image denoising. However, the fitting of the samples contaminated by noises in the training phase will result in the fact that LS-SVR cannot work well when noise level is too far from it or noise density is high. Type-2 fuzzy sets and systems have been shown to be a more promising method to manifest the uncertainties. Various noises would be taken as uncertainties in scene images. By integrating the design of learning weights with type-2 fuzzy sets, a systematic design methodology of interval type-2 fuzzy density weighted support vector regression (IT2FDW-SVR) model for scene denoising is presented to address the problem of sample uncertainty in scene images. A novel strategy is used to design the learning weights, which is similar to the selection of human experience. To handle the uncertainty of sample density, interval type-2 fuzzy logic system (IT2FLS) is employed to deduce the fuzzy learning weights (IT2FDW) in the IT2FDW-SVR, which is an extension of the previously weighted SVR. Extensive experimental results demonstrate that the proposed method can achieve better performances in terms of both objective and subjective evaluations than those state-of-the-art denoising techniques. © 2015, Springer-Verlag Berlin Heidelberg.",Soft Computing,10.1007/s00500-015-1598-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961054302&doi=10.1007%2fs00500-015-1598-4&partnerID=40&md5=7cfa31d534c25d6408424ac0281517a5,2016,7/20/21 15:49,7/20/21 15:49,647
9YGPA79Q,journalArticle,2012,"Wu, J.",A framework for learning comprehensible theories in XML document classification,1,,text,"XML has become the universal data format for a wide variety of information systems. The large number of XML documents existing on the web and in other information storage systems makes classification an important task. As a typical type of semistructured data, XML documents have both structures and contents. Traditional text learning techniques are not very suitable for XML document classification as structures are not considered. This paper presents a novel complete framework for XML document classification. We first present a knowledge representation method for XML documents which is based on a typed higher order logic formalism. With this representation method, an XML document is represented as a higher order logic term where both its contents and structures are captured. We then present a decision-tree learning algorithm driven by precision/recall breakeven point (PRDT) for the XML classification problem which can produce comprehensible theories. Finally, a semi-supervised learning algorithm is given which is based on the PRDT algorithm and the cotraining framework. Experimental results demonstrate that our framework is able to achieve good performance in both supervised and semi-supervised learning with the bonus of producing comprehensible learning theories. © 2011 IEEE.",IEEE Transactions on Knowledge and Data Engineering,10.1109/TKDE.2011.158,https://www.scopus.com/inward/record.uri?eid=2-s2.0-82155192311&doi=10.1109%2fTKDE.2011.158&partnerID=40&md5=c242713f3de9c6f29df249f3b6f9b8d0,2012,7/20/21 15:49,7/20/21 15:49,652
4NTJ3CPI,journalArticle,2021,"Patro, B.N.; Anupriy; Namboodiri, V.P.",Probabilistic framework for solving visual dialog,1,,text;img,"In this paper, we propose a probabilistic framework for solving the task of ‘Visual Dialog’. Solving this task requires reasoning and understanding of visual modality, language modality, and common sense knowledge to answer. Various architectures have been proposed to solve this task by variants of multi-modal deep learning techniques that combine visual and language representations. However, we believe that it is crucial to understand and analyze the sources of uncertainty for solving this task. Our approach allows for estimating uncertainty and also aids a diverse generation of answers. The proposed approach is obtained through a probabilistic representation module that provides us with representations for image, question and conversation history, a module that ensures that diverse latent representations for candidate answers are obtained given the probabilistic representations and an uncertainty representation module that chooses the appropriate answer that minimizes uncertainty. We thoroughly evaluate the model with a detailed ablation analysis, comparison with state of the art and visualization of the uncertainty that aids in the understanding of the method. Using the proposed probabilistic framework, we thus obtain an improved visual dialog system that is also more explainable. © 2020",Pattern Recognition,10.1016/j.patcog.2020.107586,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089570260&doi=10.1016%2fj.patcog.2020.107586&partnerID=40&md5=d0f350c9fb879d486ef94ef0c1b5941b,2021,7/20/21 15:49,7/20/21 15:49,653
MDRB9QX7,journalArticle,2018,"Tchuiev, V.; Indelman, V.",Inference Over Distribution of Posterior Class Probabilities for Reliable Bayesian Classification and Object-Level Perception,1,,img,"State of the art Bayesian classification approaches typically maintain a posterior distribution over possible classes given available sensor observations (images). Yet, while these approaches fuse all classifier outputs thus far, they do not provide any indication regarding how reliable the posterior classification is, thus limiting its functionality in terms of autonomous systems and robotics. On the other hand, current deep learning based classifiers provide an uncertainty measure, thereby quantifying model uncertainty. However, they do so on a single frame basis and do not consider a sequential framework. In this letter, we develop a novel approach that infers a distribution over posterior class probabilities, while accounting for model uncertainty. This distribution enables reasoning about uncertainty in the posterior classification and, therefore, is of prime importance for robust classification, object-level perception in uncertain and ambiguous scenarios, and for safe autonomy in general. The distribution of the posterior class probability has no known analytical solution; thus, we propose to approximate this distribution via sampling. We evaluate our approach in simulation and using real images fed into a convolutional neural network classifier. © 2016 IEEE.",IEEE Robotics and Automation Letters,10.1109/LRA.2018.2852844,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063307535&doi=10.1109%2fLRA.2018.2852844&partnerID=40&md5=8e1cf23880d8e5a008694663fddfeb86,2018,7/20/21 15:49,7/20/21 15:49,654
BED8VGVH,journalArticle,2019,"Wang, W.; Søndergaard, H.; Stuckey, P.J.",Wombit: A Portfolio Bit-Vector Solver Using Word-Level Propagation,1,,text,"We develop an idea originally proposed by Michel and Van Hentenryck of how to perform bit-vector constraint propagation on the word level. Most operations are propagated in constant time, assuming the bit-vector fits in a machine word. In contrast, bit-vector SMT solvers usually solve bit-vector problems by (ultimately) bit-blasting, that is, mapping the resulting operations to conjunctive normal form clauses, and using SAT technology to solve them. Bit-blasting generates intermediate variables which can be an advantage, as these can be searched on and learnt about. As each approach has advantages, it makes sense to try to combine them. In this paper, we describe an approach to bit-vector solving using word-level propagation with learning. We have designed alternative word-level propagators to Michel and Van Hentenryck’s, and evaluated different variants of the approach. We have also experimented with different approaches to learning and back-jumping in the solver. Based on the insights gained, we have built a portfolio solver, Wombit, which essentially extends the STP bit-vector solver. Using machine learning techniques, the solver makes a judicious up-front decision about whether to use word-level propagation or fall back on bit-blasting. © 2018, Springer Nature B.V.",Journal of Automated Reasoning,10.1007/s10817-018-9493-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056335383&doi=10.1007%2fs10817-018-9493-1&partnerID=40&md5=ff83aaf2d2f5d0a2f54b928d00949572,2019,7/20/21 15:49,7/20/21 15:49,675
A59DP9ZJ,journalArticle,2014,"Peissig, P.L.; Santos Costa, V.; Caldwell, M.D.; Rottscheit, C.; Berg, R.L.; Mendonca, E.A.; Page, D.",Relational machine learning for electronic health record-driven phenotyping,1,,EHR,"Objective: Electronic health records (EHR) offer medical and pharmacogenomics research unprecedented opportunities to identify and classify patients at risk. EHRs are collections of highly inter-dependent records that include biological, anatomical, physiological, and behavioral observations. They comprise a patient's clinical phenome, where each patient has thousands of date-stamped records distributed across many relational tables. Development of EHR computer-based phenotyping algorithms require time and medical insight from clinical experts, who most often can only review a small patient subset representative of the total EHR records, to identify phenotype features. In this research we evaluate whether relational machine learning (ML) using inductive logic programming (ILP) can contribute to addressing these issues as a viable approach for EHR-based phenotyping. Methods: Two relational learning ILP approaches and three well-known WEKA (Waikato Environment for Knowledge Analysis) implementations of non-relational approaches (PART, J48, and JRIP) were used to develop models for nine phenotypes. International Classification of Diseases, Ninth Revision (ICD-9) coded EHR data were used to select training cohorts for the development of each phenotypic model. Accuracy, precision, recall, F-Measure, and Area Under the Receiver Operating Characteristic (AUROC) curve statistics were measured for each phenotypic model based on independent manually verified test cohorts. A two-sided binomial distribution test (sign test) compared the five ML approaches across phenotypes for statistical significance. Results: We developed an approach to automatically label training examples using ICD-9 diagnosis codes for the ML approaches being evaluated. Nine phenotypic models for each ML approach were evaluated, resulting in better overall model performance in AUROC using ILP when compared to PART (p= 0.039), J48 (p= 0.003) and JRIP (p= 0.003). Discussion: ILP has the potential to improve phenotyping by independently delivering clinically expert interpretable rules for phenotype definitions, or intuitive phenotypes to assist experts. Conclusion: Relational learning using ILP offers a viable approach to EHR-driven phenotyping. © 2014 Elsevier Inc.",Journal of Biomedical Informatics,10.1016/j.jbi.2014.07.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919848159&doi=10.1016%2fj.jbi.2014.07.007&partnerID=40&md5=4560b8a03a8abc21fb4e657f3b9e8d4a,2014,7/20/21 15:49,7/20/21 15:49,682
MM9TSGYY,journalArticle,2019,"Betere, I.J.; Kinjo, H.; Nakazono, K.; Oshiro, N.",Investigation of multi-layer neural network performance evolved by genetic algorithms,1,,,"This paper presents a study on the investigation of multi-layer neural networks (MLNNs) performance evolved with genetic algorithm (GA) for multi-logic training patterns applied to various network functions. Specifically, we have concentrated on the Sigmoid, Step and ReLU functions to evaluate and simulate their performances in the network. We have revealed that GA training gives good training results in evolutionary computation by changing of Sigmoid, ReLU and Step as the activity functions in MLNN performance. Sigmoid function has proved to train all patterns for all outputs without any challenge as compared to ReLU function and Step in this study. We are still trying to see how a ReLU function could be trained with GA for MLNNs performance for the two input and four output training patterns termed as the multi-logic pattern training about multiple training parameters. © 2018, ISAROB.",Artificial Life and Robotics,10.1007/s10015-018-0494-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054535773&doi=10.1007%2fs10015-018-0494-2&partnerID=40&md5=76d07144c99ed1a898d0e87abf5f6874,2019,7/20/21 15:49,7/20/21 15:49,684
4EF4BXD9,journalArticle,2020,"Zarisfi Kermani, F.; Sadeghi, F.; Eslami, E.",Solving the twitter sentiment analysis problem based on a machine learning-based approach,1,,text,"Twitter Sentiment Analysis (TSA) as part of a text classification task has been widely attended by researchers in recent years. This paper presents a machine learning approach to solving the TSA problem in three phases. In the second phase, a suitable value for representing each feature in the Vector Space Model is determined through the weighted combination of the values obtained from four methods (i.e., Term Frequency and Inverse Document Frequency, semantic similarity, sentiment scoring using SentiWordNet, and sentiment scoring based on the class of tweets). In this manner, finding the percentage of contributions or weights of each method is defined as an optimization problem and solved using a genetic algorithm. Also, the weighted values obtained from four methods are combined based on the Einstein sum as an important T-conorm method. Finally, the performance of the proposed method is tested based on the accuracy of support vector machine and multinomial naïve Bayes classification algorithms on four famous Twitter datasets, namely the Stanford testing dataset, STS-Gold dataset, Obama-McCain Debate dataset, and Strict Obama-McCain Debate dataset. The obtained results show the high superiority of the proposed method in comparison with the other methods. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Evolutionary Intelligence,10.1007/s12065-019-00301-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074497303&doi=10.1007%2fs12065-019-00301-x&partnerID=40&md5=064426e2a466ab68466559bf866ee630,2020,7/20/21 15:49,7/20/21 15:49,687
44KCPGAV,journalArticle,2020,"Jia, W.; Liu, X.; Wang, Y.; Pedrycz, W.; Zhou, J.",Semisupervised Learning via Axiomatic Fuzzy Set Theory and SVM,1,,UNK,"In this article, we present a semantic semisupervised learning (Semantic SSL) approach targeted at unifying two machine-learning paradigms in a mutually beneficial way, where the classical support vector machine (SVM) learns to reveal primitive logic facts from data, while axiomatic fuzzy set (AFS) theory is utilized to exploit semantic knowledge and correct the wrongly perceived facts for improving the machine-learning model. This novel semisupervised method can easily produce interpretable semantic descriptions to outline different categories by forming a fuzzy set with semantic explanations realized on the basis of the AFS theory. Besides, it is known that disagreement-based semisupervised learning (SSL) can be viewed as an excellent schema so that a co-training approach with SVM and the AFS theory can be utilized to improve the resulting learning performance. Furthermore, an evaluation index is used to prune descriptions to deliver promising performance. Compared with other semisupervised approaches, the proposed approach can build a structure to reflect data-distributed information with unlabeled data and labeled data, so that the hidden information embedded in both labeled and unlabeled data can be sufficiently utilized and can potentially be applied to achieve good descriptions of each category. Experimental results demonstrate that this approach can offer a concise, comprehensible, and precise SSL frame, which strikes a balance between the interpretability and the accuracy. IEEE",IEEE Transactions on Cybernetics,10.1109/TCYB.2020.3032707,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097428882&doi=10.1109%2fTCYB.2020.3032707&partnerID=40&md5=3ba01ff705ac2bcef8bc336542a161db,2020,7/20/21 15:49,7/20/21 15:49,688
PD2A2ZVV,journalArticle,2019,"Sarwar, S.; Qayyum, Z.U.; García-Castro, R.; Safyan, M.; Munir, R.F.","Ontology based E-learning framework: A personalized, adaptive and context aware model",1,,,"Enhancing the degree of learner productivity, one of the major challenges in E-Learning systems, may be catered through effective personalization, adaptivity and context awareness while recommending the learning contents to the learners. In this paper, an E-Learning framework has been proposed that profiles the learners, categorizes the learners based on profiles, makes personalized content recommendations and performs assessment based content adaptation. A mathematical model has been proposed for learner categorization using machine learning techniques (a hybrid of case based reasoning and neural networks). The learning contents have been annotated through CourseOntology in which three academic courses (each for language of C++, C# and JAVA) have been modeled for the learners. A dynamic rule based recommender has been presented targeting a ‘relative grading system’ for maximizing the learner’s productivity. Performance of proposed framework has been measured in terms of accurate learner categorization, personalized recommendation of the learning contents, completeness and correctness of ontological model and overall performance improvement of learners in academic sessions of 2015, 2016 and 2017. The comparative analysis of proposed framework exhibits visibly improved results compared to prevalent approaches. These improvements are signified to the comprehensive attribute selection in learner profiling, dynamic techniques for learner categorization and effective content recommendation while ensuring personalization and adaptivity. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",Multimedia Tools and Applications,10.1007/s11042-019-08125-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071338621&doi=10.1007%2fs11042-019-08125-8&partnerID=40&md5=04020cef4e95df52dca712468616dd68,2019,7/20/21 15:49,7/20/21 15:49,689
R5DP39JK,journalArticle,2019,"Vashishtha, S.; Susan, S.",Fuzzy rule based unsupervised sentiment analysis from social media posts,1,,text,"In this paper, we compute the sentiment of social media posts using a novel set of fuzzy rules involving multiple lexicons and datasets. The proposed fuzzy system integrates Natural Language Processing techniques and Word Sense Disambiguation using a novel unsupervised nine fuzzy rule based system to classify the post into: positive, negative or neutral sentiment class. We perform a comparative analysis of our method on nine public twitter datasets, three sentiment lexicons, four state-of-the-art approaches for unsupervised Sentiment Analysis and one state-of-the-art method for supervised machine learning. Traditionally, Sentiment Analysis of twitter data is performed using a single lexicon. Our results can give an insight to researchers to choose which lexicon is best for social media. The fusion of fuzzy logic with lexicons for sentiment classification provides a new paradigm in Sentiment Analysis. Our method can be adapted to any lexicon and any dataset (two-class or three-class sentiment). The experiments on benchmark datasets yield higher performance for our approach as compared to the state-of-the-art. © 2019 Elsevier Ltd",Expert Systems with Applications,10.1016/j.eswa.2019.112834,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069805425&doi=10.1016%2fj.eswa.2019.112834&partnerID=40&md5=93adfcab9263b61455f694f19e36ec3e,2019,7/20/21 15:49,7/20/21 15:49,692
ACDMDN8W,journalArticle,2021,"Bounabi, M.; Elmoutaouakil, K.; Satori, K.",A new neutrosophic TF-IDF term weighting for text mining tasks: text classification use case,1,,text,"Purpose: This paper aims to present a new term weighting approach for text classification as a text mining task. The original method, neutrosophic term frequency – inverse term frequency (NTF-IDF), is an extended version of the popular fuzzy TF-IDF (FTF-IDF) and uses the neutrosophic reasoning to analyze and generate weights for terms in natural languages. The paper also propose a comparative study between the popular FTF-IDF and NTF-IDF and their impacts on different machine learning (ML) classifiers for document categorization goals. Design/methodology/approach: After preprocessing textual data, the original Neutrosophic TF-IDF applies the neutrosophic inference system (NIS) to produce weights for terms representing a document. Using the local frequency TF, global frequency IDF and text N's length as NIS inputs, this study generate two neutrosophic weights for a given term. The first measure provides information on the relevance degree for a word, and the second one represents their ambiguity degree. Next, the Zhang combination function is applied to combine neutrosophic weights outputs and present the final term weight, inserted in the document's representative vector. To analyze the NTF-IDF impact on the classification phase, this study uses a set of ML algorithms. Findings: Practicing the neutrosophic logic (NL) characteristics, the authors have been able to study the ambiguity of the terms and their degree of relevance to represent a document. NL's choice has proven its effectiveness in defining significant text vectorization weights, especially for text classification tasks. The experimentation part demonstrates that the new method positively impacts the categorization. Moreover, the adopted system's recognition rate is higher than 91%, an accuracy score not attained using the FTF-IDF. Also, using benchmarked data sets, in different text mining fields, and many ML classifiers, i.e. SVM and Feed-Forward Network, and applying the proposed term scores NTF-IDF improves the accuracy by 10%. Originality/value: The novelty of this paper lies in two aspects. First, a new term weighting method, which uses the term frequencies as components to define the relevance and the ambiguity of term; second, the application of NL to infer weights is considered as an original model in this paper, which also aims to correct the shortcomings of the FTF-IDF which uses fuzzy logic and its drawbacks. The introduced technique was combined with different ML models to improve the accuracy and relevance of the obtained feature vectors to fed the classification mechanism. © 2021, Emerald Publishing Limited.",International Journal of Web Information Systems,10.1108/IJWIS-11-2020-0067,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103899477&doi=10.1108%2fIJWIS-11-2020-0067&partnerID=40&md5=707e28923b31ac89b6593e7020b37ae9,2021,7/20/21 15:49,7/20/21 15:49,696
TBJ6EUJC,journalArticle,2020,"Sachan, S.; Yang, J.-B.; Xu, D.-L.; Benavides, D.E.; Li, Y.",An explainable AI decision-support-system to automate loan underwriting,1,,XAI,"Widespread adoption of automated decision making by artificial intelligence (AI) is witnessed due to specular advances in computation power and improvements in optimization algorithms especially in machine learning (ML). Complex ML models provide good prediction accuracy; however, the opacity of ML models does not provide sufficient assurance for their adoption in the automation of lending decisions. This paper presents an explainable AI decision-support-system to automate the loan underwriting process by belief-rule-base (BRB). This system can accommodate human knowledge and can also learn from historical data by supervised learning. The hierarchical structure of BRB can accommodates factual and heuristic rules. The system can explain the chain of events leading to a decision for a loan application by the importance of an activated rule and the contribution of antecedent attributes in the rule. A business case study on automation of mortgage underwriting is demonstrated to show that the BRB system can provide a good trade-off between accuracy and explainability. The textual explanation produced by the activation of rules could be used as a reason for denial of a loan. The decision-making process for an application can be comprehended by the significance of rules in providing the decision and contribution of its antecedent attributes. © 2019",Expert Systems with Applications,10.1016/j.eswa.2019.113100,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075989564&doi=10.1016%2fj.eswa.2019.113100&partnerID=40&md5=5ec482b90ba8e4eee4ae693fa8d34dd6,2020,7/20/21 15:49,7/20/21 15:49,721
9VUI3ZWE,journalArticle,2020,"Csiszár, O.; Csiszár, G.; Dombi, J.",Interpretable neural networks based on continuous-valued logic and multicriteria decision operators,1,,UNK,"Combining neural networks with continuous logic and multicriteria decision-making tools can reduce the black-box nature of neural models. In this study, we show that nilpotent logical systems offer an appropriate mathematical framework for hybridization of continuous nilpotent logic and neural models, helping to improve the interpretability and safety of machine learning. In our concept, perceptrons model soft inequalities; namely membership functions and continuous logical operators. We design the network architecture before training, using continuous logical operators and multicriteria decision tools with given weights working in the hidden layers. Designing the structure appropriately leads to a drastic reduction in the number of parameters to be learned. The theoretical basis offers a straightforward choice of activation functions (the cutting function or its differentiable approximation, the squashing function), and also suggests an explanation to the great success of the rectified linear unit (ReLU). In this study, we focus on the architecture of a hybrid model and introduce the building blocks for future applications in deep neural networks. © 2020 Elsevier B.V.",Knowledge-Based Systems,10.1016/j.knosys.2020.105972,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083895664&doi=10.1016%2fj.knosys.2020.105972&partnerID=40&md5=788ad14e7d99045f096f71934fb40166,2020,7/20/21 15:49,7/20/21 15:49,730
BSPHEXCD,journalArticle,2012,"Szwabe, A.; Misiorek, P.; Walkowiak, P.",Tensor-based relational learning for ontology matching,1,,UNK,"In this paper we propose the Tensor-based Reective Relational Learning System (TRRLS) as a first tensor-based approach to decision support in the area of ontology alignment. The system may be seen as realizing a probabilistic inference with regard to the relation representing the 'semantic equivalence' of ontology classes or their properties. Despite the fact that TRRLS is based on the new idea of algebraic modeling of multi-relational data, it provides similar results to the best approaches of the Ontology Alignment Evaluation Initiative (OAEI) competitors to the task of matching concepts of Adult Mouse Anatomy ontology and NCI Thesaurus ontology on the basis of partially known expert matches. © 2012 The authors and IOS Press. All rights reserved.",Frontiers in Artificial Intelligence and Applications,10.3233/978-1-61499-105-2-509,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873449067&doi=10.3233%2f978-1-61499-105-2-509&partnerID=40&md5=5eefe2f6f879533e44a4d02b9493ba3c,2012,7/20/21 15:49,7/20/21 15:49,735
QDA52ZBD,journalArticle,2019,"Liu, H.; Chen, S.-M.",Multi-stage mixed rule learning approach for advancing performance of rule-based classification,1,,UNK,"Rule learning is a special type of machine learning approaches, and its key advantage is the generation of interpretable models, which provides a transparent process of showing how an input is mapped to an output. Traditional rule learning algorithms are typically based on Boolean logic for inducing rule antecedents, which are very effective for training models on data sets that involve discrete attributes only. When continuous attributes are present in a data set, traditional rule learning approaches need to employ crisp intervals. However, in reality, problems usually show shades of grey, which motivated the development of fuzzy rule learning approaches by employing fuzzy intervals for handling continuous attributes. While a data set contains a large portion of discrete attributes or even no continuous attributes, fuzzy approaches cannot be used to learn rules effectively, leading to a drop in the performance. In this paper, a multi-stage approach of mixed rule learning is proposed, which involves strategic combination of both traditional and fuzzy approaches to handle effectively various types of attributes. We compare our proposed approach with existing algorithms of rule learning. Our experimental results show that our proposed approach leads to significant advances in the performance compared with the existing algorithms. © 2019 Elsevier Inc.",Information Sciences,10.1016/j.ins.2019.05.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065209026&doi=10.1016%2fj.ins.2019.05.008&partnerID=40&md5=d0fc7102d8dfb955fdd43cd808b4a698,2019,7/20/21 15:49,7/20/21 15:49,753
GQ4IILGA,journalArticle,2018,"Yang, Y.; Xu, D.-L.; Yang, J.-B.; Chen, Y.-W.",An evidential reasoning-based decision support system for handling customer complaints in mobile telecommunications,1,,text,"Handling customer complaints is a decision-making process that inherently involves a classification problem where each complaint should be classified exclusively to one of the complaint categories before a resolution is communicated to customers. Previous studies focus extensively on decision support systems (DSSs) to automate complaint handling, while few addresses the issue of classification imprecision when inaccurate or inconsistent information exists in customer complaint narratives. This research presents a novel DSS for handling customer complaints and develops an evidential reasoning (ER) rule-based classifier as the core component of the system to classify customer complaints with uncertain information. More specifically, textual and numeric features are firstly combined to generate evidence for formulating the relationship between customer complaint features and classification results. The ER rule is then applied to combine multiple pieces of evidence and classify customer complaints into different categories with probabilities. An empirical study is conducted in a telecommunication company. Results show that the proposed ER rule-based classification model provides high performance in comparison with other machine learning algorithms. The developed system offers telecommunication companies an informative and data-driven method for handling customer complaints in a systematic and automatic manner. © 2018 Elsevier B.V.",Knowledge-Based Systems,10.1016/j.knosys.2018.09.029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054088729&doi=10.1016%2fj.knosys.2018.09.029&partnerID=40&md5=89e4ff12455c3a700237efe0bf8cee8b,2018,7/20/21 15:49,7/20/21 15:49,762
KTEHK4MZ,journalArticle,2021,"Wang, Q.; Hao, Y.; Chen, F.",Deepening the IDA* algorithm for knowledge graph reasoning through neural network architecture,1,,KG,"Inferring missing links in Knowledge Graphs (KGs) is a key evaluation task for KG reasoning, which aims to find relations for a given entity pair. Existing research often employs the IDA* (Iterative Deepening A*) algorithm for the path discovery task owing to its efficiency and accuracy. However, it relies on heuristics to set cost functions and is also difficult to utilize useful context information in the search process. In this paper, we propose the Deep-IDA* framework which applies neural networks and reinforcement learning (RL) to empower the IDA* algorithm to tackle the path discovery problem in KG reasoning. We model KG reasoning as a Markov Decision Process (MDP) and divide our Deep-IDA* framework and the resulting path into two parts: path-finding and path-reasoning. For path-finding, we propose a policy network to model the cost from the source to a candidate location. In this process, we employ the GCN (Graph Convolutional Network) to embed the observable sub-track, then employ the LSTM (Long Short-Term Memory) to record the historical trajectory, and introduce the attention to utilize the context information, and finally form policy. For path-reasoning with the searched candidate paths passed from the former process, we employ a value network to estimate the cost from the candidate to the destination entity, using the GNN (Graph Neural Networks) to learn a message-passing algorithm that solves the path inference problem, and using the GRU (Gated Recurrent Unit) to update the historical information. Finally, the actor-learner algorithm is utilized to minimize the sum of the losses of the two parts. Experiment results on three datasets demonstrate the effectiveness and efficiency of our framework. © 2020 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2020.12.040,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098717859&doi=10.1016%2fj.neucom.2020.12.040&partnerID=40&md5=1664fc555b7f44fd3fadab33ad9243f8,2021,7/20/21 15:49,7/20/21 15:49,776
RDSQSBN7,journalArticle,2021,"Zhou, M.; Ji, D.; Li, F.",Relation Extraction in Dialogues: A Deep Learning Model Based on the Generality and Specialty of Dialogue Text,1,,text,"Relation extraction from dialogue text is an innovative task in natural language processing. In addition to the general characteristics of general relation extraction from news or scientific publication text, the task is of certain special features. For example, the context in dialogues frequently switches between speakers, and there exist rich pronoun anaphora in the dialogue text. Thus, it is important for the model to be aware of such features to improve the performance. Taking these factors together, we propose an end to-end neural model for dialogue-based relation extraction, which includes four modules to handle the problems existing in the task from different aspects: (1) the word-relation attention to model a natural intuition that different words contribute differently for the identification of different relations; (2) the graph reasoning to consider the global context information in the dialogue that contains many inter-sentence relations; (3) the speaker embeddings to incorporate speaker information into our model; (4) the speaker coreference to associate pronouns with speakers and enrich the information of graph reasoning. Our model was evaluated on a recently-proposed dataset for dialogue-based relation extraction, and achieved the state of the-art performance. We show that our proposed modules are effective through ablation studies. Our work can be a competitive benchmark for the study of dialogue based relation extraction. IEEE",IEEE/ACM Transactions on Audio Speech and Language Processing,10.1109/TASLP.2021.3082295,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107200162&doi=10.1109%2fTASLP.2021.3082295&partnerID=40&md5=95e3b167fd71613270903576b8ac1557,2021,7/20/21 15:49,7/20/21 15:49,778
ZWSKQQLU,journalArticle,2021,"Li, S.; Wang, H.; Pan, R.; Mao, M.",MemoryPath: A deep reinforcement learning framework for incorporating memory component into knowledge graph reasoning,1,,KG,"Knowledge Graph (KG) is identified as a major area in artificial intelligence, which is used for many real-world applications. The task of knowledge graph reasoning has been widely used and proven to be effective, which aims to find these reasonable paths for various relations to solve the issue of incompleteness in KGs. However, many previous works on KG reasoning, such as path-based or reinforcement learning-based methods, are too reliant on the pre-training, where the paths from the head entity and the target entity must be given to pre-train the model, which would easily lead the model to overfit on the given paths seen in the pre-training. To address this issue, we propose a novel reasoning model named MemoryPath with a deep reinforcement learning framework, which incorporates Long Short Term Memory (LSTM) and graph attention mechanism to form the memory component. The well-designed memory component can get rid of the pre-training so that the model doesn't depend on the given target entity for training. A tailored mechanism of reinforcement learning is presented in this proposed deep reinforcement framework to optimize the training procedure, where two metrics, Mean Selection Rate (MSR) and Mean Alternative Rate (MAR), are defined to quantitatively measure the complexities of the query relations. Meanwhile, three different training mechanisms, Action Dropout, Reward Shaping and Force Forward, are proposed to optimize the training process of the proposed MemoryPath. The proposed MemoryPath is validated on two datasets from FB15K-237 and NELL-995 on different tasks including fact prediction, link prediction and success rate in finding paths. The experimental results demonstrate that the tailored mechanism of reinforcement learning make the MemoryPath achieves state-of-the-art performance comparing with the other models. Also, the qualitative analysis indicates that the MemoryPath can store the learning process and automatically find the promising paths for a reasoning task during the training, and shows the effectiveness of the memory component. © 2020 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2020.08.032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091334260&doi=10.1016%2fj.neucom.2020.08.032&partnerID=40&md5=376fee3b8d1c2366c8f51c0bf660bd3e,2021,7/20/21 15:49,7/20/21 15:49,780
JK3R9PCT,journalArticle,2018,"Banaee, H.; Schaffernicht, E.; Loutfi, A.",Data-driven conceptual spaces: Creating semantic representations for linguistic descriptions of numerical data,1,,text,"There is an increasing need to derive semantics from real-world observations to facilitate natural information sharing between machine and human. Conceptual spaces theory is a possible approach and has been proposed as mid-level representation between symbolic and sub-symbolic representations, whereby concepts are represented in a geometrical space that is characterised by a number of quality dimensions. Currently, much of the work has demonstrated how conceptual spaces are created in a knowledge-driven manner, relying on prior knowledge to form concepts and identify quality dimensions. This paper presents a method to create semantic representations using data-driven conceptual spaces which are then used to derive linguistic descriptions of numerical data. Our contribution is a principled approach to automatically construct a conceptual space from a set of known observations wherein the quality dimensions and domains are not known a priori. This novelty of the approach is the ability to select and group semantic features to discriminate between concepts in a data-driven manner while preserving the semantic interpretation that is needed to infer linguistic descriptions for interaction with humans. Two data sets representing leaf images and time series signals are used to evaluate the method. An empirical evaluation for each case study assesses how well linguistic descriptions generated from the conceptual spaces identify unknown observations. Furthermore, comparisons are made with descriptions derived on alternative approaches for generating semantic models. © 2018 AI Access Foundation. All rights reserved.",Journal of Artificial Intelligence Research,10.1613/jair.1.11258,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057746407&doi=10.1613%2fjair.1.11258&partnerID=40&md5=21520c19c926f04ecf8121541b8aa108,2018,7/20/21 15:49,7/20/21 15:49,812
DMGEINNX,journalArticle,2019,"Liu, N.; Shen, B.; Zhang, Z.; Zhang, Z.; Mi, K.",Attention-based Sentiment Reasoner for aspect-based sentiment analysis,1,,text,"Aspect-based sentiment analysis (ABSA) is a powerful way of predicting the sentiment polarity of text in natural language processing. However, understanding human emotions and reasoning from text like a human continues to be a challenge. In this paper, we propose a model, named Attention-based Sentiment Reasoner (AS-Reasoner), to alleviate the problem of how to capture precise sentiment expressions in ABSA for reasoning. AS-Reasoner assigns importance degrees to different words in a sentence to capture key sentiment expressions towards a specific aspect, and transfers them into a sentiment sentence representation for reasoning in the next layer. To obtain appropriate importance degree values for different words in a sentence, two attention mechanisms we designed: intra attention and global attention. Specifically, intra attention captures the sentiment similarity between any two words in a sentence to compute weights and global attention computes weights by a global perspective. Experiments on all four English and four Chinese datasets show that the proposed model achieves state-of-the-art accuracy and macro-F1 results for aspect term level sentiment analysis and obtains the best accuracy for aspect category level sentiment analysis. The experimental results also indicate that AS-Reasoner is language-independent. © 2019, The Author(s).",Human-centric Computing and Information Sciences,10.1186/s13673-019-0196-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073199829&doi=10.1186%2fs13673-019-0196-3&partnerID=40&md5=b1a041a676af7b467d0659845d3274cb,2019,7/20/21 15:49,7/20/21 15:49,821
ZD7VLT7Z,journalArticle,2017,"Bach, S.H.; Broecheler, M.; Huang, B.; Getoor, L.",Hinge-Loss Markov random fields and probabilistic soft logic,1,,,"A fundamental challenge in developing high-impact machine learning technologies is balancing the need to model rich, structured domains with the ability to scale to big data. Many important problem areas are both richly structured and large scale, from social and biological networks, to knowledge graphs and the Web, to images, video, and natural language. In this paper, we introduce two new formalisms for modeling structured data, and show that they can both capture rich structure and scale to big data. The first, hingeloss Markov random fields (HL-MRFs), is a new kind of probabilistic graphical model that generalizes different approaches to convex inference. We unite three approaches from the randomized algorithms, probabilistic graphical models, and fuzzy logic communities, showing that all three lead to the same inference objective. We then define HL-MRFs by generalizing this unified objective. The second new formalism, probabilistic soft logic (PSL), is a probabilistic programming language that makes HL-MRFs easy to define using a syntax based on first-order logic. We introduce an algorithm for inferring most-probable variable assignments (MAP inference) that is much more scalable than general-purpose convex optimization methods, because it uses message passing to take advantage of sparse dependency structures. We then show how to learn the parameters of HL-MRFs. The learned HL-MRFs are as accurate as analogous discrete models, but much more scalable. Together, these algorithms enable HL-MRFs and PSL to model rich, structured data at scales not previously possible. © 2017 Stephen H. Bach, Matthias Broecheler, Bert Huang, and Lise Getoor.",Journal of Machine Learning Research,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030465241&partnerID=40&md5=67d66dd080a7762a7424c6c7fa893df0,2017,7/20/21 15:49,7/20/21 15:49,824
64IWKYVY,journalArticle,2017,"Jiang, J.; Li, X.; Zhao, C.; Guan, Y.; Yu, Q.",Learning and inference in knowledge-based probabilistic model for medical diagnosis,1,,EHR,"Based on a weighted knowledge graph to represent first-order knowledge and combining it with a probabilistic model, we propose a methodology for creating a medical knowledge network (MKN) in medical diagnosis. When a set of evidence is activated for a specific patient, we can generate a ground medical knowledge network that is composed of evidence nodes and potential disease nodes. By incorporating a Boltzmann machine into the potential function of a Markov network, we investigated the joint probability distribution of the MKN. To consider numerical evidence, a multivariate inference model is presented that uses conditional probability. In addition, the weights for the knowledge graph are efficiently learned from manually annotated Chinese Electronic Medical Records (CEMRs) and Blood Examination Records (BERs). In our experiments, we found numerically that an improved expression of evidence variables is necessary for medical diagnosis. Our experimental results comparing a Markov logic network and six kinds of classic machine learning algorithms on the actual CEMR database and BER database indicate that our method holds promise and that MKN can facilitate studies of intelligent diagnosis. © 2017 Elsevier B.V.",Knowledge-Based Systems,10.1016/j.knosys.2017.09.030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033491118&doi=10.1016%2fj.knosys.2017.09.030&partnerID=40&md5=2779a352ea62c5ce9f70baee6dfd57c4,2017,7/20/21 15:49,7/20/21 15:49,826
YMP2X9RF,journalArticle,2016,"Melo, H.; Watada, J.",Gaussian-PSO with fuzzy reasoning based on structural learning for training a Neural Network,1,,,"This paper proposes Gaussian-PSO-based structural learning and fuzzy reasoning to optimize the weights and the structure of the Feed Forward Neural Network. The Neural Network is widely used for various applications; though it still has disadvantages such as learning capability and slow convergence. Back Propagation, the most used learning algorithm, has several difficulties such as the necessity for a priori specification of the network structure and sensibility to parameter settings. Recently, research studies have introduced evolutionary algorithms into the learning to improve its performance. The PSO is a population-based algorithm that has the advantage of faster convergence. However, the total number of the weights in the Neural Network determines the size of each particle, therefore the size of the network structure is computationally time consuming. The proposed method improves the learning and removes the stress by eliminating the necessity of determining a detailed network. © 2015 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2015.03.104,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947195900&doi=10.1016%2fj.neucom.2015.03.104&partnerID=40&md5=b3ddd10564886a80d91f7ae502893244,2016,7/20/21 15:49,7/20/21 15:49,837
F9P7AAGU,journalArticle,2013,"Gweon, G.; Jain, M.; McDonough, J.; Raj, B.; Rosé, C.P.",Measuring prevalence of other-oriented transactive contributions using an automated measure of speech style accommodation,1,,text,"This paper contributes to a theory-grounded methodological foundation for automatic collaborative learning process analysis. It does this by illustrating how insights from the social psychology and sociolinguistics of speech style provide a theoretical framework to inform the design of a computational model. The purpose of that model is to detect prevalence of an important group knowledge integration process in raw speech data. Specifically, this paper focuses on assessment of transactivity in dyadic discussions, where a transactive contribution is operationalized as one where reasoning is made explicit, and where that reasoning builds on a prior reasoning statement within the discussion. Transactive contributions can be either self-oriented, where the contribution builds on the speaker's own prior contribution, or other-oriented, where the contribution builds on a prior contribution of a conversational partner. Other-oriented transacts are particularly central to group knowledge integration processes. An unsupervised Dynamic Bayesian Network model motivated by concepts from Speech Accommodation Theory is presented and then evaluated on the task of estimating prevalence of other-oriented transacts in dyadic discussions. The evaluation demonstrates a significant positive correlation between an automatic measure of speech style accommodation and prevalence of other-oriented transacts (R=.36,p<.05). © 2013 International Society of the Learning Sciences, Inc. and Springer Science+Business Media New York.",International Journal of Computer-Supported Collaborative Learning,10.1007/s11412-013-9172-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878111202&doi=10.1007%2fs11412-013-9172-5&partnerID=40&md5=d1eeff681cee235d62290ec32eaae2c6,2013,7/20/21 15:49,7/20/21 15:49,838
3NK9NFCA,journalArticle,2021,"Paredes, J.N.; Simari, G.I.; Martinez, M.V.; Falappa, M.A.",Detecting malicious behavior in social platforms via hybrid knowledge- and data-driven systems,1,,text,"Among the wide variety of malicious behavior commonly observed in modern social platforms, one of the most notorious is the diffusion of fake news, given its potential to influence the opinions of millions of people who can be voters, consumers, or simply citizens going about their daily lives. In this paper, we implement and carry out an empirical evaluation of a version of the recently-proposed NETDER architecture for hybrid AI decision-support systems with the capability of leveraging the availability of machine learning modules, logical reasoning about unknown objects, and forecasts based on diffusion processes. NETDER is a general architecture for reasoning about different kinds of malicious behavior such as dissemination of fake news, hate speech, and malware, detection of botnet operations, prevention of cyber attacks including those targeting software products or blockchain transactions, among others. Here, we focus on the case of fake news dissemination on social platforms by three different kinds of users: non-malicious, malicious, and botnet members. In particular, we focus on three tasks: (i) determining who is responsible for posting a fake news article, (ii) detecting malicious users, and (iii) detecting which users belong to a botnet designed to disseminate fake news. Given the difficulty of obtaining adequate data with ground truth, we also develop a testbed that combines real-world fake news datasets with synthetically generated networks of users and fully-detailed traces of their behavior throughout a series of time points. We designed our testbed to be customizable for different problem sizes and settings, and make its code publicly available to be used in similar evaluation efforts. Finally, we report on the results of a thorough experimental evaluation of three variants of our model and six environmental settings over the three tasks. Our results clearly show the effects that the quality of knowledge engineering tasks, the quality of the underlying machine learning classifier used to detect fake news, and the specific environmental conditions have on smart policing efforts in social platforms. © 2021",Future Generation Computer Systems,10.1016/j.future.2021.06.033,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109435960&doi=10.1016%2fj.future.2021.06.033&partnerID=40&md5=a34f603a9fd4e7b466e9a757c0a86e14,2021,7/20/21 15:49,7/20/21 15:49,840
AKF9GTCC,journalArticle,2021,"Mittal, V.; Gangodkar, D.; Pant, B.",Deep Graph-Long Short-Term Memory: A Deep Learning Based Approach for Text Classification,1,,text,"Multi-label text classification is a challenging task in many real applications. Mostly, in all the traditional techniques, word2vec is used to show the sequential information among text. However, use of word2vec ignores logic and context relationship among text, and we treat each label as an individual unit. Therefore, the existing techniques failed to reflect the real scenarios and to gain the semantic information regarding the relationship among texts. In this paper, we propose a model Deep Graph-Long Short-Term Memory (DG-LSTM) for multi-label text classification. In the proposed model, we store the documents using the graph database. Initially, the documents are pre-processed using standard dictionaries, and afterwards it generates the classified dictionaries. These classified dictionaries are used to generate the subgraphs. The model maintains a lookup table to reduce the search space for the new documents. For classification, the model uses the deep learning technique DG-LSTM. DG-LSTM is using Deep Graph_Rectified Linear Unit activation function to avoid blow-up and dying neuron problem of Rectified Linear Unit activation function. We verify the proposed model on the legal case of Indian judiciary. The results show that the proposed model has achieved 99% accuracy to classify the fresh case into its corresponding category. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Wireless Personal Communications,10.1007/s11277-021-08331-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102699252&doi=10.1007%2fs11277-021-08331-4&partnerID=40&md5=a13427f15564e7ab393da239346bc278,2021,7/20/21 15:49,7/20/21 15:49,847
TIRWL4WH,journalArticle,2020,"Antony Rosewelt, L.; Arokia Renjit, J.",A content recommendation system for effective e-learning using embedded feature selection and fuzzy DT based CNN,1,,text,"This paper proposes a new content recommendation system which combines the newly proposed embedded feature selection method and the new Fuzzy Temporal Logic based Decision Tree incorporated Convolutional Neural Network classifier. The newly proposed embedded feature selection called Fuzzy Decision Tree and Weighted Gini-Index based Feature Selection Algorithm (FDTWGI-FSA) that contains the existing incorporated the Fuzzy Decision Tree (FDT) and the Weighted Gini-index based Feature Selection Algorithm (WGIFSA) for getting optimized feature subset. Moreover, an enhanced CNN and Fuzzy Temporal Decision Tree for performing the deep learning process which is able to identify the exact e-content from the huge volume of data with the help of the recommended features by the proposed embedded feature selection method. The exact e-content can be identified after performing the five-layer network structure for extracting the relevant features and it also can be classified by applying the Fuzzy Temporal Decision Tree for the e-learners. Finally, the proposed content recommendation system provides exact content to the e-learners according to their level of understanding and it also satisfies them by providing the exact high level contents. The experiments have been conducted for evaluating the proposed content recommendation system and compared with the existing classifier including the standard CNN. © 2020-IOS Press and the authors. All rights reserved.",Journal of Intelligent and Fuzzy Systems,10.3233/JIFS-191721,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088878886&doi=10.3233%2fJIFS-191721&partnerID=40&md5=d6e95b23bc57c38aafbc7ecf3cc736ec,2020,7/20/21 15:49,7/20/21 15:49,851
JCDQ6NSI,journalArticle,2021,"Confalonieri, R.; Weyde, T.; Besold, T.R.; Moscoso del Prado Martín, F.",Using ontologies to enhance human understandability of global post-hoc explanations of black-box models,1,,XAI,"The interest in explainable artificial intelligence has grown strongly in recent years because of the need to convey safety and trust in the ‘how’ and ‘why’ of automated decision-making to users. While a plethora of approaches has been developed, only a few focus on how to use domain knowledge and how this influences the understanding of explanations by users. In this paper, we show that by using ontologies we can improve the human understandability of global post-hoc explanations, presented in the form of decision trees. In particular, we introduce TREPAN Reloaded, which builds on TREPAN, an algorithm that extracts surrogate decision trees from black-box models. TREPAN Reloaded includes ontologies, that model domain knowledge, in the process of extracting explanations to improve their understandability. We tested the understandability of the extracted explanations by humans in a user study with four different tasks. We evaluate the results in terms of response times and correctness, subjective ease of understanding and confidence, and similarity of free text responses. The results show that decision trees generated with TREPAN Reloaded, taking into account domain knowledge, are significantly more understandable throughout than those generated by standard TREPAN. The enhanced understandability of post-hoc explanations is achieved with little compromise on the accuracy with which the surrogate decision trees replicate the behaviour of the original neural network models. © 2021 The Author(s)",Artificial Intelligence,10.1016/j.artint.2021.103471,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101138224&doi=10.1016%2fj.artint.2021.103471&partnerID=40&md5=bbcfd5ff1a22f14273d51db4dfb39fdf,2021,7/20/21 15:49,7/20/21 15:49,853
7I4CIKII,journalArticle,2017,"Carmantini, G.S.; beim Graben, P.; Desroches, M.; Rodrigues, S.",A modular architecture for transparent computation in recurrent neural networks,1,,text,"Computation is classically studied in terms of automata, formal languages and algorithms; yet, the relation between neural dynamics and symbolic representations and operations is still unclear in traditional eliminative connectionism. Therefore, we suggest a unique perspective on this central issue, to which we would like to refer as transparent connectionism, by proposing accounts of how symbolic computation can be implemented in neural substrates. In this study we first introduce a new model of dynamics on a symbolic space, the versatile shift, showing that it supports the real-time simulation of a range of automata. We then show that the Gödelization of versatile shifts defines nonlinear dynamical automata, dynamical systems evolving on a vectorial space. Finally, we present a mapping between nonlinear dynamical automata and recurrent artificial neural networks. The mapping defines an architecture characterized by its granular modularity, where data, symbolic operations and their control are not only distinguishable in activation space, but also spatially localizable in the network itself, while maintaining a distributed encoding of symbolic representations. The resulting networks simulate automata in real-time and are programmed directly, in the absence of network training. To discuss the unique characteristics of the architecture and their consequences, we present two examples: (i) the design of a Central Pattern Generator from a finite-state locomotive controller, and (ii) the creation of a network simulating a system of interactive automata that supports the parsing of garden-path sentences as investigated in psycholinguistics experiments. © 2016 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2016.09.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994319086&doi=10.1016%2fj.neunet.2016.09.001&partnerID=40&md5=748c2c3637c624ca09c0929de9c95e1d,2017,7/20/21 15:49,7/20/21 15:49,854
M934ED4J,journalArticle,2020,"Leelavathy, S.; Nithya, M.",Public opinion mining using natural language processing technique for improvisation towards smart city,1,,covid,"In this digital world integrating smart city concepts, there is a tremendous scope and need for e-governance applications. Now people analyze the opinion of others before purchasing any product, hotel booking, stepping onto restaurants etc. and the respective user share their experience as a feedback towards the service. But there is no e-governance platform to obtain public opinion grievances towards covid19, government new laws, policies etc. With the growing availability and emergence of opinion rich information’s, new opportunities and challenges might arise in developing a technology for mining the huge set of public messages, opinions and alert the respective departments to take necessary actions and also nearby ambulances if its related to covid-19. To overcome this pandemic situation a natural language processing based efficient e-governance platform is demandful to detect the corona positive patients and provide transparency on the covid count and also alert the respective health ministry and nearby ambulance based on the user voice inputs. To convert the public voice messages into text, we used Hidden Markov Models (HMMs). To identify respective government department responsible for the respective user voice input, we perform pre-processing, part of speech, unigram, bigram, trigram analysis and fuzzy logic (machine learning technique). After identifying the responsible department, we perform 2 methods, (1) Automatic alert e-mail and message to the government departmental officials and nearby ambulance or covid camp if the user input is related to covis19. (2) Ticketing system for public and government officials monitoring. For experimental results, we used Java based web and mobile application to execute the proposed methodology. Integration of HMM, Fuzzy logic provides promising results. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.",International Journal of Speech Technology,10.1007/s10772-020-09766-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096022565&doi=10.1007%2fs10772-020-09766-z&partnerID=40&md5=451d9cb8aae0a99d5e178d6f623b035f,2020,7/20/21 15:49,7/20/21 15:49,856
PE6WNP93,journalArticle,2020,"Muñoz, L.; Trujillo, L.; Silva, S.",Transfer learning in constructive induction with Genetic Programming,1,,UNK,"Transfer learning (TL) is the process by which some aspects of a machine learning model generated on a source task is transferred to a target task, to simplify the learning required to solve the target. TL in Genetic Programming (GP) has not received much attention, since it is normally assumed that an evolved symbolic expression is specifically tailored to a problem’s data and thus cannot be used in other problems. The goal of this work is to present a broad and diverse study of TL in GP, considering a varied set of source and target tasks, and dealing with questions that have received little, or no attention, in previous GP literature. In particular, this work studies the performance of transferred solutions when the source and target tasks are from different domains, and when they do not share a similar input feature space. Additionally, the relationship between the success and failure of transferred solutions is studied, considering different source and target tasks. Finally, the predictability of TL performance is analyzed for the first time in GP literature. GP-based constructive induction of features is used to carry out the study, a wrapper-based approach where GP is used to construct feature transformations and an additional learning algorithm is used to fit the final model. The experimental work presents several notable results and contributions. First, TL is capable of generating solutions that outperform, in many cases, baseline methods in classification and regression tasks. Second, it is shown that some problems are good source problems while others are good targets in a TL system. Third, the transferability of solutions is not necessarily symmetric between two problems. Finally, results show that it is possible to predict the success of TL in some cases, particularly in classification tasks. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",Genetic Programming and Evolvable Machines,10.1007/s10710-019-09368-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074947704&doi=10.1007%2fs10710-019-09368-y&partnerID=40&md5=cd8c2b91b8438e2f1a557eed6f25c8b5,2020,7/20/21 15:49,7/20/21 15:49,858
HSBR4X9E,journalArticle,2021,"Šourek, G.; Železný, F.; Kuželka, O.",Beyond graph neural networks with lifted relational neural networks,1,,UNK,"We introduce a declarative differentiable programming framework, based on the language of Lifted Relational Neural Networks, where small parameterized logic programs are used to encode deep relational learning scenarios through the underlying symmetries. When presented with relational data, such as various forms of graphs, the logic program interpreter dynamically unfolds differentiable computation graphs to be used for the program parameter optimization by standard means. Following from the declarative, relational logic-based encoding, this results into a unified representation of a wide range of neural models in the form of compact and elegant learning programs, in contrast to the existing procedural approaches operating directly on the computational graph level. We illustrate how this idea can be used for a concise encoding of existing advanced neural architectures, with the main focus on Graph Neural Networks (GNNs). Importantly, using the framework, we also show how the contemporary GNN models can be easily extended towards higher expressiveness in various ways. In the experiments, we demonstrate correctness and computation efficiency through comparison against specialized GNN frameworks, while shedding some light on the learning performance of the existing GNN models. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.",Machine Learning,10.1007/s10994-021-06017-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107933318&doi=10.1007%2fs10994-021-06017-3&partnerID=40&md5=b2968eb7449989b12c78a1b0ef9fbb03,2021,7/20/21 15:49,7/20/21 15:49,873
XHDRS8R3,journalArticle,2020,"Dashtipour, K.; Gogate, M.; Li, J.; Jiang, F.; Kong, B.; Hussain, A.",A hybrid Persian sentiment analysis framework: Integrating dependency grammar based rules and deep neural networks,1,,text,"Social media hold valuable, vast and unstructured information on public opinion that can be utilized to improve products and services. The automatic analysis of such data, however, requires a deep understanding of natural language. Current sentiment analysis approaches are mainly based on word co-occurrence frequencies, which are inadequate in most practical cases. In this work, we propose a novel hybrid framework for concept-level sentiment analysis in Persian language, that integrates linguistic rules and deep learning to optimize polarity detection. When a pattern is triggered, the framework allows sentiments to flow from words to concepts based on symbolic dependency relations. When no pattern is triggered, the framework switches to its subsymbolic counterpart and leverages deep neural networks (DNN) to perform the classification. The proposed framework outperforms state-of-the-art approaches (including support vector machine, and logistic regression) and DNN classifiers (long short-term memory, and Convolutional Neural Networks) with a margin of 10–15% and 3–4% respectively, using benchmark Persian product and hotel reviews corpora. © 2019",Neurocomputing,10.1016/j.neucom.2019.10.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075436840&doi=10.1016%2fj.neucom.2019.10.009&partnerID=40&md5=ed6a3b3b822b73e53f969d9f34d7a645,2020,7/20/21 15:49,7/20/21 15:49,877
XEE25WKH,journalArticle,2014,"Román, P.E.; Velásquez, J.D.",A neurology-inspired model of web usage,1,,UNK,"The problem of predicting human behavior has been a great challenge for several disciplines including computer science. In particular, web user browsing behavior has been studied from the machine learning point of view, a field that has been coined web usage mining (WUM). However, current WUM techniques can be negatively impacted by changes in web site structure and content (e.g. Web 2.0). The key reason behind this issue may be that machine learning algorithms learn the observed behavior according to a particular training set, but do not model the user behavior under different conditions. We propose a simulation model that mimics human interaction with the web by recovering observed navigational steps. This web usage model is inspired by a neurophysiology's stochastic description of decision making and by the information utility of web page content. The proposed model corresponds to a high-dimensional stochastic process based on the leaky competing accumulator (LCA) neural model. We solve high-dimensional issues by considering a mesh-less symbolic interpolation. As a proof-of-concept we test the web user simulation system on an academic web site by recovering most of the observed behavior (73%). Therefore, our approach operationally describes web users that seem to react as observed users confronted by changes in the web site interface. © 2013 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2013.10.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894088597&doi=10.1016%2fj.neucom.2013.10.012&partnerID=40&md5=0f53d764131cd641e0fcf9f9ef069acd,2014,7/20/21 15:49,7/20/21 15:49,901
67L5K36W,journalArticle,2018,"Zhu, Q.; Wu, Y.; Li, Y.; Han, J.; Zhou, X.",Text mining based theme logic structure identification: application in library journals,1,,text,"Purpose: Library intelligence institutions, which are a kind of traditional knowledge management organization, are at the frontline of the big data revolution, in which the use of unstructured data has become a modern knowledge management resource. The paper aims to discuss this issue. Design/methodology/approach: This research combined theme logic structure (TLS), artificial neural network (ANN), and ensemble empirical mode decomposition (EEMD) to transform unstructured data into a signal-wave to examine the research characteristics. Findings: Research characteristics have a vital effect on knowledge management activities and management behavior through concentration and relaxation, and ultimately form a quasi-periodic evolution. Knowledge management should actively control the evolution of the research characteristics because the natural development of six to nine years was found to be difficult to plot. Originality/value: Periodic evaluation using TLS-ANN-EEMD gives insights into journal evolution and allows journal managers and contributors to follow the intrinsic mode functions and predict the journal research characteristics tendencies. © 2018, Qing Zhu, Yiqiong Wu, Yuze Li, Jing Han and Xiaoyang Zhou.",Library Hi Tech,10.1108/LHT-10-2017-0211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044566896&doi=10.1108%2fLHT-10-2017-0211&partnerID=40&md5=9da2bc405318a871b9837f75914e87f4,2018,7/20/21 15:49,7/20/21 15:49,905
4ZLMDYNN,journalArticle,2021,"Shalyminov, I.; Sordoni, A.; Atkinson, A.; Schulz, H.",GRTr: Generative-Retrieval Transformers for Data-Efficient Dialogue Domain Adaptation,1,,UNK,"Domain adaptation has recently become a key problem in dialogue systems research. Deep learning, while being the preferred technique for modeling such systems, works best given massive training data. However, in real-world scenarios, such resources are rarely available for new domains, and the ability to train with a few dialogue examples can be considered essential. Pre-training on large data sources and adapting to the target data has become the standard method for few-shot problems within the deep learning framework. In this paper, we present GRTr, a hybrid generative-retrieval model based on the large-scale general-purpose language model GPT-2 fine-tuned to the multi-domain MetaLWOz dataset. In addition to robust and diverse response generation provided by the GPT-2, our model is able to estimate generation confidence, and is equipped with retrieval logic as a fallback for the cases when the estimate is low. GRTr is the winning entry at the fast domain adaptation task of DSTC-8 in human evaluation (&gt;4% improvement over the 2nd place system). It also attains superior performance to a series of baselines on automated metrics on MetaLWOz and MultiWoz, a multi-domain dataset of goal-oriented dialogues. In this paper, we also conduct a study of GRTr's performance in the setup of limited adaptation data, evaluating the model's overall response prediction performance on MetaLWOz and goal-oriented performance on MultiWoz. IEEE",IEEE/ACM Transactions on Audio Speech and Language Processing,10.1109/TASLP.2021.3074779,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104642179&doi=10.1109%2fTASLP.2021.3074779&partnerID=40&md5=9f53f5bcd7645da6dae9dce68c2de6be,2021,7/20/21 15:49,7/20/21 15:49,910
PHLLBDJ6,journalArticle,2015,"Cambria, E.; Gastaldo, P.; Bisio, F.; Zunino, R.",An ELM-based model for affective analogical reasoning,1,,text,"Between the dawn of the Internet through year 2003, there were just a few dozens exabytes of information on the Web. Today, that much information is created weekly. The opportunity to capture the opinions of the general public about social events, political movements, company strategies, marketing campaigns, and product preferences has raised increasing interest both in the scientific community, for the exciting open challenges, and in the business world, for the remarkable fallouts in marketing and financial prediction. Keeping up with the ever-growing amount of unstructured information on the Web, however, is a formidable task and requires fast and efficient models for opinion mining. In this paper, we explore how the high generalization performance, low computational complexity, and fast learning speed of extreme learning machines can be exploited to perform analogical reasoning in a vector space model of affective common-sense knowledge. In particular, by enabling a fast reconfiguration of such a vector space, extreme learning machines allow the polarity associated with natural language concepts to be calculated in a more dynamic and accurate way and, hence, perform better concept-level sentiment analysis. © 2014 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2014.01.064,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969228568&doi=10.1016%2fj.neucom.2014.01.064&partnerID=40&md5=98817fd95ea15415776848a46a1d30b3,2015,7/20/21 15:49,7/20/21 15:49,913
B9IDA3AQ,journalArticle,2020,"Pazienza, A.; Grossi, D.; Grasso, F.; Palmieri, R.; Zito, M.; Ferilli, S.",An abstract argumentation approach for the prediction of analysts' recommendations following earnings conference calls,1,,text,"Financial analysts constitute an important element of financial decision-making in stock exchanges throughout the world. By leveraging on argumentative reasoning, we develop a method to predict financial analysts' recommendations in earnings conference calls (ECCs), an important type of financial communication. We elaborate an analysis to select those reliable arguments in the Questions Answers (QA) part of ECCs that analysts evaluate to estimate their recommendation. The observation date of stock recommendation update may variate during the next quarter: it can be either the day after the ECC or it can take weeks. Our objective is to anticipate analysts' recommendations by predicting their judgment with the help of abstract argumentation. In this paper, we devise our approach to the analysis of ECCs, by designing a general processing framework which combines natural language processing along with abstract argumentation evaluation techniques to produce a final scoring function, representing the analysts' prediction about the company's trend. Then, we evaluate the performance of our approach by specifying a strategy to predict analysts recommendations starting from the evaluation of the argumentation graph properly instantiated from an ECC transcript. We also provide the experimental setting in which we perform the predictions of recommendations as a machine learning classification task. The method is shown to outperform approaches based only on sentiment analysis. © 2019-IOS Press and the authors. All rights reserved.",Intelligenza Artificiale,10.3233/IA-190026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078915179&doi=10.3233%2fIA-190026&partnerID=40&md5=490d26156f4e3c618e5ac0fbe3b3f566,2020,7/20/21 15:49,7/20/21 15:49,943
T87KI7TJ,journalArticle,2018,"Gou, Z.; Han, L.; Sun, L.; Zhu, J.; Yan, H.",Constructing Dynamic Topic Models Based on Variational Autoencoder and Factor Graph,1,,text,"Topic models are widely used in various fields of machine learning and statistics. Among them, the dynamic topic model (DTM) is the most popular time-series topic model for the dynamic representations of text corpora. A major challenge is that the posterior distribution of DTM requires a complex reasoning process with the high cost of computing time in modeling, and even a tiny change of model requires restructuring. For these reasons, the variability and generality of DTM is so poor that DTM is difficult to be carried out. In this paper, we introduce a new method for constructing DTM based on variational autoencoder and factor graphs. This model uses re-parameterization of the variational lower bound to generate a lower bound estimator which is optimized by standard stochastic gradient descent method directly. At the same time, the optimization process is simplified by integrating the dynamic factor graph in the state space to achieve a better model. The experimental dataset uses a journal paper corpus that mainly focuses on natural language processing and spans twenty-five years (1984-2009) from DBLP. Experiment results indicate that the proposed method is effective and feasible by comparing several state-of-the-art baselines. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2018.2869838,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053353852&doi=10.1109%2fACCESS.2018.2869838&partnerID=40&md5=59dd2a048ecf2f36f43422ec72fbab6d,2018,7/20/21 15:49,7/20/21 15:49,951
TFKKNJ57,journalArticle,2021,"Davis, G.P.; Katz, G.E.; Gentili, R.J.; Reggia, J.A.",Compositional memory in attractor neural networks with one-step learning,1,,,"Compositionality refers to the ability of an intelligent system to construct models out of reusable parts. This is critical for the productivity and generalization of human reasoning, and is considered a necessary ingredient for human-level artificial intelligence. While traditional symbolic methods have proven effective for modeling compositionality, artificial neural networks struggle to learn systematic rules for encoding generalizable structured models. We suggest that this is due in part to short-term memory that is based on persistent maintenance of activity patterns without fast weight changes. We present a recurrent neural network that encodes structured representations as systems of contextually-gated dynamical attractors called attractor graphs. This network implements a functionally compositional working memory that is manipulated using top-down gating and fast local learning. We evaluate this approach with empirical experiments on storage and retrieval of graph-based data structures, as well as an automated hierarchical planning task. Our results demonstrate that compositional structures can be stored in and retrieved from neural working memory without persistent maintenance of multiple activity patterns. Further, memory capacity is improved by the use of a fast store-erase learning rule that permits controlled erasure and mutation of previously learned associations. We conclude that the combination of top-down gating and fast associative learning provides recurrent neural networks with a robust functional mechanism for compositional working memory. © 2021 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2021.01.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101137555&doi=10.1016%2fj.neunet.2021.01.031&partnerID=40&md5=a0df50a5452361f7d5d07cc1de096c46,2021,7/20/21 15:49,7/20/21 15:49,977
3SI4RLKT,journalArticle,2021,"Zia, T.; Windridge, D.",A generative adversarial network for single and multi-hop distributional knowledge base completion,1,,KG,"Knowledge bases (KBs) inherently lack reasoning ability, limiting their effectiveness for tasks such as question–answering and query expansion. Machine-learning is hence commonly employed for representation learning in order to learn semantic features useful for generalization. Most existing methods utilize discriminative models that require both positive and negative samples to learn a decision boundary. KBs, by contrast, contain only positive samples, necessitating that negative samples are generated by replacing the head/tail of predicates with randomly-chosen entities. They are thus frequently easily discriminable from positive samples, which can prevent learning of sufficiently robust classifiers. Generative models, however, do not require negative samples to learn the distribution of positive samples; stimulated by recent developments in Generative Adversarial Networks (GANs), we propose a novel framework, Knowledge Completion GANs (KCGANs), for competitively training generative link prediction models against discriminative belief prediction models. KCGAN thus invokes a game between generator-network G and discriminator-network D in which G aims to understand underlying KB structure by learning to perform link prediction while D tries to gain knowledge about the KB by learning predicate/triplet classification. Two key challenges are addressed: 1) Classical GAN architectures’ inability to easily generate samples over discrete entities; 2) the inefficiency of softmax for learning distributions over large sets of entities. As a step toward full first-order logical reasoning we further extend KCGAN to learn multi-hop logical entailment relations between entities by enabling G to compose a multi-hop relational path between entities and D to discriminate between real and fake paths. KCGAN is tested on benchmarks WordNet and FreeBase datasets and evaluated on link prediction and belief prediction tasks using MRR and HIT@ 10, achieving best-in-class performance. © 2021 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2021.04.128,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108940773&doi=10.1016%2fj.neucom.2021.04.128&partnerID=40&md5=858f493b94639ee1fe9db18ed8b75e2f,2021,7/20/21 15:49,7/20/21 15:49,978
SG97K89D,journalArticle,2019,"Patel, D.; Shah, S.; Chhinkaniwala, H.",Fuzzy logic based multi document summarization with improved sentence scoring and redundancy removal technique,1,,text,"Nowadays abundant amount of information is available on Internet which makes it difficult for the users to locate desired information. Automatic methods are needed to efficiently sieve and scavenge useful information from the Internet. Text summarization is identified and accepted as one of the solutions to find desired contents from one or more documents. The objective of proposed multi-document summarization is to gain good content coverage with information diversity. The proposed statistical feature based model utilizes the fuzzy model to deal with the imprecise and uncertainty of feature weight. Redundancy removal using cosine similarity is presented as enrichment to proposed work. The proposed approach is compared with DUC (Document Understanding Conference) participant systems and other summarization systems such as TexLexAn, ItemSum, Yago Summarizer, MSSF and PatSum using ROUGE measure on dataset DUC 2004. The experimental results show that our proposed work achieves a significant performance improvement over the other summarizers. © 2019",Expert Systems with Applications,10.1016/j.eswa.2019.05.045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066788806&doi=10.1016%2fj.eswa.2019.05.045&partnerID=40&md5=dc17439ed577c1bf1eda54ad9a45e52f,2019,7/20/21 15:49,7/20/21 15:49,985
CBUVV5TK,journalArticle,2021,"Amador-Domínguez, E.; Serrano, E.; Manrique, D.; Hohenecker, P.; Lukasiewicz, T.",An ontology-based deep learning approach for triple classification with out-of-knowledge-base entities,1,,KG,"Knowledge graphs (KGs) are one of the most common frameworks for knowledge representation. However, they suffer from a severe scalability problem that hinders their usage. KG embedding aims to provide a solution to this issue. Nonetheless, general approaches are incapable of representing and reasoning about information not previously contained in the graph. This paper proposes to leverage semantic and ontological information for a significant benefit of knowledge graph completion, focusing on triple classification. The goal of this task is to determine whether a given fact holds. Furthermore, this paper also considers the classification of facts that include entities that have not been seen during training, denoted out-of-knowledge-base or OOKB entities. An incremental method is presented, composed of six stages. Although the proposal can be applied to any KG embedding model, this work focuses on its application for semantic matching models, such as ComplEx and DistMult. Compared to other approaches, our proposal is model-agnostic, computationally inexpensive, and does not require retraining. The results show that triple classification accuracy scales up to 15% with the proposed approach, as well as accelerating the convergence of the model to its optimal solution. Furthermore, facts containing OOKB entities can be classified with a reasonable accuracy. © 2021 Elsevier Inc.",Information Sciences,10.1016/j.ins.2021.02.018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102271445&doi=10.1016%2fj.ins.2021.02.018&partnerID=40&md5=45df46e472c45e6d29b8a28ce0877665,2021,7/20/21 15:49,7/20/21 15:49,990
VVW2E88P,journalArticle,2017,"Cambria, E.; Poria, S.; Gelbukh, A.; Thelwall, M.",Sentiment Analysis Is a Big Suitcase,1,,text,"Although most works approach it as a simple categorization problem, sentiment analysis is actually a suitcase research problem that requires tackling many natural language processing (NLP) tasks. The expression 'sentiment analysis' itself is a big suitcase (like many others related to affective computing, such as emotion recognition or opinion mining) that all of us use to encapsulate our jumbled idea about how our minds convey emotions and opinions through natural language. The authors address the composite nature of the problem via a three-layer structure inspired by the 'jumping NLP curves' paradigm. In particular, they argue that there are (at least) 15 NLP problems that need to be solved to achieve human-like performance in sentiment analysis. © 2017 IEEE.",IEEE Intelligent Systems,10.1109/MIS.2017.4531228,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038582534&doi=10.1109%2fMIS.2017.4531228&partnerID=40&md5=a1a4abcf7cd5bd1c41b4e88e7e3d64f7,2017,7/20/21 15:49,7/20/21 15:49,1000
BAMGPUCX,journalArticle,2021,"Es-Sabery, F.; Hair, A.; Qadir, J.; Sainz-De-Abajo, B.; Garcia-Zapirain, B.; Torre-DIez, I.",Sentence-Level Classification Using Parallel Fuzzy Deep Learning Classifier,1,,text,"At present, with the growing number of Web 2.0 platforms such as Instagram, Facebook, and Twitter, users honestly communicate their opinions and ideas about events, services, and products. Owing to this rise in the number of social platforms and their extensive use by people, enormous amounts of data are produced hourly. However, sentiment analysis or opinion mining is considered as a useful tool that aims to extract the emotion and attitude from the user-posted data on social media platforms by using different computational methods to linguistic terms and various Natural Language Processing (NLP). Therefore, enhancing text sentiment classification accuracy has become feasible, and an interesting research area for many community researchers. In this study, a new Fuzzy Deep Learning Classifier (FDLC) is suggested for improving the performance of data-sentiment classification. Our proposed FDLC integrates Convolutional Neural Network (CNN) to build an effective automatic process for extracting the features from collected unstructured data and Feedforward Neural Network (FFNN) to compute both positive and negative sentimental scores. Then, we used the Mamdani Fuzzy System (MFS) as a fuzzy classifier to classify the outcomes of the two used deep (CNN+FFNN) learning models in three classes, which are: Neutral, Negative, and Positive. Also, to prevent the long execution time taking by our hybrid proposed FDLC, we have implemented our proposal under the Hadoop cluster. An experimental comparative study between our FDLC and some other suggestions from the literature is performed to demonstrate our offered classifier's effectiveness. The empirical result proved that our FDLC performs better than other classifiers in terms of true positive rate, true negative rate, false positive rate, false negative rate, error rate, precision, classification rate, kappa statistic, F1-score and time consumption, complexity, convergence, and stability. © 2013 IEEE.",IEEE Access,10.1109/ACCESS.2021.3053917,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106847388&doi=10.1109%2fACCESS.2021.3053917&partnerID=40&md5=0ac6e3c956a44104600e5c8a92fc0476,2021,7/20/21 15:49,7/20/21 15:49,1006
XVUJBUP5,journalArticle,2021,"Zhang, L.; Shi, Y.; Chang, Y.-C.; Lin, C.-T.",Hierarchical Fuzzy Neural Networks with Privacy Preservation for Heterogeneous Big Data,1,,UNK,"Heterogeneous big data poses many challenges in machine learning. Its enormous scale, high dimensionality, and inherent uncertainty make almost every aspect of machine learning difficult, from providing enough processing power to maintaining model accuracy to protecting privacy. However, perhaps the most imposing problem is that big data is often interspersed with sensitive personal data. Hence, we propose a privacy-preserving hierarchical fuzzy neural network to address these technical challenges while also alleviating privacy concerns. The network is trained with a two-stage optimization algorithm, and the parameters at low levels of the hierarchy are learned with a scheme based on the well-known alternating direction method of multipliers, which does not reveal local data to other agents. Coordination at high levels of the hierarchy is handled by the alternating optimization method, which converges very quickly. The entire training procedure is scalable, fast, and does not suffer from gradient vanishing problems like the methods based on backpropagation. Comprehensive simulations conducted on both regression and classification tasks demonstrate the effectiveness of the proposed model. Our code is available online.1 © 1993-2012 IEEE.",IEEE Transactions on Fuzzy Systems,10.1109/TFUZZ.2020.3021713,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098843078&doi=10.1109%2fTFUZZ.2020.3021713&partnerID=40&md5=cb20c08733fe940098aa9f0c1d33089e,2021,7/20/21 15:49,7/20/21 15:49,1034
IG4KHQSM,journalArticle,2019,"Sun, X.; Li, J.; Wei, X.; Li, C.; Tao, J.",Emotional conversation generation based on a Bayesian deep neural network,1,,text,"The field of conversation generation using neural networks has attracted increasing attention from researchers for several years. However, traditional neural language models tend to generate a generic reply with poor semantic logic and no emotion. This article proposes an emotional conversation generation model based on a Bayesian deep neural network that can generate replies with rich emotions, clear themes, and diverse sentences. The topic and emotional keywords of the replies are pregenerated by introducing commonsense knowledge in the model. The reply is divided into multiple clauses, and then a multidimensional generator based on the transformer mechanism proposed in this article is used to iteratively generate clauses from two dimensions: sentence granularity and sentence structure. Subjective and objective experiments prove that compared with existing models, the proposed model effectively improves the semantic logic and emotional accuracy of replies. This model also significantly enhances the diversity of replies, largely overcoming the shortcomings of traditional models that generate safe replies. © 2019 Association for Computing Machinery.",ACM Transactions on Information Systems,10.1145/3368960,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077738395&doi=10.1145%2f3368960&partnerID=40&md5=e84bcd5ec75b7b4322b5fd977232f89e,2019,7/20/21 15:49,7/20/21 15:49,1046
47J9ZIZM,journalArticle,2021,"Yang, M.; Li, C.; Shen, Y.; Wu, Q.; Zhao, Z.; Chen, X.",Hierarchical Human-Like Deep Neural Networks for Abstractive Text Summarization,1,,text,"Developing an abstractive text summarization (ATS) system that is capable of generating concise, appropriate, and plausible summaries for the source documents is a long-term goal of artificial intelligence (AI). Recent advances in ATS are overwhelmingly contributed by deep learning techniques, which have taken the state-of-the-art of ATS to a new level. Despite the significant success of previous methods, generating high-quality and human-like abstractive summaries remains a challenge in practice. The human reading cognition, which is essential for reading comprehension and logical thinking, is still relatively new territory and underexplored in deep neural networks. In this article, we propose a novel Hierarchical Human-like deep neural network for ATS (HH-ATS), inspired by the process of how humans comprehend an article and write the corresponding summary. Specifically, HH-ATS is composed of three primary components (i.e., a knowledge-aware hierarchical attention module, a multitask learning module, and a dual discriminator generative adversarial network), which mimic the three stages of human reading cognition (i.e., rough reading, active reading, and postediting). Experimental results on two benchmark data sets (CNN/Daily Mail and Gigaword) demonstrate that HH-ATS consistently and substantially outperforms the compared methods. © 2012 IEEE.",IEEE Transactions on Neural Networks and Learning Systems,10.1109/TNNLS.2020.3008037,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100259165&doi=10.1109%2fTNNLS.2020.3008037&partnerID=40&md5=649e7637a269915317549fbafb407cca,2021,7/20/21 15:49,7/20/21 15:49,1048
VVV3WT9M,journalArticle,2020,"Dasgupta, I.; Guo, D.; Gershman, S.J.; Goodman, N.D.",Analyzing Machine-Learned Representations: A Natural Language Case Study,1,,text,"As modern deep networks become more complex, and get closer to human-like capabilities in certain domains, the question arises as to how the representations and decision rules they learn compare to the ones in humans. In this work, we study representations of sentences in one such artificial system for natural language processing. We first present a diagnostic test dataset to examine the degree of abstract composable structure represented. Analyzing performance on these diagnostic tests indicates a lack of systematicity in representations and decision rules, and reveals a set of heuristic strategies. We then investigate the effect of training distribution on learning these heuristic strategies, and we study changes in these representations with various augmentations to the training set. Our results reveal parallels to the analogous representations in people. We find that these systems can learn abstract rules and generalize them to new contexts under certain circumstances—similar to human zero-shot reasoning. However, we also note some shortcomings in this generalization behavior—similar to human judgment errors like belief bias. Studying these parallels suggests new ways to understand psychological phenomena in humans as well as informs best strategies for building artificial intelligence with human-like language understanding. © 2020 Cognitive Science Society, Inc",Cognitive Science,10.1111/cogs.12925,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097923303&doi=10.1111%2fcogs.12925&partnerID=40&md5=dad2264ea4b2a90bf7be0d381181e603,2020,7/20/21 15:49,7/20/21 15:49,1055
GIC4LEU4,journalArticle,2013,"Dsouza, S.; Gal, Y.K.; Pasquier, P.; Abdallah, S.; Rahwan, I.",Reasoning about goal revelation in human negotiation,1,,text,"This article studies how people reveal private information in strategic settings in which participants need to negotiate over resources but are uncertain about each other's objectives. The study compares two negotiation protocols that differ in whether they allow participants to disclose their objectives in a repeated negotiation setting of incomplete information. Results show that most people agree to reveal their goals when asked, and this leads participants to more beneficial agreements. Machine learning was used to model the likelihood that people reveal their goals in negotiation, and this model was used to make goal request decisions in the game. In simulation, use of this model is shown to outperform people making the same type of decisions. These results demonstrate the benefit of this approach towards designing agents to negotiate with people under incomplete information. © 2001-2011 IEEE.",IEEE Intelligent Systems,10.1109/MIS.2011.93,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880665809&doi=10.1109%2fMIS.2011.93&partnerID=40&md5=0b4bef3569f1b205ceee506706e80fae,2013,7/20/21 15:49,7/20/21 15:49,1093
DBNFFD67,journalArticle,2021,"Es-sabery, F.; Hair, A.; Qadir, J.; Sainz-de-Abajo, B.; Garcia-Zapirain, B.; De La Torre-Diez, I.",Sentence-Level Classification Using Parallel Fuzzy Deep Learning Classifier,1,,text,"At present, with the growing number of Web 2.0 platforms such as Instagram, Facebook, and Twitter, users honestly communicate their opinions and ideas about events, services, and products. Owing to this rise in the number of social platforms and their extensive use by people, enormous amounts of data are produced hourly. However, sentiment analysis or opinion mining is considered as a useful tool that aims to extract the emotion and attitude from the user-posted data on social media platforms by using different computational methods to linguistic terms and various Natural Language Processing (NLP). Therefore, enhancing text sentiment classification accuracy has become feasible, and an interesting research area for many community researchers. In this study, a new Fuzzy Deep Learning Classifier (FDLC) is suggested for improving the performance of data-sentiment classification. Our proposed FDLC integrates Convolutional Neural Network (CNN) to build an effective automatic process for extracting the features from collected unstructured data and Feedforward Neural Network (FFNN) to compute both positive and negative sentimental scores. Then, we used the Mamdani Fuzzy System (MFS) as a fuzzy classifier to classify the outcomes of the two used deep (CNN+FFNN) learning models in three classes, which are: Neutral, Negative, and Positive. Also, to prevent the long execution time taking by our hybrid proposed FDLC, we have implemented our proposal under the Hadoop cluster. An experimental comparative study between our FDLC and some other suggestions from the literature is performed to demonstrate our offered classifier&#x2019;s effectiveness. The empirical result proved that our FDLC performs better than other classifiers in terms of true positive rate, true negative rate, false positive rate, false negative rate, error rate, precision, classification rate, kappa statistic, F1-score and time consumption, complexity, convergence, and stability. CCBY",IEEE Access,10.1109/ACCESS.2021.3053917,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100468874&doi=10.1109%2fACCESS.2021.3053917&partnerID=40&md5=396f7ce7ea930aa7a7d3b8af2dc2c3fa,2021,7/20/21 15:49,7/20/21 15:49,1094
LVKTK7F6,journalArticle,2020,"Wang, G.; Jia, Q.-S.; Qiao, J.; Bi, J.; Liu, C.",A sparse deep belief network with efficient fuzzy learning framework,1,,UNK,"Deep belief network (DBN) is one of the most feasible ways to realize deep learning (DL) technique, and it has been attracting more and more attentions in nonlinear system modeling. However, DBN cannot provide satisfactory results in learning speed, modeling accuracy and robustness, which is mainly caused by dense representation and gradient diffusion. To address these problems and promote DBN's development in cross-models, we propose a Sparse Deep Belief Network with Fuzzy Neural Network (SDBFNN) for nonlinear system modeling. In this novel framework, the sparse DBN is considered as a pre-training technique to realize fast weight-initialization and to obtain feature vectors. It can balance the dense representation to improve its robustness. A fuzzy neural network is developed for supervised modeling so as to eliminate the gradient diffusion. Its input happens to be the obtained feature vector. As a novel cross-model, SDBFNN combines the advantages of both pre-training technique and fuzzy neural network to improve modeling capability. Its convergence is also analyzed as well. A benchmark problem and a practical problem in wastewater treatment are conducted to demonstrate the superiority of SDBFNN. The extensive experimental results show that SDBFNN achieves better performance than the existing methods in learning speed, modeling accuracy and robustness. © 2019 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2019.09.035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073015074&doi=10.1016%2fj.neunet.2019.09.035&partnerID=40&md5=6bfde4b2aed5b3dec2ea75bf3f96855e,2020,7/20/21 15:49,7/20/21 15:49,1153
Z7DF4QH9,journalArticle,2017,"Zerva, C.; Batista-Navarro, R.; Day, P.; Ananiadou, S.",Using uncertainty to link and rank evidence from biomedical literature for model curation,1,,text,"Motivation: In recent years, there has been great progress in the field of automated curation of biomedical networks and models, aided by text mining methods that provide evidence from literature. Such methods must not only extract snippets of text that relate to model interactions, but also be able to contextualize the evidence and provide additional confidence scores for the interaction in question. Although various approaches calculating confidence scores have focused primarily on the quality of the extracted information, there has been little work on exploring the textual uncertainty conveyed by the author. Despite textual uncertainty being acknowledged in biomedical text mining as an attribute of text mined interactions (events), it is significantly understudied as a means of providing a confidence measure for interactions in pathways or other biomedical models. In this work, we focus on improving identification of textual uncertainty for events and explore how it can be used as an additional measure of confidence for biomedical models. Results: We present a novel method for extracting uncertainty from the literature using a hybrid approach that combines rule induction and machine learning. Variations of this hybrid approach are then discussed, alongside their advantages and disadvantages. We use subjective logic theory to combine multiple uncertainty values extracted from different sources for the same interaction. Our approach achieves F-scores of 0.76 and 0.88 based on the BioNLP-ST and Genia-MK corpora, respectively, making considerable improvements over previously published work. Moreover, we evaluate our proposed system on pathways related to two different areas, namely leukemia and melanoma cancer research. © The Author 2017. Published by Oxford University Press.",Bioinformatics,10.1093/bioinformatics/btx466,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039853755&doi=10.1093%2fbioinformatics%2fbtx466&partnerID=40&md5=8cf5f7d19ee10493d9ddf5b9f6619827,2017,7/20/21 15:49,7/20/21 15:49,1167
96YWDJ2H,journalArticle,2011,"Belaïd, A.; D'Andecy, V.P.; Hamza, H.; Belaïd, Y.",Administrative document analysis and structure,1,,text,"This chapter reports our knowledge about the analysis and recognition of scanned administrative documents. Regarding essentially the administrative paper flow with new and continuous arrivals, all the conventional techniques reserved to static databases modeling and recognition are doomed to failure. For this purpose, a new technique based on the experience was investigated giving very promising results. This technique is related to the case-based reasoning already used in data mining and various problems of machine learning. After the presentation of the context related to the administrative document flow and its requirements in a real time processing, we present a case based reasonning for invoice processing. The case corresponds to the co-existence of a problem and its solution. The problem in an invoice corresponds to a local structure such as the keywords of an address or the line patterns in the amounts table, while the solution is related to their content. This problem is then compared to a document case base using graph probing. For this purpose, we proposed an improvement of an already existing neural network called Incremental Growing Neural Gas. © 2011 Springer-Verlag Berlin Heidelberg.",Studies in Computational Intelligence,10.1007/978-3-642-22913-8_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80455129757&doi=10.1007%2f978-3-642-22913-8_3&partnerID=40&md5=528c919801f5fca7b36cd438e58e0dee,2011,7/20/21 15:49,7/20/21 15:49,1182
XCZY3LAE,journalArticle,2011,"Smole, D.; Čeh, M.; Podobnikar, T.",Evaluation of inductive logic programming for information extraction from natural language texts to support spatial data recommendation services,1,,,"In this article we analyze a well-known and extensively researched problem: how to find all datasets, on the one hand, and on the other hand only those that are of value to the user when dealing with a specific spatially oriented task. In analogy with existing approaches to a similar problem from other fields of human endeavor, we call this software solution 'a spatial data recommendation service.' In its final version, this service should be capable of matching requests created in the user's mind with the content of the existing datasets, while taking into account the user's preferences obtained from the user's previous use of the service. As a result, the service should recommend a list of datasets best suited to the user's needs. In this regard, we consider metadata, particularly natural language definitions of spatial entities, a crucial piece of the solution. To be able to use this information in the process of matching the user's request with the dataset content, this information must be semantically preprocessed. To automate this task we have applied a machine learning approach. With inductive logic programming (ILP) our system learns rules that identify and extract values for the five most frequent relations/properties found in Slovene natural language definitions of spatial entities. The initially established quality criterion for identifying and extracting information was met in three out of five examples. Therefore we conclude that ILP offers a promising approach to developing an information extraction component of a spatial data recommendation service. © 2011 Copyright Taylor and Francis Group, LLC.",International Journal of Geographical Information Science,10.1080/13658816.2011.556640,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859113383&doi=10.1080%2f13658816.2011.556640&partnerID=40&md5=4102f9f503ca5be1b5a2371fc696052c,2011,7/20/21 15:49,7/20/21 15:49,1186
M6MWATK2,journalArticle,2018,"Zhang, J.; Williams, S.O.; Wang, H.",Intelligent computing system based on pattern recognition and data mining algorithms,1,,UNK,"The integration of intelligent system mainly includes the application of intelligent technology, such as artificial intelligence and computational intelligence method, which is used in different levels of the system. This paper introduces the application and technology of several intelligent system integrations, the advantages and disadvantages of learning theory and expert system. Neural network is applied in intelligent systems and we use scope reviewed several new development of intelligent technology, plus this paper describes the development direction of the intelligent system. This paper introduces the basic concepts of data mining, including data mining technology, artificial intelligence, machine learning, statistical analysis, fuzzy logic, pattern recognition and artificial neural networks and other technologies. We analyze the structure of the general algorithm of data mining, and classify the data mining technology in details, including more than 10 techniques of decision tree technology, neural network technology, rough set and fuzzy set. Finally, the research directions of data mining in artificial intelligence, e-commerce applications and mobile communication computing are discussed. © 2017 Elsevier Inc.",Sustainable Computing: Informatics and Systems,10.1016/j.suscom.2017.10.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034587707&doi=10.1016%2fj.suscom.2017.10.010&partnerID=40&md5=95709003e570d27b8a75225b637e29f3,2018,7/20/21 15:49,7/20/21 15:49,1199
Z3Y3BTDB,journalArticle,2015,"Shell, J.; Coupland, S.",Fuzzy Transfer Learning: Methodology and application,1,,UNK,"Producing a methodology that is able to predict output using a model is a well studied area in Computational Intelligence (CI). However, a number of real-world applications require a model but have little or no data available of the specific environment. Predominantly, standard machine learning approaches focus on a need for training data for such models to come from the same domain as the target task. Such restrictions can severely reduce the data acquisition making it extremely costly, or in certain situations, impossible. This impedes the ability of these approaches to model such environments. It is on this particular problem that this paper is focussed. In this paper two concepts, Transfer Learning (TL) and Fuzzy Logic (FL) are combined in a framework, Fuzzy Transfer Learning (FuzzyTL), to address the problem of learning tasks that have no prior direct contextual knowledge. Through the use of a FL based learning method, uncertainty that is evident in dynamic environments is represented. By applying a TL approach through the combining of labelled data from a contextually related source task, and little or no unlabelled data from a target task, the framework is shown to be able to accomplish predictive tasks using models learned from contextually different data. ©2014 Published by Elsevier Inc. All rights reserved.",Information Sciences,10.1016/j.ins.2014.09.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922440761&doi=10.1016%2fj.ins.2014.09.004&partnerID=40&md5=4e76aad13354c61f42a447601454419a,2015,7/20/21 15:49,7/20/21 15:49,1201
S49KWVJ7,journalArticle,2019,"He, C.; Liu, Y.; Yao, T.; Xu, F.; Hu, Y.; Zheng, J.",A fast learning algorithm based on extreme learning machine for regular fuzzy neural network,1,,UNK,The regular fuzzy neural network (RFNN) is a kind of fuzzy neural network by fuzzifying the feed-forward neural network. The RFNN can directly deal with the language information and it has the merits of fuzzy system and neural network. It is presented a fast learning algorithm based on the extreme learning machine (ELM) for the RFNN in this paper. The RFNN referred here is a three-layer feed-forward fuzzy neural network and the connected weights in the RFNN are all fuzzy numbers. A simulation example is given to approximately realize the fuzzy if-Then rules by the RFNN. The results show that the RFNN trained by the proposed algorithm has good performance and approximation ability. © 2019-IOS Press and the authors. All rights reserved.,Journal of Intelligent and Fuzzy Systems,10.3233/JIFS-18046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064672921&doi=10.3233%2fJIFS-18046&partnerID=40&md5=98fb6f1a7da01c86c46b95cbf0aba45f,2019,7/20/21 15:49,7/20/21 15:49,1206
CWDWGM8M,journalArticle,2019,"Hsieh, J.-G.; Jeng, J.-H.; Lin, Y.-L.; Kuo, Y.-S.",Single index fuzzy neural networks using locally weighted polynomial regression,1,,UNK,"The novel single index fuzzy neural network models are proposed in this paper for general machine learning problems. The proposed models are different from the usual fuzzy neural network models in that the output nodes of the networks are replaced by (nonparametric) single index models. Specifically, instead of pre-specifying the output activation functions as in the usual models, they are re-estimated adaptively during the training process via “Loess” (“LOcal regrESSion”), a powerful (nonparametric) scatterplot smoother. These estimated activation functions are not necessarily the usual sigmoidal or identity functions. It is interesting to find that in many cases the estimated output activation functions are well approximated by simple polynomial or generalized hyperbolic tangent functions. These problem-tailored simple functions can, if necessary, then be used as the actual output activation functions for neural network training and prediction. Particle swarm optimization, a commonly used evolutionary computation technique, is adopted in this study to search the optimal connection weights of the neural networks. The main advantages of the single index fuzzy neural network models are that they are well suited in situations when one lacks the information about the probability distribution of the response and it is not necessary to specify the output activation functions of the neural networks. Simulation results show that the proposed models usually provide better fits than the usual models for the data at hand. © 2019 Elsevier B.V.",Fuzzy Sets and Systems,10.1016/j.fss.2019.02.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062340898&doi=10.1016%2fj.fss.2019.02.010&partnerID=40&md5=4caea19a718f1782a96a1b6e76fe2d3e,2019,7/20/21 15:49,7/20/21 15:49,1212
D3AHAVXB,journalArticle,2020,"Ming, Y.; Xu, P.; Cheng, F.; Qu, H.; Ren, L.",ProtoSteer: Steering Deep Sequence Model with Prototypes,1,,,"Recently we have witnessed growing adoption of deep sequence models (e.g. LSTMs) in many application domains, including predictive health care, natural language processing, and log analysis. However, the intricate working mechanism of these models confines their accessibility to the domain experts. Their black-box nature also makes it a challenging task to incorporate domain-specific knowledge of the experts into the model. In ProtoSteer (Prototype Steering), we tackle the challenge of directly involving the domain experts to steer a deep sequence model without relying on model developers as intermediaries. Our approach originates in case-based reasoning, which imitates the common human problem-solving process of consulting past experiences to solve new problems. We utilize ProSeNet (Prototype Sequence Network), which learns a small set of exemplar cases (i.e., prototypes) from historical data. In ProtoSteer they serve both as an efficient visual summary of the original data and explanations of model decisions. With ProtoSteer the domain experts can inspect, critique, and revise the prototypes interactively. The system then incorporates user-specified prototypes and incrementally updates the model. We conduct extensive case studies and expert interviews in application domains including sentiment analysis on texts and predictive diagnostics based on vehicle fault logs. The results demonstrate that involvements of domain users can help obtain more interpretable models with concise prototypes while retaining similar accuracy. © 1995-2012 IEEE.",IEEE Transactions on Visualization and Computer Graphics,10.1109/TVCG.2019.2934267,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075630282&doi=10.1109%2fTVCG.2019.2934267&partnerID=40&md5=7eab1cda9540bfbde4a816ebf424cd64,2020,7/20/21 15:49,7/20/21 15:49,1229
6DWCY3EC,journalArticle,2012,"Mehler, A.; Lücking, A.; Menke, P.",Assessing cognitive alignment in different types of dialog by means of a network model,1,,text,"We present a network model of dialog lexica, called TiTAN (Two-layer Time-Aligned Network) series. TiTAN series capture the formation and structure of dialog lexica in terms of serialized graph representations. The dynamic update of TiTAN series is driven by the dialog-inherent timing of turn-taking. The model provides a link between neural, connectionist underpinnings of dialog lexica on the one hand and observable symbolic behavior on the other. On the neural side, priming and spreading activation are modeled in terms of TiTAN networking. On the symbolic side, TiTAN series account for cognitive alignment in terms of the structural coupling of the linguistic representations of dialog partners. This structural stance allows us to apply TiTAN in machine learning of data of dialogical alignment. In previous studies, it has been shown that aligned dialogs can be distinguished from non-aligned ones by means of TiTAN -based modeling. Now, we simultaneously apply this model to two types of dialog: task-oriented, experimentally controlled dialogs on the one hand and more spontaneous, direction giving dialogs on the other. We ask whether it is possible to separate aligned dialogs from non-aligned ones in a type-crossing way. Starting from a recent experiment (. Mehler, Lücking, & Menke, 2011a), we show that such a type-crossing classification is indeed possible. This hints at a structural fingerprint left by alignment in networks of linguistic items that are routinely co-activated during conversation. © 2012 Elsevier Ltd.",Neural Networks,10.1016/j.neunet.2012.02.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861762399&doi=10.1016%2fj.neunet.2012.02.013&partnerID=40&md5=26a67baacbef087092153f8439bfccda,2012,7/20/21 15:49,7/20/21 15:49,1264
Y56IDMX3,journalArticle,2018,"Kim, E.-H.; Oh, S.-K.; Pedrycz, W.",Design of double fuzzy clustering-driven context neural networks,1,,UNK,"In this study, we introduce a novel category of double fuzzy clustering-driven context neural networks (DFCCNNs). The study is focused on the development of advanced design methodologies for redesigning the structure of conventional fuzzy clustering-based neural networks. The conventional fuzzy clustering-based neural networks typically focus on dividing the input space into several local spaces (implied by clusters). In contrast, the proposed DFCCNNs take into account two distinct local spaces called context and cluster spaces, respectively. Cluster space refers to the local space positioned in the input space whereas context space concerns a local space formed in the output space. Through partitioning the output space into several local spaces, each context space is used as the desired (target) local output to construct local models. To complete this, the proposed network includes a new context layer for reasoning about context space in the output space. In this sense, Fuzzy C-Means (FCM) clustering is useful to form local spaces in both input and output spaces. The first one is used in order to form clusters and train weights positioned between the input and hidden layer, whereas the other one is applied to the output space to form context spaces. The key features of the proposed DFCCNNs can be enumerated as follows: (i) the parameters between the input layer and hidden layer are built through FCM clustering. The connections (weights) are specified as constant terms being in fact the centers of the clusters. The membership functions (represented through the partition matrix) produced by the FCM are used as activation functions located at the hidden layer of the “conventional” neural networks. (ii) Following the hidden layer, a context layer is formed to approximate the context space of the output variable and each node in context layer means individual local model. The outputs of the context layer are specified as a combination of both weights formed as linear function and the outputs of the hidden layer. The weights are updated using the least square estimation (LSE)-based method. (iii) At the output layer, the outputs of context layer are decoded to produce the corresponding numeric output. At this time, the weighted average is used and the weights are also adjusted with the use of the LSE scheme. From the viewpoint of performance improvement, the proposed design methodologies are discussed and experimented with the aid of benchmark machine learning datasets. Through the experiments, it is shown that the generalization abilities of the proposed DFCCNNs are better than those of the conventional FCNNs reported in the literature. © 2018 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2018.03.018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046336298&doi=10.1016%2fj.neunet.2018.03.018&partnerID=40&md5=86290d990a097dcf11db86d690c6acb1,2018,7/20/21 15:49,7/20/21 15:49,1266
JA5HHBV2,journalArticle,2020,"Nápoles, G.; Jastrzębska, A.; Mosquera, C.; Vanhoof, K.; Homenda, W.",Deterministic learning of hybrid Fuzzy Cognitive Maps and network reduction approaches,1,,UNK,"Hybrid artificial intelligence deals with the construction of intelligent systems by relying on both human knowledge and historical data records. In this paper, we approach this problem from a neural perspective, particularly when modeling and simulating dynamic systems. Firstly, we propose a Fuzzy Cognitive Map architecture in which experts are requested to define the interaction among the input neurons. As a second contribution, we introduce a fast and deterministic learning rule to compute the weights among input and output neurons. This parameterless learning method is based on the Moore–Penrose inverse and it can be performed in a single step. In addition, we discuss a model to determine the relevance of weights, which allows us to better understand the system. Last but not least, we introduce two calibration methods to adjust the model after the removal of potentially superfluous weights. © 2020 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2020.01.019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078744842&doi=10.1016%2fj.neunet.2020.01.019&partnerID=40&md5=1adf862ed129e7abc0864e917908816c,2020,7/20/21 15:49,7/20/21 15:49,1267
54LE8HAY,journalArticle,2014,"Davtalab, R.; Dezfoulian, M.H.; Mansoorizadeh, M.",Multi-level fuzzy min-max neural network classifier,1,,UNK,"In this paper a multi-level fuzzy min-max neural network classifier (MLF), which is a supervised learning method, is described. MLF uses basic concepts of the fuzzy min-max (FMM) method in a multi-level structure to classify patterns. This method uses separate classifiers with smaller hyperboxes in different levels to classify the samples that are located in overlapping regions. The final output of the network is formed by combining the outputs of these classifiers. MLF is capable of learning nonlinear boundaries with a single pass through the data. According to the obtained results, the MLF method, compared to the other FMM networks, has the highest performance and the lowest sensitivity to maximum size of the hyperbox parameter θ, with a training accuracy of 100% in most cases. © 2012 IEEE.",IEEE Transactions on Neural Networks and Learning Systems,10.1109/TNNLS.2013.2275937,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897647724&doi=10.1109%2fTNNLS.2013.2275937&partnerID=40&md5=2f4ee25e2029aaa9701d9971f67eb640,2014,7/20/21 15:49,7/20/21 15:49,1274
ZH4FMZ2Y,journalArticle,2017,"Pratama, M.; Lu, J.; Lughofer, E.; Zhang, G.; Er, M.J.",An Incremental Learning of Concept Drifts Using Evolving Type-2 Recurrent Fuzzy Neural Networks,1,,UNK,"The age of online data stream and dynamic environments results in the increasing demand of advanced machine learning techniques to deal with concept drifts in large data streams. Evolving fuzzy systems (EFS) are one of recent initiatives from the fuzzy system community to resolve the issue. Existing EFSs are not robust against data uncertainty, temporal system dynamics, and the absence of system order, because a vast majority of EFSs are designed in the type-1 feedforward network architecture. This paper aims to solve the issue of data uncertainty, temporal behavior, and the absence of system order by developing a novel evolving recurrent fuzzy neural network, called evolving type-2 recurrent fuzzy neural network (eT2RFNN). eT2RFNN is constructed in a new recurrent network architecture, featuring double recurrent layers. The new recurrent network architecture evolves a generalized interval type-2 fuzzy rule, where the rule premise is built upon the interval type-2 multivariate Gaussian function, whereas the rule consequent is crafted by the nonlinear wavelet function. The eT2RFNN adopts a holistic concept of evolving systems, where the fuzzy rule can be automatically generated, pruned, merged, and recalled in the single-pass learning mode. eT2RFNN is capable of coping with the problem of high dimensionality because it is equipped with online feature selection technology. The efficacy of eT2RFNN was experimentally validated using artificial and real-world data streams and compared with prominent learning algorithms. eT2RFNN produced more reliable predictive accuracy, while retaining lower complexity than its counterparts. © 2017 IEEE.",IEEE Transactions on Fuzzy Systems,10.1109/TFUZZ.2016.2599855,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032441894&doi=10.1109%2fTFUZZ.2016.2599855&partnerID=40&md5=c2134edab87d683e9ddd75e9b37bab3e,2017,7/20/21 15:50,7/20/21 15:50,1296
33PCBE9R,journalArticle,2021,"Gan, Z.; Zeng, B.; Cheng, L.; Liu, S.; Yang, H.; Xu, M.; Ding, M.",RoRePo: Detecting the role information and relative position information for contexts in multi-turn dialogue generation,1,,,"In multi-turn dialogue generation, dialogue contexts have been shown to have an important influence on the reasoning of the next round of dialogue. A multi-turn dialogue between two people should be able to give a reasonable response according to the relevant context. However, the widely used hierarchical recurrent encoder-decoder model and the latest model that detecting the relevant contexts with self-attention are facing the same problem. Their given response doesn't match the identity of the current speaker, which we call it role ambiguity. In this paper, we propose a new model, named RoRePo, to tackle this problem by detecting the role information and relative position information. Firstly, as a part of the decoder input, we add a role embedding to identity different speakers. Secondly, we incorporate self-attention mechanism with relative position representation to dialogue context understanding. Besides, the design of our model architecture considers the influence of latent variables in generating more diverse responses. Experimental results of our evaluations on the DailyDialog and DSTC7_AVSD datasets show that our proposed model advances in multi-turn dialogue generation. © 2021 - IOS Press. All rights reserved.",Journal of Intelligent and Fuzzy Systems,10.3233/JIFS-202641,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104954784&doi=10.3233%2fJIFS-202641&partnerID=40&md5=65b21ad445dde58d2fa5781dc4c7fe96,2021,7/20/21 15:50,7/20/21 15:50,1306
X5MI5WMJ,journalArticle,2018,"Dario, G.-G.; Parés, F.; Vilalta, A.; Moreno, J.; Ayguade, E.; Labarta, J.; Cortés, U.; Suzumura, T.",On the behavior of convolutional nets for feature extraction,1,,UNK,"Deep neural networks are representation learning techniques. During training, a deep net is capable of generating a descriptive language of unprecedented size and detail in machine learning. Extracting the descriptive language coded within a trained CNN model (in the case of image data), and reusing it for other purposes is a field of interest, as it provides access to the visual descriptors previously learnt by the CNN after processing millions of images, without requiring an expensive training phase. Contributions to this field (commonly known as feature representation transfer or transfer learning) have been purely empirical so far, extracting all CNN features from a single layer close to the output and testing their performance by feeding them to a classifier. This approach has provided consistent results, although its relevance is limited to classification tasks. In a completely different approach, in this paper we statistically measure the discriminative power of every single feature found within a deep CNN, when used for characterizing every class of 11 datasets. We seek to provide new insights into the behavior of CNN features, particularly the ones from convolutional layers, as this can be relevant for their application to knowledge representation and reasoning. Our results confirm that low and middle level features may behave differently to high level features, but only under certain conditions. We find that all CNN features can be used for knowledge representation purposes both by their presence or by their absence, doubling the information a single CNN feature may provide. We also study how much noise these features may include, and propose a thresholding approach to discard most of it. All these insights have a direct application to the generation of CNN embedding spaces. © 2018 AI Access Foundation. All rights reserved.",Journal of Artificial Intelligence Research,10.1613/jair.5756,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047837205&doi=10.1613%2fjair.5756&partnerID=40&md5=1f5658c804fe8ffef4bb7861e7d89e9b,2018,7/20/21 15:50,7/20/21 15:50,1319
NSMF6RCH,journalArticle,2017,"Galitsky, B.",Improving relevance in a content pipeline via syntactic generalization,1,,text,"This is a report from the field on a linguistic-based relevance technology based on learning of parse trees for processing, classification and delivery of a stream of texts. We describe the content pipeline for eBay entertainment domain which employs this technology, and show that text processing relevance is the main bottleneck for its performance. A number of components of the content pipeline such as content mining, aggregation, deduplication, opinion mining, integrity enforcing need to rely on domain-independent efficient text classification, entity extraction and relevance assessment operations. Text relevance assessment is based on the operation of syntactic generalization (SG) which finds a maximum common sub-tree for a pair of parse trees for sentences. Relevance of two portions of texts is then defined as a cardinality of this sub-tree. SG is intended to substitute keyword-based analysis for more accurate assessment of relevance which takes phrase-level and sentence-level information into account. In the partial case where short expression are commonly used terms such as Facebook likes, SG ascends to the level of categories and a reasoning technique is required to map these categories in the course of relevance assessment. A number of content pipeline components employ web mining which needs SG to compare web search results. We describe how SG works in a number of components in the content pipeline including personalization and recommendation, and provide the evaluation results for eBay deployment. Content pipeline support is implemented as an open source contribution OpenNLP.Similarity and is available at https://github.com/bgalitsky/relevance-based-on-pars-trees. © 2016 Elsevier Ltd",Engineering Applications of Artificial Intelligence,10.1016/j.engappai.2016.11.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006868883&doi=10.1016%2fj.engappai.2016.11.001&partnerID=40&md5=57418c10b16696a7cc4b829b6d24aa2f,2017,7/20/21 15:50,7/20/21 15:50,1321
U7TPBL9U,journalArticle,2021,"Wu, X.; Weng, J.",Learning to recognize while learning to speak: Self-supervision and developing a speaking motor,1,,,"Traditionally, learning speech synthesis and speech recognition were investigated as two separate tasks. This separation hinders incremental development for concurrent synthesis and recognition, where partially-learned synthesis and partially-learned recognition must help each other throughout lifelong learning. This work is a paradigm shift—we treat synthesis and recognition as two intertwined aspects of a lifelong learning agent. Furthermore, in contrast to existing recognition or synthesis systems, babies do not need their mothers to directly supervise their vocal tracts at every moment during the learning. We argue that self-generated non-symbolic states/actions at fine-grained time level help such a learner as necessary temporal contexts. Here, we approach a new and challenging problem—how to enable an autonomous learning system to develop an artificial speaking motor for generating temporally-dense (e.g., frame-wise) actions on the fly without human handcrafting a set of symbolic states. The self-generated states/actions are Muscles-like, High-dimensional, Temporally-dense and Globally-smooth (MHTG), so that these states/actions are directly attended for concurrent synthesis and recognition for each time frame. Human teachers are relieved from supervising learner's motor ends. The Candid Covariance-free Incremental (CCI) Principal Component Analysis (PCA) is applied to develop such an artificial speaking motor where PCA features drive the motor. Since each life must develop normally, each Developmental Network-2 (DN-2) reaches the same network (maximum likelihood, ML) regardless of randomly initialized weights, where ML is not just for a function approximator but rather an emergent Turing Machine. The machine-synthesized sounds are evaluated by both the neural network and humans with recognition experiments. Our experimental results showed learning-to-synthesize and learning-to-recognize-through-synthesis for phonemes. This work corresponds to a key step toward our goal to close a great gap toward fully autonomous machine learning directly from the physical world. © 2021 Elsevier Ltd",Neural Networks,10.1016/j.neunet.2021.05.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107089244&doi=10.1016%2fj.neunet.2021.05.006&partnerID=40&md5=37890b4bebb572f940d7d99c694e2353,2021,7/20/21 15:50,7/20/21 15:50,1359
6BM6PQF7,journalArticle,2020,"Han, W.; Peng, M.; Xie, Q.; Hu, G.; Gao, W.; Wang, H.; Zhang, Y.; Liu, Z.",DTC: Transfer learning for commonsense machine comprehension,1,,text,"Commonsense Machine Comprehension (CMC) is a popular natural language understanding task. CMC enables computers to learn about causal and temporal reasoning by exploiting implicit commonsense knowledge and can be applied to Question Answering, Search Engine and Dialogue System. Previous methods for CMC limit the vision on CMC task, neglecting that Recognizing Textual Entailment(RTE) task has much similarities with CMC task. In this paper, we propose a transfer learning model, which can take advantage of commonsense knowledge in RTE task by mapping CMC examples and RTE examples to a shared feature space and comprehending in this feature space. Specifically, we first establish a transfer learning framework which has three components: (1) source and target mappings, (2) domain regularization, and (3) CMC score function. Then we make selection for each component in our transfer learning framework and propose the Domain Transfer Comprehension(DTC) model. Experiments on Story Cloze Test show that our model outperforms most previous approaches and provides competitive results with state-of-art methods. We also show each components of our model have positive effect on performance. © 2019",Neurocomputing,10.1016/j.neucom.2019.07.110,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079892028&doi=10.1016%2fj.neucom.2019.07.110&partnerID=40&md5=38b1fe46c685cd5e7a9cab303eaeb8d7,2020,7/20/21 15:50,7/20/21 15:50,1362
QUTS25F6,journalArticle,2015,"Riveret, R.; Korkinof, D.; Draief, M.; Pitt, J.",Probabilistic abstract argumentation: An investigation with Boltzmann machines,1,,text,"Probabilistic argumentation and neuro-argumentative systems offer new computational perspectives for the theory and applications of argumentation, but their principled construction involves two entangled problems. On the one hand, probabilistic argumentation aims at combining the quantitative uncertainty addressed by probability theory with the qualitative uncertainty of argumentation, but probabilistic dependences amongst arguments as well as learning are usually neglected. On the other hand, neuro-argumentative systems offer the opportunity to couple the computational advantages of learning and massive parallel computation from neural networks with argumentative reasoning and explanatory abilities, but the relation of probabilistic argumentation frameworks with these systems has been ignored so far. Towards the construction of neuro-argumentative systems based on probabilistic argumentation, we associate a model of abstract argumentation and the graphical model of Boltzmann machines (BMs) in order to (i) account for probabilistic abstract argumentation with possible and unknown probabilistic dependences amongst arguments, (ii) learn distributions of labellings from a set of cases and (iii) sample labellings according to the learned distribution. Experiments on domain independent artificial datasets show that argumentative BMs can be trained with conventional training procedures and compare well with conventional machines for generating labellings of arguments, with the assurance of generating grounded labellings - on demand. © 2015 Taylor & Francis.",Argument and Computation,10.1080/19462166.2015.1107134,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951179979&doi=10.1080%2f19462166.2015.1107134&partnerID=40&md5=d3ae958bfa5a8d467cd3c1b838ac30c2,2015,7/20/21 15:50,7/20/21 15:50,1366
8NM7C7KQ,journalArticle,2011,"Galitsky, B.; De La Rosa, J.-L.; Kovalerchuk, B.",Discovering common outcomes of agents' communicative actions in various domains,1,,,"We explore the common patterns of human behavior, expressed via communicative actions, and displayed in various domains of human activities associated with conflicts. We build the generic methodology based on machine learning and reasoning to predict specific communicative actions of human agents, given previous sequence of communicative actions of themselves and their opponents. This methodology is applied to textual as well as structured data on inter-human conflicts of diverse modalities. Scenarios are represented by directed graphs with labeled vertices (for communicative actions) and arcs (for temporal and causal relationships between subjects of these actions). Scenario representation and learning techniques are firstly developed in the domain of textual customer complaints, and then applied to such problems as predicting an outcome of international conflicts, assessment of an attitude of a security clearance candidate, mining emails for suspicious emotional profiles, and recognizing suspicious behavior of cell phone users. We present an evaluation of the proposed methodology in the domain of customer complaint and conduct some comparative evaluation in the other domains mentioned above. Successful use of the proposed methodology in rather distinct domains shows its adequacy for mining human attitude-related data in a wide range of applications. © 2010 Elsevier B.V. All rights reserved.",Knowledge-Based Systems,10.1016/j.knosys.2010.06.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650814122&doi=10.1016%2fj.knosys.2010.06.004&partnerID=40&md5=9a42d5751472ab8e1e680c83532e351d,2011,7/20/21 15:50,7/20/21 15:50,1367
K4XTMZYM,journalArticle,2017,"Yeh, J.-W.; Su, S.-F.",Efficient Approach for RLS Type Learning in TSK Neural Fuzzy Systems,1,,UNK,"This paper presents an efficient approach for the use of recursive least square (RLS) learning algorithm in Takagi-Sugeno-Kang neural fuzzy systems. In the use of RLS, reduced covariance matrix, of which the off-diagonal blocks defining the correlation between rules are set to zeros, may be employed to reduce computational burden. However, as reported in the literature, the performance of such an approach is slightly worse than that of using the full covariance matrix. In this paper, we proposed a so-called enhanced local learning concept in which a threshold is considered to stop learning for those less fired rules. It can be found from our experiments that the proposed approach can have better performances than that of using the full covariance matrix. Enhanced local learning method can be more active on the structure learning phase. Thus, the method not only can stop the update for insufficiently fired rules to reduce disturbances in self-constructing neural fuzzy inference network but also raises the learning speed on structure learning phase by using a large backpropagation learning constant. © 2017 IEEE.",IEEE Transactions on Cybernetics,10.1109/TCYB.2016.2638861,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008499918&doi=10.1109%2fTCYB.2016.2638861&partnerID=40&md5=6845de787d0a533ad4f66f1bed3dc544,2017,7/20/21 15:50,7/20/21 15:50,1442
J4NN3VZU,journalArticle,2019,"Ji, X.; Shen, H.-W.; Ritter, A.; MacHiraju, R.; Yen, P.-Y.",Visual Exploration of Neural Document Embedding in Information Retrieval: Semantics and Feature Selection,1,,XAI,"Neural embeddings are widely used in language modeling and feature generation with superior computational power. Particularly, neural document embedding-converting texts of variable-length to semantic vector representations-has shown to benefit widespread downstream applications, e.g., information retrieval (IR). However, the black-box nature makes it difficult to understand how the semantics are encoded and employed. We propose visual exploration of neural document embedding to gain insights into the underlying embedding space, and promote the utilization in prevalent IR applications. In this study, we take an IR application-driven view, which is further motivated by biomedical IR in healthcare decision-making, and collaborate with domain experts to design and develop a visual analytics system. This system visualizes neural document embeddings as a configurable document map and enables guidance and reasoning; facilitates to explore the neural embedding space and identify salient neural dimensions (semantic features) per task and domain interest; and supports advisable feature selection (semantic analysis) along with instant visual feedback to promote IR performance. We demonstrate the usefulness and effectiveness of this system and present inspiring findings in use cases. This work will help designers/developers of downstream applications gain insights and confidence in neural document embedding, and exploit that to achieve more favorable performance in application domains. © 1995-2012 IEEE.",IEEE Transactions on Visualization and Computer Graphics,10.1109/TVCG.2019.2903946,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065410305&doi=10.1109%2fTVCG.2019.2903946&partnerID=40&md5=df1fbeb94218af7c1a004a35ef4e2b2d,2019,7/20/21 15:50,7/20/21 15:50,1454
GS3TRUYZ,journalArticle,2018,"Hussain, A.; Cambria, E.",Semi-supervised learning for big social data analysis,1,,,"In an era of social media and connectivity, web users are becoming increasingly enthusiastic about interacting, sharing, and working together through online collaborative media. More recently, this collective intelligence has spread to many different areas, with a growing impact on everyday life, such as in education, health, commerce and tourism, leading to an exponential growth in the size of the social Web. However, the distillation of knowledge from such unstructured Big data is, an extremely challenging task. Consequently, the semantic and multimodal contents of the Web in this present day are, whilst being well suited for human use, still barely accessible to machines. In this work, we explore the potential of a novel semi-supervised learning model based on the combined use of random projection scaling as part of a vector space model, and support vector machines to perform reasoning on a knowledge base. The latter is developed by merging a graph representation of commonsense with a linguistic resource for the lexical representation of affect. Comparative simulation results show a significant improvement in tasks such as emotion recognition and polarity detection, and pave the way for development of future semi-supervised learning approaches to big social data analytics. © 2017 Elsevier B.V.",Neurocomputing,10.1016/j.neucom.2017.10.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032371736&doi=10.1016%2fj.neucom.2017.10.010&partnerID=40&md5=8ba4edf6e121c55005f6c8a0894821a8,2018,7/20/21 15:50,7/20/21 15:50,1455
CTKS4HDY,journalArticle,2013,"Didandeh, A.; Mirbakhsh, N.; Afsharchi, M.",Concept learning games: An ontological study in multi-agent systems,1,,multi-agent systems,"In this paper, we intend to have a game theoretic study on the concept learning problem in a multi-agent system. Concept learning is a very essential and well-studied domain of machine learning when it is studied under the characteristics of a multi-agent system. The most important reasons are the partiality of the environment perception for any agent and also the communication holdbacks, resulting into a deep need for a collaborative protocol in favor of multi-agent transactions. Here we wish to investigate multi-agent concept learning with the help of its components, thoroughly with a game theoretic taste, esp. on the pre-learning processes. Based on two standard notations, we address the non-unanimity of concepts, classification of objects, voting and communicating protocol, and also the learning itself. In such a game of concept learning, we consider a group of agents, communicating and consulting to upgrade their ontologies based on their conceptualizations of the environment. For this purpose, we investigate the problem in two separate and standard distinctions of game theory study, cooperation and competition. Several solution concepts and innovative ideas from the multi-agent realm are used to produce an approach that contains the reasoning process of the agents in this system. Some experimentations come at the end to show the functionality of our approach. These experimentations come distinctly for both cooperative and competitive views. © 2012 Springer Science+Business Media, LLC.",Information Systems Frontiers,10.1007/s10796-012-9343-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882450501&doi=10.1007%2fs10796-012-9343-3&partnerID=40&md5=6498e905e35d81b2732a4f69cc44812c,2013,7/20/21 15:50,7/20/21 15:50,1458
UJIATK82,journalArticle,2018,"Lau, H.; Lee, C.K.M.; Nakandala, D.; Shum, P.",An outcome-based process optimization model using fuzzy-based association rules,1,,UNK,"Purpose: The purpose of this paper is to propose an outcome-based process optimization model which can be deployed in companies to enhance their business operations, strengthening their competitiveness in the current industrial environment. To validate the approach, a case example has been included to assess the practicality and validity of this approach to be applied in actual environment. Design/methodology/approach: This model embraces two approaches including: fuzzy logic for mimicking the human thinking and decision making mechanism; and data mining association rules approach for optimizing the analyzed knowledge for future decision-making as well as providing a mechanism to apply the obtained knowledge to support the improvement of different types of processes. Findings: The new methodology of the proposed algorithm has been evaluated in a case study and the algorithm shows its potential to determine the primary factors that have a great effect upon the final result of the entire operation comprising a number of processes. In this case example, relevant process parameters have been identified as the important factors causing significant impact on the result of final outcome. Research limitations/implications: The proposed methodology requires the dependence on human knowledge and personal experience to determine the various fuzzy regions of the processes. This can be fairly subjective and even biased. As such, it is advisable that the development of artificial intelligence techniques to support automatic machine learning to derive the fuzzy sets should be promoted to provide more reliable results. Originality/value: Recent study on the relevant topics indicates that an intelligent process optimization approach, which is able to interact seamlessly with the knowledge-based system and extract useful information for process improvement, is still seen as an area that requires more study and investigation. In this research, the process optimization system with an effective process mining algorithm embedded for supporting knowledge discovery is proposed for use to achieve better quality control. © 2018, Emerald Publishing Limited.",Industrial Management and Data Systems,10.1108/IMDS-08-2017-0347,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051821082&doi=10.1108%2fIMDS-08-2017-0347&partnerID=40&md5=95b7289629665d69d8febc07177ea624,2018,7/20/21 15:50,7/20/21 15:50,1474
LVJ8NGHX,journalArticle,2017,"Martínez-Plumed, F.; Ferri, C.; Hernández-Orallo, J.; Ramírez-Quintana, M.J.",A computational analysis of general intelligence tests for evaluating cognitive development,1,,UNK,"The progression in several cognitive tests for the same subjects at different ages provides valuable information about their cognitive development. One question that has caught recent interest is whether the same approach can be used to assess the cognitive development of artificial systems. In particular, can we assess whether the ‘fluid’ or ‘crystallised’ intelligence of an artificial cognitive system is changing during its cognitive development as a result of acquiring more concepts? In this paper, we address several IQ tests problems (odd-one-out problems, Raven's Progressive Matrices and Thurstone's letter series) with a general learning system that is not particularly designed on purpose to solve intelligence tests. The goal is to better understand the role of the basic cognitive operational constructs (such as identity, difference, order, counting, logic, etc.) that are needed to solve these intelligence test problems and serve as a proof-of-concept for evaluation in other developmental problems. From here, we gain some insights into the characteristics and usefulness of these tests and how careful we need to be when applying human test problems to assess the abilities and cognitive development of robots and other artificial cognitive systems. © 2017 Elsevier B.V.",Cognitive Systems Research,10.1016/j.cogsys.2017.01.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013779387&doi=10.1016%2fj.cogsys.2017.01.006&partnerID=40&md5=ed77f43a824db0a3c0903ba7991c4bad,2017,7/20/21 15:50,7/20/21 15:50,1481
MPD5LQBT,journalArticle,2017,"Berg, J.; Järvisalo, M.",Cost-optimal constrained correlation clustering via weighted partial Maximum Satisfiability,1,,UNK,"Integration of the fields of constraint solving and data mining and machine learning has recently been identified within the AI community as an important research direction with high potential. This work contributes to this direction by providing a first study on the applicability of state-of-the-art Boolean optimization procedures to cost-optimal correlation clustering under constraints in a general similarity-based setting. We develop exact formulations of the correlation clustering task as Maximum Satisfiability (MaxSAT), the optimization version of the Boolean satisfiability (SAT) problem. For obtaining cost-optimal clusterings, we apply a state-of-the-art MaxSAT solver for solving the resulting MaxSAT instances optimally, resulting in cost-optimal clusterings. We experimentally evaluate the MaxSAT-based approaches to cost-optimal correlation clustering, both on the scalability of our method and the quality of the clusterings obtained. Furthermore, we show how the approach extends to constrained correlation clustering, where additional user knowledge is imposed as constraints on the optimal clusterings of interest. We show experimentally that added user knowledge allows clustering larger datasets, and at the same time tends to decrease the running time of our approach. We also investigate the effects of MaxSAT-level preprocessing, symmetry breaking, and the choice of the MaxSAT solver on the efficiency of the approach. © 2015 Elsevier B.V.",Artificial Intelligence,10.1016/j.artint.2015.07.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937879126&doi=10.1016%2fj.artint.2015.07.001&partnerID=40&md5=33fec67b6a5969100d0b96856c3a9630,2017,7/20/21 15:50,7/20/21 15:50,1482
7YX447XS,journalArticle,2016,"Belkebir, R.; Guessoum, A.",Concept generalization and fusion for abstractive sentence generation,1,,text,"Text summarization is either extractive or abstractive. Extractive summarization is to select the most salient pieces of information (words, phrases, and/or sentences) from a source document without adding any external information. Abstractive summarization allows an internal representation of the source document so as to produce a faithful summary of the source. In this case, external text can be inserted into the generated summary. Because of the complexity of the abstractive approach, the vast majority of work in text summarization has adopted an extractive approach. In this work, we focus on concepts fusion and generalization, i.e. where different concepts appearing in a sentence can be replaced by one concept which covers the meanings of all of them. This is one operation that can be used as part of an abstractive text summarization system. The main goal of this contribution is to enrich the research efforts on abstractive text summarization with a novel approach that allows the generalization of sentences using semantic resources. This work should be useful in intelligent systems more generally since it introduces a means to shorten sentences by producing more general (hence abstractions of the) sentences. It could be used, for instance, to display shorter texts in applications for mobile devices. It should also improve the quality of the generated text summaries by mentioning key (general) concepts. One can think of using the approach in reasoning systems where different concepts appearing in the same context are related to one another with the aim of finding a more general representation of the concepts. This could be in the context of Goal Formulation, expert systems, scenario recognition, and cognitive reasoning more generally. We present our methodology for the generalization and fusion of concepts that appear in sentences. This is achieved through (1) the detection and extraction of what we define as generalizable sentences and (2) the generation and reduction of the space of generalization versions. We introduce two approaches we have designed to select the best sentences from the space of generalization versions. Using four NLTK1 corpora, the first approach estimates the ""acceptability"" of a given generalization version. The second approach is Machine Learning-based and uses contextual and specific features. The recall, precision and F1-score measures resulting from the evaluation of the concept generalization and fusion approach are presented. © 2016 Elsevier Ltd. All rights reserved.",Expert Systems with Applications,10.1016/j.eswa.2016.01.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957598648&doi=10.1016%2fj.eswa.2016.01.007&partnerID=40&md5=8192da646ba41a5baa360966c2509e34,2016,7/20/21 15:50,7/20/21 15:50,1500